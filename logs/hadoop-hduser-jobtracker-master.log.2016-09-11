2016-09-11 00:03:43,442 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 00:03:43,507 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 00:03:43,509 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 00:03:43,510 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:03:43,510 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 00:03:43,511 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:03:43,511 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 00:03:43,511 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 00:03:43,517 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 00:03:43,527 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 00:03:43,530 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:03:43,533 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:03:43,534 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:03:43,535 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:03:43,554 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 00:03:43,576 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 00:03:43,598 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 00:03:43,669 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 00:03:43,669 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 00:03:43,669 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 00:03:43,669 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 00:03:43,787 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 00:03:43,788 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 00:03:43,788 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:03:43,788 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:03:43,789 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 00:03:43,789 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 00:03:43,843 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 00:03:43,950 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:03:43,951 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:03:53,956 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:03:53,958 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:04:03,963 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:04:03,967 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:04:13,970 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:04:13,971 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:04:23,973 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:04:23,974 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:04:33,978 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:04:33,980 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:04:43,985 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:04:43,988 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:04:53,990 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:04:53,991 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:05:03,996 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:05:03,998 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:05:14,003 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:05:14,006 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:05:24,013 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:05:24,015 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:05:34,021 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:05:34,024 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:05:44,026 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:05:44,027 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:05:54,028 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:05:54,029 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:06:04,035 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:06:04,038 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:06:14,044 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:06:14,049 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:06:24,051 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:06:24,052 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:06:34,056 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:06:34,057 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:06:44,061 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:06:44,063 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:06:54,065 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:06:54,066 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:04,067 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:07:04,068 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:14,071 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:07:14,073 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:24,077 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:07:24,080 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:34,081 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:07:34,082 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:44,084 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:07:44,085 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:54,086 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:07:54,087 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:07:56,210 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-11 00:08:00,968 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 00:08:01,033 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 00:08:01,036 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 00:08:01,037 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:08:01,037 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 00:08:01,037 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:08:01,038 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 00:08:01,038 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 00:08:01,043 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 00:08:01,053 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 00:08:01,056 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:01,059 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:08:01,061 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:01,061 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:08:01,081 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 00:08:01,103 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 00:08:01,105 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 00:08:01,113 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 00:08:01,114 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 00:08:01,114 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 00:08:01,114 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 00:08:01,232 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 00:08:01,233 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 00:08:01,233 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:01,233 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:01,233 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 00:08:01,233 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 00:08:01,257 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 00:08:01,316 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:08:01,317 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:11,320 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:08:11,321 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:21,326 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:08:21,332 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:31,336 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:08:31,338 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:41,344 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:08:41,347 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:08:51,350 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:08:51,358 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:01,360 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:01,361 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:11,367 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:11,370 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:12,507 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-11 00:09:17,278 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 00:09:17,342 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 00:09:17,344 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 00:09:17,345 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:09:17,345 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 00:09:17,346 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:09:17,346 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 00:09:17,346 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 00:09:17,352 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 00:09:17,362 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 00:09:17,365 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:17,368 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:09:17,369 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:17,370 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:09:17,389 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 00:09:17,412 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 00:09:17,414 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 00:09:17,422 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 00:09:17,422 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 00:09:17,422 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 00:09:17,422 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 00:09:17,541 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 00:09:17,541 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 00:09:17,542 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:17,542 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:17,542 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 00:09:17,542 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 00:09:17,566 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 00:09:17,628 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:17,629 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:27,634 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:27,639 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:37,644 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:37,648 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:47,655 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:47,659 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:09:57,661 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:09:57,663 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:10:07,668 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:10:07,685 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:10:17,688 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:10:17,689 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:10:27,695 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:10:27,697 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:10:37,699 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:10:37,700 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:10:47,705 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:10:47,708 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:10:57,711 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:10:57,712 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:11:07,714 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:11:07,715 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:11:17,719 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:11:17,722 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:11:27,727 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:11:27,729 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:11:37,734 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:11:37,737 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:11:47,740 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:11:47,741 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:11:57,746 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:11:57,749 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:07,752 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:12:07,756 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:10,194 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-11 00:12:14,949 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 00:12:15,013 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 00:12:15,015 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 00:12:15,016 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:12:15,017 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 00:12:15,017 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:12:15,017 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 00:12:15,017 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 00:12:15,023 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 00:12:15,032 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 00:12:15,035 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:15,038 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:12:15,040 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:15,040 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:12:15,059 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 00:12:15,082 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 00:12:15,084 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 00:12:15,092 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 00:12:15,092 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 00:12:15,092 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 00:12:15,092 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 00:12:15,210 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 00:12:15,211 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 00:12:15,211 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:15,211 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:15,211 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 00:12:15,211 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 00:12:15,236 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 00:12:15,295 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:12:15,297 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:25,302 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:12:25,305 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:35,309 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:12:35,311 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:45,314 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:12:45,330 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:12:55,332 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:12:55,333 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:13:05,336 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:13:05,338 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:13:15,340 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:13:15,341 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:13:25,343 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:13:25,346 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:13:35,348 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:13:35,350 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:13:45,352 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:13:45,354 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:13:55,356 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:13:55,357 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:14:05,359 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:14:05,360 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:14:15,362 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:14:15,363 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:14:25,364 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:14:25,365 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:14:35,367 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:14:35,368 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:14:45,370 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:14:45,371 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:14:55,375 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:14:55,379 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:15:05,382 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:15:05,385 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:15:15,387 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:15:15,388 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:15:25,390 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:15:25,391 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:15:35,392 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:15:35,393 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:15:45,395 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:15:45,396 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:15:55,398 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:15:55,398 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:05,400 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:16:05,401 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:15,402 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:16:15,403 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:25,631 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-11 00:16:26,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.129.40.100:8020. Already tried 0 time(s).
2016-09-11 00:16:27,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/10.129.40.100:8020. Already tried 1 time(s).
2016-09-11 00:16:27,406 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
java.io.IOException: Call to master/10.129.40.100:8020 failed on local exception: java.io.IOException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:940)
	at org.apache.hadoop.ipc.Client.call(Client.java:908)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:850)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:620)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1525)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
Caused by: java.io.IOException
	at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:571)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:601)
Caused by: java.lang.InterruptedException
	... 2 more
2016-09-11 00:16:30,345 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 00:16:30,409 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 00:16:30,412 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 00:16:30,412 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:16:30,413 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 00:16:30,413 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 00:16:30,413 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 00:16:30,413 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 00:16:30,419 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 00:16:30,429 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 00:16:30,432 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:30,435 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:16:30,436 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:30,437 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 00:16:30,456 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 00:16:30,479 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 00:16:30,481 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 00:16:30,489 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 00:16:30,489 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 00:16:30,489 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 00:16:30,489 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 00:16:30,608 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 00:16:30,608 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 00:16:30,609 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:30,609 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:30,609 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 00:16:30,609 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 00:16:30,633 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 00:16:30,685 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:16:30,687 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:40,693 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:16:40,696 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:16:50,702 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:16:50,705 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:17:00,710 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:17:00,712 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:17:10,716 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:17:10,719 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:17:20,722 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:17:20,738 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:17:30,744 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:17:30,748 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:17:40,751 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:17:40,752 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:17:50,757 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:17:50,760 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:18:00,763 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:18:00,765 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:18:10,767 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:18:10,768 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:18:20,770 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:18:20,772 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:18:30,777 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:18:30,780 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:18:40,783 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:18:40,784 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:18:50,786 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:18:50,786 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:19:00,789 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:19:00,791 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:19:10,793 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:19:10,794 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:19:20,798 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:19:20,802 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:19:30,806 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:19:30,808 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:19:40,810 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:19:40,811 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:19:50,813 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:19:50,814 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:20:00,817 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:20:00,819 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:20:10,821 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:20:10,822 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:20:20,826 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:20:20,828 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:20:30,830 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:20:30,831 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:20:40,835 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:20:40,836 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:20:50,841 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:20:50,843 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:21:00,847 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:21:00,850 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:21:10,854 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:21:10,857 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:21:20,861 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:21:20,863 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:21:30,867 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:21:30,870 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:21:40,874 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:21:40,878 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:21:50,880 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:21:50,881 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:22:00,885 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:22:00,887 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:22:10,889 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:22:10,889 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:22:20,893 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:22:20,895 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:22:30,899 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:22:30,902 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:22:40,904 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:22:40,906 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:22:50,909 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:22:50,911 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:23:00,915 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:23:00,917 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:23:10,920 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:23:10,922 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:23:20,925 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:23:20,927 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:23:30,931 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:23:30,933 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:23:40,935 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:23:40,936 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:23:50,940 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:23:50,942 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:24:00,945 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:24:00,947 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:24:10,950 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:24:10,952 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:24:20,954 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:24:20,956 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:24:30,958 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:24:30,958 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:24:40,962 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:24:40,964 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:24:50,968 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:24:50,971 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:25:00,973 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:25:00,974 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:25:10,978 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:25:10,980 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:25:20,982 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:25:20,983 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:25:30,986 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:25:30,988 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:25:40,992 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:25:40,994 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:25:50,998 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:25:51,000 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:26:01,001 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:26:01,002 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:26:11,006 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:26:11,008 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:26:21,012 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:26:21,014 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:26:31,018 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:26:31,020 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:26:41,024 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:26:41,027 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:26:51,031 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:26:51,034 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:27:01,035 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:27:01,036 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:27:11,038 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:27:11,039 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:27:21,041 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:27:21,043 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:27:31,047 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:27:31,049 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:27:41,053 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:27:41,055 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:27:51,059 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:27:51,061 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:28:01,065 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:28:01,067 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:28:11,069 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:28:11,070 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:28:21,072 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:28:21,072 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:28:31,074 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:28:31,075 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:28:41,076 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:28:41,077 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:28:51,079 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:28:51,080 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:29:01,081 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:29:01,082 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:29:11,083 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:29:11,084 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:29:21,085 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:29:21,086 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:29:31,089 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:29:31,090 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:29:41,095 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:29:41,098 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:29:51,104 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:29:51,106 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:30:01,108 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:30:01,109 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:30:11,110 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:30:11,111 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:30:21,112 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:30:21,113 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:30:31,115 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:30:31,115 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:30:41,117 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:30:41,118 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:30:51,119 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:30:51,120 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:31:01,121 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:31:01,122 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:31:11,125 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:31:11,126 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:31:21,129 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:31:21,131 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:31:31,134 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:31:31,137 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:31:41,138 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:31:41,139 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:31:51,140 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:31:51,141 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:32:01,144 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:32:01,147 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:32:11,149 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:32:11,150 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:32:21,153 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:32:21,156 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:32:31,159 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:32:31,160 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:32:41,162 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:32:41,162 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:32:51,164 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:32:51,166 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:33:01,169 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:33:01,171 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:33:11,173 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:33:11,173 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:33:21,175 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:33:21,176 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:33:31,177 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:33:31,178 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:33:41,181 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:33:41,184 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:33:51,187 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:33:51,189 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:34:01,190 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:34:01,191 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:34:11,193 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:34:11,193 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:34:21,194 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:34:21,195 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1099 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 1148. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 00:34:31,199 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 00:34:31,347 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-11 00:34:31,347 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-11 00:34:31,348 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-11 00:34:31,350 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032045_0001_hduser.201609032111.old
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032116_0002_conf.xml
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032045_0001_conf.xml.201609032111.old
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032116_0001_conf.xml
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032116_0001_hduser
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032008_0001_conf.xml.201609032045.old
2016-09-11 00:34:31,447 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032111_0001_conf.xml.201609032116.old
2016-09-11 00:34:31,448 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032008_0001_hduser.201609032045.old
2016-09-11 00:34:31,448 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032111_0001_hduser.201609032116.old
2016-09-11 00:34:31,448 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609032116_0002_hduser
2016-09-11 00:34:31,659 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-11 00:34:31,666 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-11 00:34:31,666 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-11 00:34:31,666 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 00:34:31,666 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-11 00:34:31,667 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-11 00:34:31,668 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-11 00:34:31,668 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-11 00:34:31,668 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-11 00:34:31,668 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-11 00:34:31,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-11 00:34:31,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-11 00:34:31,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-11 00:34:31,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-11 00:34:31,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-11 00:34:31,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-11 00:34:31,673 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-11 00:34:31,673 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-11 00:34:31,772 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-11 00:34:31,773 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:38550 to host slave2
2016-09-11 00:34:31,793 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-11 00:34:31,793 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:46686 to host slave5
2016-09-11 00:34:31,794 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-11 00:34:31,794 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:36138 to host slave1
2016-09-11 00:34:31,796 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-11 00:34:31,796 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:34048 to host slave3
2016-09-11 00:34:32,822 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-11 00:34:32,822 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:36115 to host slave4
2016-09-11 00:58:01,373 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-11 00:58:01,443 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609110016_0001 added successfully for user 'hduser' to queue 'default'
2016-09-11 00:58:01,443 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609110016_0001
2016-09-11 00:58:01,444 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609110016_0001
2016-09-11 00:58:01,475 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609110016_0001_hduser
2016-09-11 00:58:01,628 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609110016_0001_conf.xml
2016-09-11 00:58:01,684 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609110016_0001/jobToken
2016-09-11 00:58:01,708 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609110016_0001 = 0. Number of splits = 2
2016-09-11 00:58:01,709 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609110016_0001 initialized successfully with 2 map tasks and 0 reduce tasks.
2016-09-11 00:58:02,626 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609110016_0001_m_000003_0' to tip task_201609110016_0001_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36138'
2016-09-11 01:01:11,669 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110016_0001_m_000003_0 is 189041 ms debug.
2016-09-11 01:04:31,669 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110016_0001_m_000003_0 is 389042 ms debug.
2016-09-11 01:07:51,669 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110016_0001_m_000003_0 is 589042 ms debug.
2016-09-11 01:11:11,669 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36138'
2016-09-11 01:11:11,670 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609110016_0001_m_000003_0 on tracker_slave1:127.0.0.1/127.0.0.1:36138: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36138
2016-09-11 01:11:11,682 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110016_0001_m_000003_0'
2016-09-11 01:11:11,683 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110016_0001_m_000003_0 is 789042 ms debug.
2016-09-11 01:11:11,684 INFO org.apache.hadoop.mapred.JobTracker: Launching task attempt_201609110016_0001_m_000003_0 timed out.
2016-09-11 01:11:12,006 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609110016_0001_m_000003_1' to tip task_201609110016_0001_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34048'
2016-09-11 01:11:15,062 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110016_0001_m_000003_1' has completed task_201609110016_0001_m_000003 successfully.
2016-09-11 01:11:15,107 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609110016_0001_m_000000
2016-09-11 01:11:15,108 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110016_0001_m_000000_0' to tip task_201609110016_0001_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34048'
2016-09-11 01:11:15,389 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609110016_0001_m_000001
2016-09-11 01:11:15,390 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110016_0001_m_000001_0' to tip task_201609110016_0001_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:38550'
2016-09-11 01:12:15,906 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609110016_0001_m_000001 for speculative execution
2016-09-11 01:12:15,907 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110016_0001_m_000001_1' to tip task_201609110016_0001_m_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46686'
2016-09-11 01:21:22,390 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110016_0001_m_000000_0' has completed task_201609110016_0001_m_000000 successfully.
2016-09-11 01:23:34,083 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110016_0001_m_000001_1' has completed task_201609110016_0001_m_000001 successfully.
2016-09-11 01:23:34,089 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609110016_0001_m_000002_0' to tip task_201609110016_0001_m_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46686'
2016-09-11 01:23:40,097 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110016_0001_m_000002_0' has completed task_201609110016_0001_m_000002 successfully.
2016-09-11 01:23:40,100 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609110016_0001 has completed successfully.
2016-09-11 01:23:40,102 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609110016_0001,submitTime=1473535681321,launchTime=1473535681709,finishTime=1473537220100,numMaps=2,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=1285,reduceSlotsSeconds=0,clusterMapCapacity=20,clusterReduceCapacity=8
2016-09-11 01:23:40,180 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609110016_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609110016_0001_hduser
2016-09-11 01:23:40,182 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110016_0001_m_000001_1'
2016-09-11 01:23:40,182 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110016_0001_m_000002_0'
2016-09-11 01:23:40,183 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110016_0001_m_000001_0'
2016-09-11 01:23:40,186 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609110016_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609110016_0001_conf.xml
2016-09-11 01:23:40,190 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609110016_0001_conf.xml
2016-09-11 01:23:40,190 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110016_0001_m_000000_0'
2016-09-11 01:23:40,190 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110016_0001_m_000003_1'
2016-09-11 01:23:40,190 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609110016_0001' of user 'hduser'
2016-09-11 01:54:31,686 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36115'
2016-09-11 01:54:31,687 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave2:127.0.0.1/127.0.0.1:38550'
2016-09-11 01:54:31,687 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46686'
2016-09-11 01:54:31,688 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34048'
2016-09-11 02:03:16,476 WARN org.apache.hadoop.mapred.JobTracker: Status from unknown Tracker : tracker_slave4:127.0.0.1/127.0.0.1:36115
2016-09-11 02:03:16,476 WARN org.apache.hadoop.mapred.JobTracker: Status from unknown Tracker : tracker_slave5:127.0.0.1/127.0.0.1:46686
2016-09-11 02:03:16,497 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:46686 to host slave5
2016-09-11 02:03:16,649 WARN org.apache.hadoop.mapred.JobTracker: Status from unknown Tracker : tracker_slave2:127.0.0.1/127.0.0.1:38550
2016-09-11 02:03:16,684 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:38550 to host slave2
2016-09-11 02:03:16,719 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:36115 to host slave4
2016-09-11 02:03:17,037 WARN org.apache.hadoop.mapred.JobTracker: Status from unknown Tracker : tracker_slave3:127.0.0.1/127.0.0.1:34048
2016-09-11 02:03:17,097 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:34048 to host slave3
2016-09-11 02:10:17,519 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-11 02:10:22,534 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 02:10:22,603 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 02:10:22,606 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 02:10:22,606 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 02:10:22,607 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 02:10:22,607 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 02:10:22,607 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 02:10:22,607 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 02:10:22,613 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 02:10:22,623 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 02:10:22,626 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:22,629 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 02:10:22,631 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:22,631 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 02:10:22,651 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 02:10:22,674 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 02:10:22,676 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 02:10:22,684 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 02:10:22,684 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 02:10:22,684 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 02:10:22,684 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 02:10:22,808 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 02:10:22,809 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 02:10:22,809 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:22,810 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:22,810 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 02:10:22,810 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 02:10:22,840 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 02:10:22,907 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 02:10:22,908 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 0 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 211. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:32,911 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 02:10:32,913 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 211 has reached the threshold 0.9990 of total blocks 211. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:42,918 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 02:10:42,921 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 211 has reached the threshold 0.9990 of total blocks 211. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:10:52,927 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 02:10:52,930 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 211 has reached the threshold 0.9990 of total blocks 211. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 02:11:02,932 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 02:11:03,014 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-11 02:11:03,015 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-11 02:11:03,016 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-11 02:11:03,018 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-11 02:11:03,228 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-11 02:11:03,235 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-11 02:11:03,235 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-11 02:11:03,235 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 02:11:03,235 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-11 02:11:03,236 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-11 02:11:03,236 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-11 02:11:03,240 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-11 02:11:03,241 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-11 02:11:03,241 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-11 02:11:03,241 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-11 02:11:03,241 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-11 02:11:03,245 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-11 02:11:03,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-11 02:11:03,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-11 02:11:03,256 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-11 02:11:03,256 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-11 02:11:03,256 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-11 02:11:03,367 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-11 02:11:03,368 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:45024 to host slave4
2016-09-11 02:11:03,387 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-11 02:11:03,387 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:41981 to host slave3
2016-09-11 02:11:03,408 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-11 02:11:03,408 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:44801 to host slave1
2016-09-11 02:11:03,419 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-11 02:11:03,419 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:45459 to host slave5
2016-09-11 02:11:03,428 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-11 02:11:03,428 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:44415 to host slave2
2016-09-11 02:11:09,762 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-11 02:11:09,843 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609110210_0001 added successfully for user 'hduser' to queue 'default'
2016-09-11 02:11:09,844 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609110210_0001
2016-09-11 02:11:09,844 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609110210_0001
2016-09-11 02:11:09,878 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609110210_0001_hduser
2016-09-11 02:11:09,953 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609110210_0001_conf.xml
2016-09-11 02:11:10,002 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609110210_0001/jobToken
2016-09-11 02:11:10,012 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609110210_0001 = 10000000000. Number of splits = 38
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000000 has split on node:/default-rack/slave4
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000001 has split on node:/default-rack/slave4
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000002 has split on node:/default-rack/slave4
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000003 has split on node:/default-rack/slave2
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000004 has split on node:/default-rack/slave2
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000005 has split on node:/default-rack/slave4
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000006 has split on node:/default-rack/slave2
2016-09-11 02:11:10,013 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000007 has split on node:/default-rack/slave2
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000008 has split on node:/default-rack/slave4
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000009 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000010 has split on node:/default-rack/slave2
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000011 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000012 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000013 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000014 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000015 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000016 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000017 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000018 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000019 has split on node:/default-rack/slave4
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000019 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000019 has split on node:/default-rack/slave2
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000020 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000020 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000020 has split on node:/default-rack/slave2
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000021 has split on node:/default-rack/slave2
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000021 has split on node:/default-rack/slave5
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000021 has split on node:/default-rack/slave3
2016-09-11 02:11:10,014 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000022 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000022 has split on node:/default-rack/slave3
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000022 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000023 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000023 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000023 has split on node:/default-rack/slave2
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000024 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000024 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000024 has split on node:/default-rack/slave2
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000025 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000025 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000025 has split on node:/default-rack/slave2
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000026 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000026 has split on node:/default-rack/slave3
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000026 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000027 has split on node:/default-rack/slave2
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000027 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000027 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000028 has split on node:/default-rack/slave4
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000028 has split on node:/default-rack/slave5
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000028 has split on node:/default-rack/slave2
2016-09-11 02:11:10,015 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000029 has split on node:/default-rack/slave5
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000029 has split on node:/default-rack/slave3
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000029 has split on node:/default-rack/slave4
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000030 has split on node:/default-rack/slave5
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000030 has split on node:/default-rack/slave3
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000030 has split on node:/default-rack/slave4
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000031 has split on node:/default-rack/slave2
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000031 has split on node:/default-rack/slave5
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000031 has split on node:/default-rack/slave3
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000032 has split on node:/default-rack/slave3
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000032 has split on node:/default-rack/slave4
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000032 has split on node:/default-rack/slave5
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000033 has split on node:/default-rack/slave2
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000033 has split on node:/default-rack/slave5
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000033 has split on node:/default-rack/slave3
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000034 has split on node:/default-rack/slave2
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000034 has split on node:/default-rack/slave5
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000034 has split on node:/default-rack/slave4
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000035 has split on node:/default-rack/slave2
2016-09-11 02:11:10,016 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000035 has split on node:/default-rack/slave5
2016-09-11 02:11:10,017 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000035 has split on node:/default-rack/slave3
2016-09-11 02:11:10,017 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000036 has split on node:/default-rack/slave5
2016-09-11 02:11:10,017 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000037 has split on node:/default-rack/slave4
2016-09-11 02:11:10,017 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000037 has split on node:/default-rack/slave5
2016-09-11 02:11:10,017 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609110210_0001_m_000037 has split on node:/default-rack/slave2
2016-09-11 02:11:10,018 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609110210_0001 initialized successfully with 38 map tasks and 1 reduce tasks.
2016-09-11 02:11:12,394 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609110210_0001_m_000039_0' to tip task_201609110210_0001_m_000039, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:15,458 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000039_0' has completed task_201609110210_0001_m_000039 successfully.
2016-09-11 02:11:15,464 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000000_0' to tip task_201609110210_0001_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000000
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000001_0' to tip task_201609110210_0001_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000001
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000002_0' to tip task_201609110210_0001_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000002
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000005_0' to tip task_201609110210_0001_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000005
2016-09-11 02:11:15,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000008_0' to tip task_201609110210_0001_m_000008, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:15,467 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000008
2016-09-11 02:11:18,404 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000009_0' to tip task_201609110210_0001_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41981'
2016-09-11 02:11:18,404 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000009
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000013_0' to tip task_201609110210_0001_m_000013, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41981'
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000013
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000014_0' to tip task_201609110210_0001_m_000014, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41981'
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000014
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000015_0' to tip task_201609110210_0001_m_000015, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41981'
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000015
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000017_0' to tip task_201609110210_0001_m_000017, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41981'
2016-09-11 02:11:18,405 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000017
2016-09-11 02:11:18,423 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000003_0' to tip task_201609110210_0001_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:11:18,423 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000003
2016-09-11 02:11:18,423 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000004_0' to tip task_201609110210_0001_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000004
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000006_0' to tip task_201609110210_0001_m_000006, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000006
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000007_0' to tip task_201609110210_0001_m_000007, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000007
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000010_0' to tip task_201609110210_0001_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:11:18,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000010
2016-09-11 02:11:18,441 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000011_0' to tip task_201609110210_0001_m_000011, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000011
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000012_0' to tip task_201609110210_0001_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000012
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000016_0' to tip task_201609110210_0001_m_000016, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000016
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000018_0' to tip task_201609110210_0001_m_000018, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000018
2016-09-11 02:11:18,442 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000019_0' to tip task_201609110210_0001_m_000019, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:11:18,443 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000019
2016-09-11 02:11:18,446 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000020_0' to tip task_201609110210_0001_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000020
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000021_0' to tip task_201609110210_0001_m_000021, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000021
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000023_0' to tip task_201609110210_0001_m_000023, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000023
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000024_0' to tip task_201609110210_0001_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000024
2016-09-11 02:11:18,447 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000025_0' to tip task_201609110210_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:11:18,448 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000025
2016-09-11 02:11:57,474 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000001_0' has completed task_201609110210_0001_m_000001 successfully.
2016-09-11 02:11:57,477 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000022_0' to tip task_201609110210_0001_m_000022, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:11:57,477 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000022
2016-09-11 02:12:00,691 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000008_0' has completed task_201609110210_0001_m_000008 successfully.
2016-09-11 02:12:00,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000026_0' to tip task_201609110210_0001_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:12:00,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000026
2016-09-11 02:12:00,701 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609110210_0001_r_000000_0' to tip task_201609110210_0001_r_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:12:03,986 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000024_0' has completed task_201609110210_0001_m_000024 successfully.
2016-09-11 02:12:03,991 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000027_0' to tip task_201609110210_0001_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:12:03,991 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000027
2016-09-11 02:12:05,503 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000005_0' has completed task_201609110210_0001_m_000005 successfully.
2016-09-11 02:12:05,505 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000028_0' to tip task_201609110210_0001_m_000028, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:12:05,505 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000028
2016-09-11 02:12:07,000 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000021_0' has completed task_201609110210_0001_m_000021 successfully.
2016-09-11 02:12:07,001 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000031_0' to tip task_201609110210_0001_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:12:07,001 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000031
2016-09-11 02:12:10,294 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000025_0' has completed task_201609110210_0001_m_000025 successfully.
2016-09-11 02:12:10,295 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000033_0' to tip task_201609110210_0001_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:12:10,296 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000033
2016-09-11 02:12:12,121 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000000_0' has completed task_201609110210_0001_m_000000 successfully.
2016-09-11 02:12:12,122 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000002_0' has completed task_201609110210_0001_m_000002 successfully.
2016-09-11 02:12:12,123 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000029_0' to tip task_201609110210_0001_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:12:12,123 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000029
2016-09-11 02:12:12,123 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000030_0' to tip task_201609110210_0001_m_000030, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:12:12,123 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000030
2016-09-11 02:12:16,694 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000023_0' has completed task_201609110210_0001_m_000023 successfully.
2016-09-11 02:12:16,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000034_0' to tip task_201609110210_0001_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:12:16,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000034
2016-09-11 02:12:17,792 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000012_0' has completed task_201609110210_0001_m_000012 successfully.
2016-09-11 02:12:17,793 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000019_0' has completed task_201609110210_0001_m_000019 successfully.
2016-09-11 02:12:17,794 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000032_0' to tip task_201609110210_0001_m_000032, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:12:17,794 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000032
2016-09-11 02:12:17,794 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000035_0' to tip task_201609110210_0001_m_000035, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 02:12:17,794 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000035
2016-09-11 02:12:19,700 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000020_0' has completed task_201609110210_0001_m_000020 successfully.
2016-09-11 02:12:19,710 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000037_0' to tip task_201609110210_0001_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:12:19,710 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000037
2016-09-11 02:12:21,550 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000004_0' has completed task_201609110210_0001_m_000004 successfully.
2016-09-11 02:12:21,552 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000036_0' to tip task_201609110210_0001_m_000036, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:12:21,552 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000036
2016-09-11 02:12:34,911 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000009_0' has completed task_201609110210_0001_m_000009 successfully.
2016-09-11 02:12:34,914 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000013_0' has completed task_201609110210_0001_m_000013 successfully.
2016-09-11 02:12:34,917 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000015_0' has completed task_201609110210_0001_m_000015 successfully.
2016-09-11 02:12:34,918 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000017_0' has completed task_201609110210_0001_m_000017 successfully.
2016-09-11 02:12:37,929 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000014_0' has completed task_201609110210_0001_m_000014 successfully.
2016-09-11 02:12:43,737 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000031_0' has completed task_201609110210_0001_m_000031 successfully.
2016-09-11 02:12:52,751 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000027_0' has completed task_201609110210_0001_m_000027 successfully.
2016-09-11 02:12:56,023 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000037_0' has completed task_201609110210_0001_m_000037 successfully.
2016-09-11 02:12:59,026 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609110210_0001_m_000022 for speculative execution
2016-09-11 02:12:59,028 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000022_1' to tip task_201609110210_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:12:59,028 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000022
2016-09-11 02:13:02,031 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000033_0' has completed task_201609110210_0001_m_000033 successfully.
2016-09-11 02:13:02,031 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000034_0' has completed task_201609110210_0001_m_000034 successfully.
2016-09-11 02:13:02,032 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609110210_0001_m_000026 for speculative execution
2016-09-11 02:13:02,033 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000026_1' to tip task_201609110210_0001_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:13:02,033 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000026
2016-09-11 02:13:02,033 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609110210_0001_r_000000 for speculative execution
2016-09-11 02:13:02,033 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609110210_0001_r_000000_1' to tip task_201609110210_0001_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:13:05,038 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609110210_0001_m_000003 for speculative execution
2016-09-11 02:13:05,039 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000003_1' to tip task_201609110210_0001_m_000003, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:13:05,039 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609110210_0001_m_000003
2016-09-11 02:13:17,049 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000022_1' has completed task_201609110210_0001_m_000022 successfully.
2016-09-11 02:13:17,050 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609110210_0001_m_000030 for speculative execution
2016-09-11 02:13:17,050 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000030_1' to tip task_201609110210_0001_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:13:17,050 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000030
2016-09-11 02:13:20,054 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000026_1' has completed task_201609110210_0001_m_000026 successfully.
2016-09-11 02:13:20,055 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609110210_0001_m_000032 for speculative execution
2016-09-11 02:13:20,055 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609110210_0001_m_000032_1' to tip task_201609110210_0001_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:44415'
2016-09-11 02:13:20,055 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609110210_0001_m_000032
2016-09-11 02:13:24,815 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609110210_0001
2016-09-11 02:13:24,816 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609110210_0001'
2016-09-11 02:13:25,476 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609110210_0001_m_000038_0' to tip task_201609110210_0001_m_000038, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:45024'
2016-09-11 02:13:25,476 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000022_0'
2016-09-11 02:13:31,164 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000026_0'
2016-09-11 02:13:33,971 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000003_1'
2016-09-11 02:13:36,317 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000028_0'
2016-09-11 02:13:46,972 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000029_0'
2016-09-11 02:13:46,972 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000030_0'
2016-09-11 02:13:49,324 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000030_1'
2016-09-11 02:13:49,324 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000032_1'
2016-09-11 02:13:49,324 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_r_000000_1'
2016-09-11 02:13:54,982 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609110210_0001_m_000038_0' has completed task_201609110210_0001_m_000038 successfully.
2016-09-11 02:13:54,983 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609110210_0001,submitTime=1473540069732,launchTime=1473540070017,finishTime=1473540234983,numMaps=38,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=KILLED,mapSlotSeconds=1825,reduceSlotsSeconds=156,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 02:13:55,003 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2016-09-11 02:13:55,003 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-4636516231986958085_7088
2016-09-11 02:13:55,004 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.101:50010
2016-09-11 02:13:55,026 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609110210_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609110210_0001_hduser
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000000_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000001_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000002_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000005_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000008_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000038_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000039_0'
2016-09-11 02:13:55,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_r_000000_0'
2016-09-11 02:13:55,055 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609110210_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609110210_0001_conf.xml
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609110210_0001_conf.xml
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000003_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000004_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000006_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000007_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000009_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000010_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000011_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000012_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000013_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000014_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000015_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000016_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000017_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000018_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000019_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000020_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000021_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000022_1'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000023_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000024_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000025_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000026_1'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000027_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000031_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000032_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000033_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000034_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000035_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000036_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609110210_0001_m_000037_0'
2016-09-11 02:13:55,059 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609110210_0001' of user 'hduser'
2016-09-11 02:14:23,236 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110210_0001_m_000036_0 is 121684 ms debug.
2016-09-11 02:17:43,236 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110210_0001_m_000036_0 is 321684 ms debug.
2016-09-11 02:21:03,237 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110210_0001_m_000036_0 is 521685 ms debug.
2016-09-11 02:24:23,237 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609110210_0001_m_000036_0 is 721685 ms debug.
2016-09-11 02:24:23,237 INFO org.apache.hadoop.mapred.JobTracker: Launching task attempt_201609110210_0001_m_000036_0 timed out.
2016-09-11 02:24:23,245 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44801'
2016-09-11 02:24:23,246 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:45459'
2016-09-11 03:11:03,241 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609110016_0001.info]
2016-09-11 04:11:03,295 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609110210_0001.info]
2016-09-11 18:06:50,824 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-11 18:06:55,726 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-11 18:06:55,790 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-11 18:06:55,793 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-11 18:06:55,793 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 18:06:55,794 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-11 18:06:55,794 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-11 18:06:55,794 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-11 18:06:55,795 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 18:06:55,800 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-11 18:06:55,810 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-11 18:06:55,813 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:06:55,816 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 18:06:55,818 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:06:55,818 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-11 18:06:55,838 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-11 18:06:55,860 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-11 18:06:55,862 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-11 18:06:55,872 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-11 18:06:55,872 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-11 18:06:55,872 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-11 18:06:55,873 INFO org.mortbay.log: jetty-6.1.14
2016-09-11 18:06:56,002 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-11 18:06:56,003 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-11 18:06:56,003 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:06:56,004 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:06:56,004 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-11 18:06:56,004 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-11 18:06:56,029 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-11 18:06:56,090 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 18:06:56,092 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 210 has reached the threshold 0.9990 of total blocks 210. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:07:06,096 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 18:07:06,099 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 210 has reached the threshold 0.9990 of total blocks 210. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:07:16,104 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 18:07:16,107 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 210 has reached the threshold 0.9990 of total blocks 210. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-11 18:07:26,113 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-11 18:07:26,194 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-11 18:07:26,196 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-11 18:07:26,199 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-11 18:07:26,203 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-11 18:07:26,351 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-11 18:07:26,359 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-11 18:07:26,359 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-11 18:07:26,359 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-11 18:07:26,359 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-11 18:07:26,361 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-11 18:07:26,362 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-11 18:07:26,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-11 18:07:26,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-11 18:07:26,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-11 18:07:26,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-11 18:07:26,368 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-11 18:07:26,372 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-11 18:07:26,369 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-11 18:07:26,376 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-11 18:07:26,377 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-11 18:07:26,377 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-11 18:07:26,378 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-11 18:07:26,474 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-11 18:07:26,474 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:39212 to host slave1
2016-09-11 18:07:26,476 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-11 18:07:26,477 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:37567 to host slave3
2016-09-11 18:07:26,498 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-11 18:07:26,498 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:34280 to host slave4
2016-09-11 18:07:26,514 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-11 18:07:26,514 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:33185 to host slave5
2016-09-11 18:07:26,525 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-11 18:07:26,525 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:34871 to host slave2
2016-09-11 18:08:03,335 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-11 18:08:03,421 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0001 added successfully for user 'hduser' to queue 'default'
2016-09-11 18:08:03,421 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0001
2016-09-11 18:08:03,421 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0001
2016-09-11 18:08:03,456 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0001_hduser
2016-09-11 18:08:03,530 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0001_conf.xml
2016-09-11 18:08:03,578 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0001/jobToken
2016-09-11 18:08:03,588 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0001 = 10000000000. Number of splits = 38
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000000 has split on node:/default-rack/slave2
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000001 has split on node:/default-rack/slave2
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000002 has split on node:/default-rack/slave2
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000003 has split on node:/default-rack/slave5
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000004 has split on node:/default-rack/slave5
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000005 has split on node:/default-rack/slave2
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000006 has split on node:/default-rack/slave5
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000007 has split on node:/default-rack/slave5
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000008 has split on node:/default-rack/slave2
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000009 has split on node:/default-rack/slave5
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000010 has split on node:/default-rack/slave4
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000011 has split on node:/default-rack/slave4
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000012 has split on node:/default-rack/slave4
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000013 has split on node:/default-rack/slave4
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000014 has split on node:/default-rack/slave4
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000015 has split on node:/default-rack/slave3
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000016 has split on node:/default-rack/slave3
2016-09-11 18:08:03,589 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000017 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000018 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000019 has split on node:/default-rack/slave5
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000019 has split on node:/default-rack/slave4
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000019 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000019 has split on node:/default-rack/slave2
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000020 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000020 has split on node:/default-rack/slave4
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000020 has split on node:/default-rack/slave5
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000020 has split on node:/default-rack/slave2
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000021 has split on node:/default-rack/slave5
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000021 has split on node:/default-rack/slave4
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000021 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000021 has split on node:/default-rack/slave2
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000022 has split on node:/default-rack/slave4
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000022 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000022 has split on node:/default-rack/slave5
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000022 has split on node:/default-rack/slave2
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000023 has split on node:/default-rack/slave2
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000023 has split on node:/default-rack/slave4
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000023 has split on node:/default-rack/slave5
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000023 has split on node:/default-rack/slave3
2016-09-11 18:08:03,590 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000024 has split on node:/default-rack/slave4
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000024 has split on node:/default-rack/slave3
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000024 has split on node:/default-rack/slave5
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000024 has split on node:/default-rack/slave2
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000025 has split on node:/default-rack/slave3
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000025 has split on node:/default-rack/slave4
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000025 has split on node:/default-rack/slave5
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000025 has split on node:/default-rack/slave2
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000026 has split on node:/default-rack/slave5
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000026 has split on node:/default-rack/slave4
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000026 has split on node:/default-rack/slave3
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000026 has split on node:/default-rack/slave2
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000027 has split on node:/default-rack/slave4
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000027 has split on node:/default-rack/slave3
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000027 has split on node:/default-rack/slave5
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000027 has split on node:/default-rack/slave2
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000028 has split on node:/default-rack/slave5
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000028 has split on node:/default-rack/slave4
2016-09-11 18:08:03,591 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000028 has split on node:/default-rack/slave3
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000028 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000029 has split on node:/default-rack/slave5
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000029 has split on node:/default-rack/slave4
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000029 has split on node:/default-rack/slave3
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000029 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000030 has split on node:/default-rack/slave3
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000030 has split on node:/default-rack/slave4
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000030 has split on node:/default-rack/slave5
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000030 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000031 has split on node:/default-rack/slave5
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000031 has split on node:/default-rack/slave4
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000031 has split on node:/default-rack/slave3
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000031 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000032 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000032 has split on node:/default-rack/slave4
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000032 has split on node:/default-rack/slave5
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000032 has split on node:/default-rack/slave3
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000033 has split on node:/default-rack/slave4
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000033 has split on node:/default-rack/slave3
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000033 has split on node:/default-rack/slave5
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000033 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000034 has split on node:/default-rack/slave2
2016-09-11 18:08:03,592 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000034 has split on node:/default-rack/slave4
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000034 has split on node:/default-rack/slave5
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000034 has split on node:/default-rack/slave3
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000035 has split on node:/default-rack/slave3
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000035 has split on node:/default-rack/slave4
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000035 has split on node:/default-rack/slave5
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000035 has split on node:/default-rack/slave2
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000036 has split on node:/default-rack/slave3
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000037 has split on node:/default-rack/slave5
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000037 has split on node:/default-rack/slave4
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000037 has split on node:/default-rack/slave3
2016-09-11 18:08:03,593 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0001_m_000037 has split on node:/default-rack/slave2
2016-09-11 18:08:03,594 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0001 initialized successfully with 38 map tasks and 1 reduce tasks.
2016-09-11 18:08:05,527 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0001_m_000039_0' to tip task_201609111806_0001_m_000039, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:08,557 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000039_0' has completed task_201609111806_0001_m_000039 successfully.
2016-09-11 18:08:08,572 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000000_0' to tip task_201609111806_0001_m_000000, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:08,576 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000000
2016-09-11 18:08:08,576 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000001_0' to tip task_201609111806_0001_m_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:08,576 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000001
2016-09-11 18:08:08,576 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000002_0' to tip task_201609111806_0001_m_000002, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:08,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000002
2016-09-11 18:08:08,577 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000003_0' to tip task_201609111806_0001_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:08,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000003
2016-09-11 18:08:08,577 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000004_0' to tip task_201609111806_0001_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:08,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000004
2016-09-11 18:08:08,578 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000006_0' to tip task_201609111806_0001_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:08:08,579 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000006
2016-09-11 18:08:08,579 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000007_0' to tip task_201609111806_0001_m_000007, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:08:08,580 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000007
2016-09-11 18:08:08,580 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000009_0' to tip task_201609111806_0001_m_000009, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:08:08,580 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000009
2016-09-11 18:08:08,580 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000019_0' to tip task_201609111806_0001_m_000019, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:08:08,581 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000019
2016-09-11 18:08:08,581 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000020_0' to tip task_201609111806_0001_m_000020, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:08:08,581 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000020
2016-09-11 18:08:08,582 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000005_0' to tip task_201609111806_0001_m_000005, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:08,582 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000005
2016-09-11 18:08:08,582 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000008_0' to tip task_201609111806_0001_m_000008, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:08,582 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000008
2016-09-11 18:08:08,583 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000021_0' to tip task_201609111806_0001_m_000021, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:08,583 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000021
2016-09-11 18:08:08,583 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000022_0' to tip task_201609111806_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:08,583 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000022
2016-09-11 18:08:08,583 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000023_0' to tip task_201609111806_0001_m_000023, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:08,584 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000023
2016-09-11 18:08:08,584 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000010_0' to tip task_201609111806_0001_m_000010, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:08,584 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000010
2016-09-11 18:08:08,584 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000011_0' to tip task_201609111806_0001_m_000011, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:08,584 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000011
2016-09-11 18:08:08,584 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000012_0' to tip task_201609111806_0001_m_000012, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:08,585 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000012
2016-09-11 18:08:08,585 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000013_0' to tip task_201609111806_0001_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:08,585 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000013
2016-09-11 18:08:08,585 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000014_0' to tip task_201609111806_0001_m_000014, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:08,585 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000014
2016-09-11 18:08:11,589 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000015_0' to tip task_201609111806_0001_m_000015, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:08:11,590 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000015
2016-09-11 18:08:11,590 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000016_0' to tip task_201609111806_0001_m_000016, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:08:11,590 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000016
2016-09-11 18:08:11,590 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000017_0' to tip task_201609111806_0001_m_000017, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:08:11,590 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000017
2016-09-11 18:08:11,590 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000018_0' to tip task_201609111806_0001_m_000018, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:08:11,591 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000018
2016-09-11 18:08:11,591 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000024_0' to tip task_201609111806_0001_m_000024, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:08:11,591 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000024
2016-09-11 18:08:26,662 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000005_0' has completed task_201609111806_0001_m_000005 successfully.
2016-09-11 18:08:26,664 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000008_0' has completed task_201609111806_0001_m_000008 successfully.
2016-09-11 18:08:26,665 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000025_0' to tip task_201609111806_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:26,665 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000025
2016-09-11 18:08:26,665 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000026_0' to tip task_201609111806_0001_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:26,666 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000026
2016-09-11 18:08:26,667 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0001_r_000000_0' to tip task_201609111806_0001_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:08:34,680 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000014_0' has completed task_201609111806_0001_m_000014 successfully.
2016-09-11 18:08:34,682 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000027_0' to tip task_201609111806_0001_m_000027, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:34,682 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000027
2016-09-11 18:08:37,099 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000002_0' has completed task_201609111806_0001_m_000002 successfully.
2016-09-11 18:08:37,103 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000028_0' to tip task_201609111806_0001_m_000028, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:37,103 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000028
2016-09-11 18:08:42,274 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000024_0' has completed task_201609111806_0001_m_000024 successfully.
2016-09-11 18:08:42,276 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000029_0' to tip task_201609111806_0001_m_000029, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:08:42,276 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000029
2016-09-11 18:08:50,723 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000001_0' has completed task_201609111806_0001_m_000001 successfully.
2016-09-11 18:08:50,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000030_0' to tip task_201609111806_0001_m_000030, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:50,724 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000030
2016-09-11 18:08:52,703 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000027_0' has completed task_201609111806_0001_m_000027 successfully.
2016-09-11 18:08:52,705 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000031_0' to tip task_201609111806_0001_m_000031, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:08:52,705 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000031
2016-09-11 18:08:57,898 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000000_0' has completed task_201609111806_0001_m_000000 successfully.
2016-09-11 18:08:57,899 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000032_0' to tip task_201609111806_0001_m_000032, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:08:57,899 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000032
2016-09-11 18:09:07,202 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000019_0' has completed task_201609111806_0001_m_000019 successfully.
2016-09-11 18:09:07,203 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000020_0' has completed task_201609111806_0001_m_000020 successfully.
2016-09-11 18:09:07,203 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000033_0' to tip task_201609111806_0001_m_000033, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:09:07,203 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000033
2016-09-11 18:09:07,204 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000034_0' to tip task_201609111806_0001_m_000034, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:09:07,204 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000034
2016-09-11 18:09:13,727 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000010_0' has completed task_201609111806_0001_m_000010 successfully.
2016-09-11 18:09:13,729 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000035_0' to tip task_201609111806_0001_m_000035, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:09:13,729 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000035
2016-09-11 18:09:22,809 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000028_0' has completed task_201609111806_0001_m_000028 successfully.
2016-09-11 18:09:22,811 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000036_0' to tip task_201609111806_0001_m_000036, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:09:22,811 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000036
2016-09-11 18:09:23,923 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000006_0' has completed task_201609111806_0001_m_000006 successfully.
2016-09-11 18:09:23,924 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000007_0' has completed task_201609111806_0001_m_000007 successfully.
2016-09-11 18:09:23,924 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000009_0' has completed task_201609111806_0001_m_000009 successfully.
2016-09-11 18:09:23,925 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000037_0' to tip task_201609111806_0001_m_000037, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:09:23,925 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000037
2016-09-11 18:09:25,207 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000023_0' has completed task_201609111806_0001_m_000023 successfully.
2016-09-11 18:09:27,692 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609111806_0001_r_000000 for speculative execution
2016-09-11 18:09:27,692 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0001_r_000000_1' to tip task_201609111806_0001_r_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:09:32,129 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000011_0' has completed task_201609111806_0001_m_000011 successfully.
2016-09-11 18:09:32,130 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000012_0' has completed task_201609111806_0001_m_000012 successfully.
2016-09-11 18:09:34,475 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000003_0' has completed task_201609111806_0001_m_000003 successfully.
2016-09-11 18:09:35,143 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000013_0' has completed task_201609111806_0001_m_000013 successfully.
2016-09-11 18:09:36,495 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000015_0' has completed task_201609111806_0001_m_000015 successfully.
2016-09-11 18:09:36,496 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000017_0' has completed task_201609111806_0001_m_000017 successfully.
2016-09-11 18:09:36,497 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000018_0' has completed task_201609111806_0001_m_000018 successfully.
2016-09-11 18:09:37,492 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000032_0' has completed task_201609111806_0001_m_000032 successfully.
2016-09-11 18:09:38,116 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000021_0' has completed task_201609111806_0001_m_000021 successfully.
2016-09-11 18:09:39,502 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000016_0' has completed task_201609111806_0001_m_000016 successfully.
2016-09-11 18:09:44,166 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0001_m_000026 for speculative execution
2016-09-11 18:09:44,166 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000026_1' to tip task_201609111806_0001_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:09:44,166 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000026
2016-09-11 18:09:52,540 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000037_0' has completed task_201609111806_0001_m_000037 successfully.
2016-09-11 18:09:56,185 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000031_0' has completed task_201609111806_0001_m_000031 successfully.
2016-09-11 18:10:07,533 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000036_0' has completed task_201609111806_0001_m_000036 successfully.
2016-09-11 18:10:07,565 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000034_0' has completed task_201609111806_0001_m_000034 successfully.
2016-09-11 18:10:07,567 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0001_m_000025 for speculative execution
2016-09-11 18:10:07,567 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000025_1' to tip task_201609111806_0001_m_000025, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:10:07,568 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000025
2016-09-11 18:10:10,573 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000033_0' has completed task_201609111806_0001_m_000033 successfully.
2016-09-11 18:10:10,574 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0001_m_000004 for speculative execution
2016-09-11 18:10:10,575 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000004_1' to tip task_201609111806_0001_m_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:10:10,575 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0001_m_000004
2016-09-11 18:10:19,546 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000030_0' has completed task_201609111806_0001_m_000030 successfully.
2016-09-11 18:10:19,547 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0001_m_000035 for speculative execution
2016-09-11 18:10:19,547 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0001_m_000035_1' to tip task_201609111806_0001_m_000035, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:10:19,547 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0001_m_000035
2016-09-11 18:10:29,727 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000029_0' has completed task_201609111806_0001_m_000029 successfully.
2016-09-11 18:10:35,174 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000022_0' has completed task_201609111806_0001_m_000022 successfully.
2016-09-11 18:10:44,392 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000025_1' has completed task_201609111806_0001_m_000025 successfully.
2016-09-11 18:10:44,393 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000004_1' has completed task_201609111806_0001_m_000004 successfully.
2016-09-11 18:10:51,584 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000004_0'
2016-09-11 18:10:51,585 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0001_m_000004_0' to tip task_201609111806_0001_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:10:52,197 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000025_0'
2016-09-11 18:10:52,198 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0001_m_000025_0' to tip task_201609111806_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:10:54,594 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000004_0'
2016-09-11 18:10:58,206 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000025_0'
2016-09-11 18:11:10,215 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000026_0' has completed task_201609111806_0001_m_000026 successfully.
2016-09-11 18:11:16,338 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000026_1'
2016-09-11 18:11:16,338 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0001_m_000026_1' to tip task_201609111806_0001_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:11:19,342 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000026_1'
2016-09-11 18:11:58,381 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000035_0' has completed task_201609111806_0001_m_000035 successfully.
2016-09-11 18:12:00,643 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000035_1'
2016-09-11 18:19:18,347 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_r_000000_0' has completed task_201609111806_0001_r_000000 successfully.
2016-09-11 18:19:18,353 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0001_m_000038_0' to tip task_201609111806_0001_m_000038, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:19:24,028 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_r_000000_1'
2016-09-11 18:19:24,029 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0001_r_000000_1' to tip task_201609111806_0001_r_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:19:24,359 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0001_m_000038_0' has completed task_201609111806_0001_m_000038 successfully.
2016-09-11 18:19:24,360 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0001 has completed successfully.
2016-09-11 18:19:24,361 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0001,submitTime=1473597483302,launchTime=1473597483593,finishTime=1473598164360,numMaps=38,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2607,reduceSlotsSeconds=649,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 18:19:24,456 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0001_hduser
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000005_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000008_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000021_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000022_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000023_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000026_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000038_0'
2016-09-11 18:19:24,459 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_r_000000_0'
2016-09-11 18:19:24,464 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0001_conf.xml
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0001_conf.xml
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000000_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000001_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000002_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000003_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000004_1'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000006_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000007_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000009_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000010_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000011_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000012_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000013_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000014_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000015_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000016_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000017_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000018_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000019_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000020_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000024_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000025_1'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000027_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000028_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000029_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000030_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000031_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000032_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000033_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000034_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000035_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000036_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000037_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_r_000000_1'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0001_m_000039_0'
2016-09-11 18:19:24,470 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0001' of user 'hduser'
2016-09-11 18:20:28,542 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0001.   Cache size is 0
2016-09-11 18:36:10,255 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0002 added successfully for user 'hduser' to queue 'default'
2016-09-11 18:36:10,255 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0002
2016-09-11 18:36:10,255 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0002
2016-09-11 18:36:10,262 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0002_hduser
2016-09-11 18:36:10,264 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0002_conf.xml
2016-09-11 18:36:10,325 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0002/jobToken
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0002 = 10000000000. Number of splits = 38
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000000 has split on node:/default-rack/slave4
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000001 has split on node:/default-rack/slave4
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000002 has split on node:/default-rack/slave4
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000003 has split on node:/default-rack/slave5
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000004 has split on node:/default-rack/slave5
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000005 has split on node:/default-rack/slave4
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000006 has split on node:/default-rack/slave5
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000007 has split on node:/default-rack/slave5
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000008 has split on node:/default-rack/slave4
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000009 has split on node:/default-rack/slave5
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000010 has split on node:/default-rack/slave3
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000011 has split on node:/default-rack/slave3
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000012 has split on node:/default-rack/slave3
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000013 has split on node:/default-rack/slave3
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000014 has split on node:/default-rack/slave3
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000015 has split on node:/default-rack/slave2
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000016 has split on node:/default-rack/slave2
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000017 has split on node:/default-rack/slave2
2016-09-11 18:36:10,329 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000018 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000019 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000019 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000019 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000019 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000020 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000020 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000020 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000020 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000021 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000021 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000021 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000021 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000022 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000022 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000022 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000022 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000023 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000023 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000023 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000023 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000024 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000024 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000024 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000024 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000025 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000025 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000025 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000025 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000026 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000026 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000026 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000026 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000027 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000027 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000027 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000027 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000028 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000028 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000028 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000028 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000029 has split on node:/default-rack/slave5
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000029 has split on node:/default-rack/slave4
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000029 has split on node:/default-rack/slave3
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000029 has split on node:/default-rack/slave2
2016-09-11 18:36:10,330 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000030 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000030 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000030 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000030 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000031 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000031 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000031 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000031 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000032 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000032 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000032 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000032 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000033 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000033 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000033 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000033 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000034 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000034 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000034 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000034 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000035 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000035 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000035 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000035 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000036 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000037 has split on node:/default-rack/slave4
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000037 has split on node:/default-rack/slave3
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000037 has split on node:/default-rack/slave5
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0002_m_000037 has split on node:/default-rack/slave2
2016-09-11 18:36:10,331 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0002 initialized successfully with 38 map tasks and 1 reduce tasks.
2016-09-11 18:36:10,376 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0002_m_000039_0' to tip task_201609111806_0002_m_000039, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:36:13,379 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000039_0' has completed task_201609111806_0002_m_000039 successfully.
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000000_0' to tip task_201609111806_0002_m_000000, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000000
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000001_0' to tip task_201609111806_0002_m_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000001
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000002_0' to tip task_201609111806_0002_m_000002, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000002
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000003_0' to tip task_201609111806_0002_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000003
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000004_0' to tip task_201609111806_0002_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:36:13,381 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000004
2016-09-11 18:36:14,560 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000005_0' to tip task_201609111806_0002_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000005
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000008_0' to tip task_201609111806_0002_m_000008, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000008
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000019_0' to tip task_201609111806_0002_m_000019, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000019
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000020_0' to tip task_201609111806_0002_m_000020, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000020
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000021_0' to tip task_201609111806_0002_m_000021, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:14,561 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000021
2016-09-11 18:36:15,565 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000010_0' to tip task_201609111806_0002_m_000010, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:36:15,565 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000010
2016-09-11 18:36:15,566 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000011_0' to tip task_201609111806_0002_m_000011, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:36:15,566 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000011
2016-09-11 18:36:15,566 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000012_0' to tip task_201609111806_0002_m_000012, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:36:15,566 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000012
2016-09-11 18:36:15,567 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000013_0' to tip task_201609111806_0002_m_000013, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:36:15,567 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000013
2016-09-11 18:36:15,567 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000014_0' to tip task_201609111806_0002_m_000014, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 18:36:15,567 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000014
2016-09-11 18:36:15,610 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000006_0' to tip task_201609111806_0002_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:36:15,610 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000006
2016-09-11 18:36:15,610 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000007_0' to tip task_201609111806_0002_m_000007, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:36:15,610 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000007
2016-09-11 18:36:15,610 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000009_0' to tip task_201609111806_0002_m_000009, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:36:15,611 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000009
2016-09-11 18:36:15,611 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000022_0' to tip task_201609111806_0002_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:36:15,611 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000022
2016-09-11 18:36:15,611 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000023_0' to tip task_201609111806_0002_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:36:15,611 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000023
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000015_0' to tip task_201609111806_0002_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000015
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000016_0' to tip task_201609111806_0002_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000016
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000017_0' to tip task_201609111806_0002_m_000017, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000017
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000018_0' to tip task_201609111806_0002_m_000018, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000018
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000024_0' to tip task_201609111806_0002_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:36:16,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000024
2016-09-11 18:36:33,607 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000008_0' has completed task_201609111806_0002_m_000008 successfully.
2016-09-11 18:36:33,608 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000025_0' to tip task_201609111806_0002_m_000025, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:33,608 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000025
2016-09-11 18:36:39,716 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000005_0' has completed task_201609111806_0002_m_000005 successfully.
2016-09-11 18:36:39,720 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000026_0' to tip task_201609111806_0002_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:36:39,720 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000026
2016-09-11 18:36:39,720 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0002_r_000000_0' to tip task_201609111806_0002_r_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:37:01,517 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000003_0' has completed task_201609111806_0002_m_000003 successfully.
2016-09-11 18:37:01,518 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000027_0' to tip task_201609111806_0002_m_000027, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:37:01,518 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000027
2016-09-11 18:37:07,524 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000002_0' has completed task_201609111806_0002_m_000002 successfully.
2016-09-11 18:37:07,526 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000004_0' has completed task_201609111806_0002_m_000004 successfully.
2016-09-11 18:37:07,528 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000028_0' to tip task_201609111806_0002_m_000028, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:37:07,528 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000028
2016-09-11 18:37:07,528 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000029_0' to tip task_201609111806_0002_m_000029, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:37:07,528 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000029
2016-09-11 18:37:10,090 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000018_0' has completed task_201609111806_0002_m_000018 successfully.
2016-09-11 18:37:10,091 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000030_0' to tip task_201609111806_0002_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:37:10,091 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000030
2016-09-11 18:37:22,111 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000016_0' has completed task_201609111806_0002_m_000016 successfully.
2016-09-11 18:37:22,113 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000031_0' to tip task_201609111806_0002_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:37:22,113 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000031
2016-09-11 18:37:22,684 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000009_0' has completed task_201609111806_0002_m_000009 successfully.
2016-09-11 18:37:22,685 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000023_0' has completed task_201609111806_0002_m_000023 successfully.
2016-09-11 18:37:22,686 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000032_0' to tip task_201609111806_0002_m_000032, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:37:22,686 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000032
2016-09-11 18:37:22,686 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000033_0' to tip task_201609111806_0002_m_000033, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:37:22,686 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000033
2016-09-11 18:37:25,903 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000001_0' has completed task_201609111806_0002_m_000001 successfully.
2016-09-11 18:37:25,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000034_0' to tip task_201609111806_0002_m_000034, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:37:25,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000034
2016-09-11 18:37:26,361 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609111806_0002_m_000034_0 is 457 ms debug.
2016-09-11 18:37:28,928 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000030_0' has completed task_201609111806_0002_m_000030 successfully.
2016-09-11 18:37:28,930 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000035_0' to tip task_201609111806_0002_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 18:37:28,930 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000035
2016-09-11 18:37:28,977 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000006_0' has completed task_201609111806_0002_m_000006 successfully.
2016-09-11 18:37:28,979 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000037_0' to tip task_201609111806_0002_m_000037, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 18:37:28,979 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0002_m_000037
2016-09-11 18:37:36,951 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000000_0' has completed task_201609111806_0002_m_000000 successfully.
2016-09-11 18:37:36,952 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0002_m_000036_0' to tip task_201609111806_0002_m_000036, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 18:37:36,952 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0002_m_000036
2016-09-11 18:37:37,007 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000007_0' has completed task_201609111806_0002_m_000007 successfully.
2016-09-11 18:37:37,938 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000024_0' has completed task_201609111806_0002_m_000024 successfully.
2016-09-11 18:37:38,080 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000019_0' has completed task_201609111806_0002_m_000019 successfully.
2016-09-11 18:37:40,014 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000022_0' has completed task_201609111806_0002_m_000022 successfully.
2016-09-11 18:37:44,076 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000015_0' has completed task_201609111806_0002_m_000015 successfully.
2016-09-11 18:37:45,164 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000010_0' has completed task_201609111806_0002_m_000010 successfully.
2016-09-11 18:37:45,165 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000014_0' has completed task_201609111806_0002_m_000014 successfully.
2016-09-11 18:37:48,173 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000011_0' has completed task_201609111806_0002_m_000011 successfully.
2016-09-11 18:37:48,174 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000012_0' has completed task_201609111806_0002_m_000012 successfully.
2016-09-11 18:37:48,175 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000013_0' has completed task_201609111806_0002_m_000013 successfully.
2016-09-11 18:37:53,080 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000017_0' has completed task_201609111806_0002_m_000017 successfully.
2016-09-11 18:38:05,682 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000027_0' has completed task_201609111806_0002_m_000027 successfully.
2016-09-11 18:38:07,045 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000037_0' has completed task_201609111806_0002_m_000037 successfully.
2016-09-11 18:38:11,103 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000031_0' has completed task_201609111806_0002_m_000031 successfully.
2016-09-11 18:38:14,107 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000035_0' has completed task_201609111806_0002_m_000035 successfully.
2016-09-11 18:38:25,065 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000032_0' has completed task_201609111806_0002_m_000032 successfully.
2016-09-11 18:38:25,066 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000033_0' has completed task_201609111806_0002_m_000033 successfully.
2016-09-11 18:38:25,890 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000034_0' has completed task_201609111806_0002_m_000034 successfully.
2016-09-11 18:38:29,300 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000021_0' has completed task_201609111806_0002_m_000021 successfully.
2016-09-11 18:38:30,525 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000029_0' has completed task_201609111806_0002_m_000029 successfully.
2016-09-11 18:38:30,526 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000036_0' has completed task_201609111806_0002_m_000036 successfully.
2016-09-11 18:38:33,531 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000028_0' has completed task_201609111806_0002_m_000028 successfully.
2016-09-11 18:38:39,015 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000020_0' has completed task_201609111806_0002_m_000020 successfully.
2016-09-11 18:39:13,243 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000025_0' has completed task_201609111806_0002_m_000025 successfully.
2016-09-11 18:39:26,832 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000026_0' has completed task_201609111806_0002_m_000026 successfully.
2016-09-11 18:54:31,377 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_r_000000_0' has completed task_201609111806_0002_r_000000 successfully.
2016-09-11 18:54:31,379 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0002_m_000038_0' to tip task_201609111806_0002_m_000038, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 18:54:37,402 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0002_m_000038_0' has completed task_201609111806_0002_m_000038 successfully.
2016-09-11 18:54:37,403 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0002 has completed successfully.
2016-09-11 18:54:37,403 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0002,submitTime=1473599170147,launchTime=1473599170331,finishTime=1473600277403,numMaps=38,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2822,reduceSlotsSeconds=1069,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 18:54:37,510 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0002_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0002_hduser
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000005_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000008_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000019_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000020_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000021_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000025_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000026_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000038_0'
2016-09-11 18:54:37,511 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_r_000000_0'
2016-09-11 18:54:37,516 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0002_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0002_conf.xml
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0002_conf.xml
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000000_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000001_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000002_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000003_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000004_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000006_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000007_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000009_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000010_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000011_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000012_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000013_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000014_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000015_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000016_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000017_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000018_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000022_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000023_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000024_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000027_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000028_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000029_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000030_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000031_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000032_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000033_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000034_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000035_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000036_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000037_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0002_m_000039_0'
2016-09-11 18:54:37,521 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0002' of user 'hduser'
2016-09-11 18:54:57,093 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0002.   Cache size is 1
2016-09-11 19:02:59,945 INFO org.apache.hadoop.conf.Configuration: found resource webapps/static/jobconf.xsl at file:/usr/local/hadoop-0.21.0/webapps/static/jobconf.xsl
2016-09-11 19:08:33,284 INFO org.apache.hadoop.conf.Configuration: found resource webapps/static/jobconf.xsl at file:/usr/local/hadoop-0.21.0/webapps/static/jobconf.xsl
2016-09-11 19:21:21,210 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0003 added successfully for user 'hduser' to queue 'default'
2016-09-11 19:21:21,210 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0003
2016-09-11 19:21:21,211 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0003
2016-09-11 19:21:21,219 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0003_hduser
2016-09-11 19:21:21,225 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0003_conf.xml
2016-09-11 19:21:21,283 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0003/jobToken
2016-09-11 19:21:21,286 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0003 = 10000000000. Number of splits = 38
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000000 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000001 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000002 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000003 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000004 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000005 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000006 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000007 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000008 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000009 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000010 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000011 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000012 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000013 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000014 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000015 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000016 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000017 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000018 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000019 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000019 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000019 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000019 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000020 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000020 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000020 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000020 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000021 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000021 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000021 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000021 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000022 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000022 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000022 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000022 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000023 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000023 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000023 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000023 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000024 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000024 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000024 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000024 has split on node:/default-rack/slave2
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000025 has split on node:/default-rack/slave3
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000025 has split on node:/default-rack/slave4
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000025 has split on node:/default-rack/slave5
2016-09-11 19:21:21,287 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000025 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000026 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000026 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000026 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000026 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000027 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000027 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000027 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000027 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000028 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000028 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000028 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000028 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000029 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000029 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000029 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000029 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000030 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000030 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000030 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000030 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000031 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000031 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000031 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000031 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000032 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000032 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000032 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000032 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000033 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000033 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000033 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000033 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000034 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000034 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000034 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000034 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000035 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000035 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000035 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000035 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000036 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000037 has split on node:/default-rack/slave3
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000037 has split on node:/default-rack/slave4
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000037 has split on node:/default-rack/slave5
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0003_m_000037 has split on node:/default-rack/slave2
2016-09-11 19:21:21,288 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0003 initialized successfully with 38 map tasks and 5 reduce tasks.
2016-09-11 19:21:21,448 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0003_m_000039_0' to tip task_201609111806_0003_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:24,452 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000039_0' has completed task_201609111806_0003_m_000039 successfully.
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000000_0' to tip task_201609111806_0003_m_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000000
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000001_0' to tip task_201609111806_0003_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000001
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000002_0' to tip task_201609111806_0003_m_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000002
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000005_0' to tip task_201609111806_0003_m_000005, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:24,453 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000005
2016-09-11 19:21:24,454 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000008_0' to tip task_201609111806_0003_m_000008, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:24,454 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000008
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000015_0' to tip task_201609111806_0003_m_000015, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000015
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000016_0' to tip task_201609111806_0003_m_000016, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000016
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000017_0' to tip task_201609111806_0003_m_000017, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000017
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000018_0' to tip task_201609111806_0003_m_000018, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000018
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000019_0' to tip task_201609111806_0003_m_000019, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:25,424 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000019
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000003_0' to tip task_201609111806_0003_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000003
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000004_0' to tip task_201609111806_0003_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000004
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000006_0' to tip task_201609111806_0003_m_000006, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000006
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000007_0' to tip task_201609111806_0003_m_000007, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000007
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000009_0' to tip task_201609111806_0003_m_000009, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:21:25,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000009
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000010_0' to tip task_201609111806_0003_m_000010, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000010
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000011_0' to tip task_201609111806_0003_m_000011, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000011
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000012_0' to tip task_201609111806_0003_m_000012, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000012
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000013_0' to tip task_201609111806_0003_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000013
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000014_0' to tip task_201609111806_0003_m_000014, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:21:26,625 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000014
2016-09-11 19:21:26,886 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000020_0' to tip task_201609111806_0003_m_000020, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:21:26,886 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000020
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000021_0' to tip task_201609111806_0003_m_000021, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000021
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000022_0' to tip task_201609111806_0003_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000022
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000023_0' to tip task_201609111806_0003_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000023
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000024_0' to tip task_201609111806_0003_m_000024, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:21:26,887 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000024
2016-09-11 19:21:42,470 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000001_0' has completed task_201609111806_0003_m_000001 successfully.
2016-09-11 19:21:42,471 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000002_0' has completed task_201609111806_0003_m_000002 successfully.
2016-09-11 19:21:42,472 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000025_0' to tip task_201609111806_0003_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:42,472 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000025
2016-09-11 19:21:42,472 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000026_0' to tip task_201609111806_0003_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:42,472 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000026
2016-09-11 19:21:42,472 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0003_r_000000_0' to tip task_201609111806_0003_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:21:43,461 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0003_r_000001_0' to tip task_201609111806_0003_r_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:43,720 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0003_r_000002_0' to tip task_201609111806_0003_r_000002, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:21:44,651 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0003_r_000003_0' to tip task_201609111806_0003_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:21:44,907 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0003_r_000004_0' to tip task_201609111806_0003_r_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:21:49,472 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000019_0' has completed task_201609111806_0003_m_000019 successfully.
2016-09-11 19:21:49,473 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000027_0' to tip task_201609111806_0003_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:21:49,473 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000027
2016-09-11 19:22:00,893 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000010_0' has completed task_201609111806_0003_m_000010 successfully.
2016-09-11 19:22:00,893 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000011_0' has completed task_201609111806_0003_m_000011 successfully.
2016-09-11 19:22:00,894 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000028_0' to tip task_201609111806_0003_m_000028, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:22:00,894 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000028
2016-09-11 19:22:00,894 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000029_0' to tip task_201609111806_0003_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:22:00,894 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000029
2016-09-11 19:22:04,582 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000012_0' has completed task_201609111806_0003_m_000012 successfully.
2016-09-11 19:22:04,583 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000030_0' to tip task_201609111806_0003_m_000030, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:22:04,583 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000030
2016-09-11 19:22:13,941 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000013_0' has completed task_201609111806_0003_m_000013 successfully.
2016-09-11 19:22:13,942 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000031_0' to tip task_201609111806_0003_m_000031, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:22:13,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000031
2016-09-11 19:22:18,491 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000005_0' has completed task_201609111806_0003_m_000005 successfully.
2016-09-11 19:22:18,493 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000032_0' to tip task_201609111806_0003_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:22:18,493 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000032
2016-09-11 19:22:21,382 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000015_0' has completed task_201609111806_0003_m_000015 successfully.
2016-09-11 19:22:21,383 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000016_0' has completed task_201609111806_0003_m_000016 successfully.
2016-09-11 19:22:21,383 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000018_0' has completed task_201609111806_0003_m_000018 successfully.
2016-09-11 19:22:21,383 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000033_0' to tip task_201609111806_0003_m_000033, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:22:21,384 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000033
2016-09-11 19:22:21,384 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000034_0' to tip task_201609111806_0003_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:22:21,384 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000034
2016-09-11 19:22:21,384 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000035_0' to tip task_201609111806_0003_m_000035, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:22:21,384 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000035
2016-09-11 19:22:22,954 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000014_0' has completed task_201609111806_0003_m_000014 successfully.
2016-09-11 19:22:22,955 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000037_0' to tip task_201609111806_0003_m_000037, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:22:22,955 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000037
2016-09-11 19:22:26,623 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000017_0' has completed task_201609111806_0003_m_000017 successfully.
2016-09-11 19:22:26,624 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000036_0' to tip task_201609111806_0003_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:22:26,624 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000036
2016-09-11 19:22:28,284 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000008_0' has completed task_201609111806_0003_m_000008 successfully.
2016-09-11 19:22:34,038 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000004_0' has completed task_201609111806_0003_m_000004 successfully.
2016-09-11 19:22:34,288 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000000_0' has completed task_201609111806_0003_m_000000 successfully.
2016-09-11 19:22:37,042 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000006_0' has completed task_201609111806_0003_m_000006 successfully.
2016-09-11 19:22:40,053 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000009_0' has completed task_201609111806_0003_m_000009 successfully.
2016-09-11 19:22:43,058 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000003_0' has completed task_201609111806_0003_m_000003 successfully.
2016-09-11 19:22:49,301 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000026_0' has completed task_201609111806_0003_m_000026 successfully.
2016-09-11 19:22:52,348 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000022_0' has completed task_201609111806_0003_m_000022 successfully.
2016-09-11 19:22:55,069 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000007_0' has completed task_201609111806_0003_m_000007 successfully.
2016-09-11 19:22:56,036 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000036_0' has completed task_201609111806_0003_m_000036 successfully.
2016-09-11 19:23:01,310 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000028 for speculative execution
2016-09-11 19:23:01,311 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000028_1' to tip task_201609111806_0003_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:23:01,312 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000028
2016-09-11 19:23:01,564 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000029 for speculative execution
2016-09-11 19:23:01,565 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000029_1' to tip task_201609111806_0003_m_000029, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:23:01,565 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000029
2016-09-11 19:23:02,046 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000034_0' has completed task_201609111806_0003_m_000034 successfully.
2016-09-11 19:23:06,810 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000023_0' has completed task_201609111806_0003_m_000023 successfully.
2016-09-11 19:23:07,568 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000030 for speculative execution
2016-09-11 19:23:07,569 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000030_1' to tip task_201609111806_0003_m_000030, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:23:07,569 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000030
2016-09-11 19:23:10,487 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000025_0' has completed task_201609111806_0003_m_000025 successfully.
2016-09-11 19:23:16,495 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000031 for speculative execution
2016-09-11 19:23:16,495 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000031_1' to tip task_201609111806_0003_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:23:16,495 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000031
2016-09-11 19:23:19,574 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000020_0' has completed task_201609111806_0003_m_000020 successfully.
2016-09-11 19:23:22,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000035 for speculative execution
2016-09-11 19:23:22,577 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000035_1' to tip task_201609111806_0003_m_000035, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:23:22,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0003_m_000035
2016-09-11 19:23:22,582 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000021_0' has completed task_201609111806_0003_m_000021 successfully.
2016-09-11 19:23:28,592 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000024_0' has completed task_201609111806_0003_m_000024 successfully.
2016-09-11 19:23:34,742 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000032_0' has completed task_201609111806_0003_m_000032 successfully.
2016-09-11 19:23:46,750 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000028_1' has completed task_201609111806_0003_m_000028 successfully.
2016-09-11 19:23:46,751 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000033 for speculative execution
2016-09-11 19:23:46,752 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000033_1' to tip task_201609111806_0003_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:23:46,752 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000033
2016-09-11 19:23:47,524 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000027_0' has completed task_201609111806_0003_m_000027 successfully.
2016-09-11 19:23:49,734 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000029_1' has completed task_201609111806_0003_m_000029 successfully.
2016-09-11 19:23:52,755 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000031_1' has completed task_201609111806_0003_m_000031 successfully.
2016-09-11 19:24:03,327 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000028_0'
2016-09-11 19:24:03,328 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0003_m_000028_0' to tip task_201609111806_0003_m_000028, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:24:04,770 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000033_1' has completed task_201609111806_0003_m_000033 successfully.
2016-09-11 19:24:04,771 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609111806_0003_m_000037 for speculative execution
2016-09-11 19:24:04,771 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0003_m_000037_1' to tip task_201609111806_0003_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:24:04,771 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0003_m_000037
2016-09-11 19:24:06,363 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609111806_0003_m_000028_0 is 3035 ms debug.
2016-09-11 19:24:10,553 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000033_0'
2016-09-11 19:24:10,553 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0003_m_000033_0' to tip task_201609111806_0003_m_000033, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:24:13,776 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000037_1' has completed task_201609111806_0003_m_000037 successfully.
2016-09-11 19:24:13,792 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000029_0'
2016-09-11 19:24:13,792 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000031_0'
2016-09-11 19:24:13,793 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0003_m_000029_0' to tip task_201609111806_0003_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:24:13,793 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000037_0'
2016-09-11 19:24:13,950 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0003_m_000031_0' to tip task_201609111806_0003_m_000031, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:24:19,753 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000030_1' has completed task_201609111806_0003_m_000030 successfully.
2016-09-11 19:24:20,753 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000028_0'
2016-09-11 19:24:20,753 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000029_0'
2016-09-11 19:24:26,021 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000030_0'
2016-09-11 19:24:26,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0003_m_000030_0' to tip task_201609111806_0003_m_000030, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:24:29,647 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000030_0'
2016-09-11 19:24:35,399 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000031_0'
2016-09-11 19:24:39,844 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000035_0' has completed task_201609111806_0003_m_000035 successfully.
2016-09-11 19:24:40,768 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000035_1'
2016-09-11 19:24:48,853 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000033_0'
2016-09-11 19:25:29,988 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609111806_0003_r_000004 for speculative execution
2016-09-11 19:25:29,988 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0003_r_000004_1' to tip task_201609111806_0003_r_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:25:32,991 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_r_000000_0' has completed task_201609111806_0003_r_000000 successfully.
2016-09-11 19:25:43,928 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_r_000001_0' has completed task_201609111806_0003_r_000001 successfully.
2016-09-11 19:25:50,759 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_r_000003_0' has completed task_201609111806_0003_r_000003 successfully.
2016-09-11 19:26:11,511 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_r_000002_0' has completed task_201609111806_0003_r_000002 successfully.
2016-09-11 19:26:48,874 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_r_000004_0' has completed task_201609111806_0003_r_000004 successfully.
2016-09-11 19:26:48,874 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0003_m_000038_0' to tip task_201609111806_0003_m_000038, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:26:56,230 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000004_1'
2016-09-11 19:26:56,231 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609111806_0003_r_000004_1' to tip task_201609111806_0003_r_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:26:57,882 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0003_m_000038_0' has completed task_201609111806_0003_m_000038 successfully.
2016-09-11 19:26:57,883 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0003 has completed successfully.
2016-09-11 19:26:57,883 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0003,submitTime=1473601881152,launchTime=1473601881288,finishTime=1473602217883,numMaps=38,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2591,reduceSlotsSeconds=1264,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0003_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0003_hduser
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000020_0'
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000021_0'
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000022_0'
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000023_0'
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000024_0'
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000038_0'
2016-09-11 19:26:58,034 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000004_0'
2016-09-11 19:26:58,042 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0003_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0003_conf.xml
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0003_conf.xml
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000000_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000001_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000002_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000003_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000004_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000005_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000006_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000007_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000008_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000009_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000010_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000011_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000012_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000013_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000014_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000015_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000016_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000017_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000018_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000019_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000025_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000026_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000027_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000028_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000029_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000030_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000031_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000032_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000033_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000034_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000035_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000036_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000037_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000000_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000001_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000002_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000003_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_r_000004_1'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0003_m_000039_0'
2016-09-11 19:26:58,055 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0003' of user 'hduser'
2016-09-11 19:27:11,432 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0003.   Cache size is 2
2016-09-11 19:53:27,239 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0004 added successfully for user 'hduser' to queue 'default'
2016-09-11 19:53:27,239 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0004
2016-09-11 19:53:27,239 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0004
2016-09-11 19:53:27,241 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0004_hduser
2016-09-11 19:53:27,246 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0004_conf.xml
2016-09-11 19:53:27,273 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0004/jobToken
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0004 = 10000000000. Number of splits = 38
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000000 has split on node:/default-rack/slave4
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000001 has split on node:/default-rack/slave4
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000002 has split on node:/default-rack/slave4
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000003 has split on node:/default-rack/slave5
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000004 has split on node:/default-rack/slave5
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000005 has split on node:/default-rack/slave4
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000006 has split on node:/default-rack/slave5
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000007 has split on node:/default-rack/slave5
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000008 has split on node:/default-rack/slave4
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000009 has split on node:/default-rack/slave5
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000010 has split on node:/default-rack/slave3
2016-09-11 19:53:27,276 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000011 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000012 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000013 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000014 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000015 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000016 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000017 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000018 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000019 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000019 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000019 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000019 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000020 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000020 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000020 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000020 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000021 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000021 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000021 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000021 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000022 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000022 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000022 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000022 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000023 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000023 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000023 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000023 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000024 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000024 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000024 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000024 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000025 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000025 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000025 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000025 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000026 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000026 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000026 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000026 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000027 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000027 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000027 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000027 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000028 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000028 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000028 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000028 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000029 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000029 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000029 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000029 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000030 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000030 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000030 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000030 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000031 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000031 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000031 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000031 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000032 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000032 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000032 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000032 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000033 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000033 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000033 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000033 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000034 has split on node:/default-rack/slave2
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000034 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000034 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000034 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000035 has split on node:/default-rack/slave4
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000035 has split on node:/default-rack/slave3
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000035 has split on node:/default-rack/slave5
2016-09-11 19:53:27,277 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000035 has split on node:/default-rack/slave2
2016-09-11 19:53:27,278 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000036 has split on node:/default-rack/slave2
2016-09-11 19:53:27,278 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000037 has split on node:/default-rack/slave2
2016-09-11 19:53:27,278 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000037 has split on node:/default-rack/slave4
2016-09-11 19:53:27,278 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000037 has split on node:/default-rack/slave5
2016-09-11 19:53:27,278 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0004_m_000037 has split on node:/default-rack/slave3
2016-09-11 19:53:27,278 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0004 initialized successfully with 38 map tasks and 5 reduce tasks.
2016-09-11 19:53:27,355 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0004_m_000039_0' to tip task_201609111806_0004_m_000039, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:33,360 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000039_0' has completed task_201609111806_0004_m_000039 successfully.
2016-09-11 19:53:33,362 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000000_0' to tip task_201609111806_0004_m_000000, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:33,362 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000000
2016-09-11 19:53:33,362 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000001_0' to tip task_201609111806_0004_m_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:33,362 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000001
2016-09-11 19:53:33,363 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000002_0' to tip task_201609111806_0004_m_000002, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:33,363 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000002
2016-09-11 19:53:33,363 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000003_0' to tip task_201609111806_0004_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:33,363 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000003
2016-09-11 19:53:33,363 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000004_0' to tip task_201609111806_0004_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:33,363 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000004
2016-09-11 19:53:34,066 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000005_0' to tip task_201609111806_0004_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:53:34,067 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000005
2016-09-11 19:53:34,067 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000008_0' to tip task_201609111806_0004_m_000008, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:53:34,067 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000008
2016-09-11 19:53:34,067 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000019_0' to tip task_201609111806_0004_m_000019, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:53:34,067 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000019
2016-09-11 19:53:34,068 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000020_0' to tip task_201609111806_0004_m_000020, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:53:34,068 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000020
2016-09-11 19:53:34,068 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000021_0' to tip task_201609111806_0004_m_000021, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:53:34,068 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000021
2016-09-11 19:53:35,123 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000006_0' to tip task_201609111806_0004_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:53:35,123 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000006
2016-09-11 19:53:35,123 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000007_0' to tip task_201609111806_0004_m_000007, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000007
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000009_0' to tip task_201609111806_0004_m_000009, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000009
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000022_0' to tip task_201609111806_0004_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000022
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000023_0' to tip task_201609111806_0004_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:53:35,124 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000023
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000010_0' to tip task_201609111806_0004_m_000010, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000010
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000011_0' to tip task_201609111806_0004_m_000011, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000011
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000012_0' to tip task_201609111806_0004_m_000012, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000012
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000013_0' to tip task_201609111806_0004_m_000013, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000013
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000014_0' to tip task_201609111806_0004_m_000014, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:53:35,660 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000014
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000015_0' to tip task_201609111806_0004_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000015
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000016_0' to tip task_201609111806_0004_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000016
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000017_0' to tip task_201609111806_0004_m_000017, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000017
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000018_0' to tip task_201609111806_0004_m_000018, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000018
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000024_0' to tip task_201609111806_0004_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:53:36,021 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000024
2016-09-11 19:53:57,919 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000002_0' has completed task_201609111806_0004_m_000002 successfully.
2016-09-11 19:53:57,920 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000025_0' to tip task_201609111806_0004_m_000025, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:53:57,920 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000025
2016-09-11 19:54:00,273 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000005_0' has completed task_201609111806_0004_m_000005 successfully.
2016-09-11 19:54:00,274 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000008_0' has completed task_201609111806_0004_m_000008 successfully.
2016-09-11 19:54:00,274 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000026_0' to tip task_201609111806_0004_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:54:00,274 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000026
2016-09-11 19:54:00,274 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000027_0' to tip task_201609111806_0004_m_000027, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:54:00,274 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000027
2016-09-11 19:54:00,274 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0004_r_000000_0' to tip task_201609111806_0004_r_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 19:54:00,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0004_r_000001_0' to tip task_201609111806_0004_r_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:54:02,682 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0004_r_000002_0' to tip task_201609111806_0004_r_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 19:54:02,846 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0004_r_000003_0' to tip task_201609111806_0004_r_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:54:03,040 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0004_r_000004_0' to tip task_201609111806_0004_r_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:54:27,058 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000016_0' has completed task_201609111806_0004_m_000016 successfully.
2016-09-11 19:54:27,058 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000028_0' to tip task_201609111806_0004_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:54:27,058 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000028
2016-09-11 19:54:33,065 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000024_0' has completed task_201609111806_0004_m_000024 successfully.
2016-09-11 19:54:33,066 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000029_0' to tip task_201609111806_0004_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:54:33,066 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000029
2016-09-11 19:54:37,919 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000001_0' has completed task_201609111806_0004_m_000001 successfully.
2016-09-11 19:54:37,933 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000030_0' to tip task_201609111806_0004_m_000030, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:54:37,933 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000030
2016-09-11 19:54:43,143 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000017_0' has completed task_201609111806_0004_m_000017 successfully.
2016-09-11 19:54:43,143 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000018_0' has completed task_201609111806_0004_m_000018 successfully.
2016-09-11 19:54:43,144 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000031_0' to tip task_201609111806_0004_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:54:43,144 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000031
2016-09-11 19:54:43,144 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000032_0' to tip task_201609111806_0004_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:54:43,144 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000032
2016-09-11 19:54:49,157 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000015_0' has completed task_201609111806_0004_m_000015 successfully.
2016-09-11 19:54:49,157 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000033_0' to tip task_201609111806_0004_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 19:54:49,157 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000033
2016-09-11 19:54:50,298 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000004_0' has completed task_201609111806_0004_m_000004 successfully.
2016-09-11 19:54:50,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000034_0' to tip task_201609111806_0004_m_000034, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:54:50,299 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000034
2016-09-11 19:55:08,441 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000000_0' has completed task_201609111806_0004_m_000000 successfully.
2016-09-11 19:55:08,442 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000025_0' has completed task_201609111806_0004_m_000025 successfully.
2016-09-11 19:55:08,442 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000035_0' to tip task_201609111806_0004_m_000035, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:55:08,443 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000035
2016-09-11 19:55:08,443 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000036_0' to tip task_201609111806_0004_m_000036, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 19:55:08,443 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0004_m_000036
2016-09-11 19:55:09,861 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000022_0' has completed task_201609111806_0004_m_000022 successfully.
2016-09-11 19:55:09,862 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0004_m_000037_0' to tip task_201609111806_0004_m_000037, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:55:09,862 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0004_m_000037
2016-09-11 19:55:22,332 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000010_0' has completed task_201609111806_0004_m_000010 successfully.
2016-09-11 19:55:22,334 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000011_0' has completed task_201609111806_0004_m_000011 successfully.
2016-09-11 19:55:22,334 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000012_0' has completed task_201609111806_0004_m_000012 successfully.
2016-09-11 19:55:23,453 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000003_0' has completed task_201609111806_0004_m_000003 successfully.
2016-09-11 19:55:23,534 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000019_0' has completed task_201609111806_0004_m_000019 successfully.
2016-09-11 19:55:23,536 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000020_0' has completed task_201609111806_0004_m_000020 successfully.
2016-09-11 19:55:23,536 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000021_0' has completed task_201609111806_0004_m_000021 successfully.
2016-09-11 19:55:25,339 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000013_0' has completed task_201609111806_0004_m_000013 successfully.
2016-09-11 19:55:25,757 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000007_0' has completed task_201609111806_0004_m_000007 successfully.
2016-09-11 19:55:28,348 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000014_0' has completed task_201609111806_0004_m_000014 successfully.
2016-09-11 19:55:31,511 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000006_0' has completed task_201609111806_0004_m_000006 successfully.
2016-09-11 19:55:31,512 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000009_0' has completed task_201609111806_0004_m_000009 successfully.
2016-09-11 19:55:31,512 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000023_0' has completed task_201609111806_0004_m_000023 successfully.
2016-09-11 19:55:35,274 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000028_0' has completed task_201609111806_0004_m_000028 successfully.
2016-09-11 19:56:11,802 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000031_0' has completed task_201609111806_0004_m_000031 successfully.
2016-09-11 19:56:14,553 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000036_0' has completed task_201609111806_0004_m_000036 successfully.
2016-09-11 19:56:14,808 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000029_0' has completed task_201609111806_0004_m_000029 successfully.
2016-09-11 19:56:16,033 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000027_0' has completed task_201609111806_0004_m_000027 successfully.
2016-09-11 19:56:25,042 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000026_0' has completed task_201609111806_0004_m_000026 successfully.
2016-09-11 19:56:25,372 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000032_0' has completed task_201609111806_0004_m_000032 successfully.
2016-09-11 19:56:25,373 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000033_0' has completed task_201609111806_0004_m_000033 successfully.
2016-09-11 19:56:43,169 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000030_0' has completed task_201609111806_0004_m_000030 successfully.
2016-09-11 19:56:47,380 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000037_0' has completed task_201609111806_0004_m_000037 successfully.
2016-09-11 19:56:54,521 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000035_0' has completed task_201609111806_0004_m_000035 successfully.
2016-09-11 19:57:00,526 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000034_0' has completed task_201609111806_0004_m_000034 successfully.
2016-09-11 19:57:58,426 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_r_000004_0' has completed task_201609111806_0004_r_000004 successfully.
2016-09-11 19:58:26,745 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_r_000000_0' has completed task_201609111806_0004_r_000000 successfully.
2016-09-11 19:58:28,425 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_r_000002_0' has completed task_201609111806_0004_r_000002 successfully.
2016-09-11 19:58:40,843 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_r_000001_0' has completed task_201609111806_0004_r_000001 successfully.
2016-09-11 19:59:05,434 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_r_000003_0' has completed task_201609111806_0004_r_000003 successfully.
2016-09-11 19:59:05,435 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0004_m_000038_0' to tip task_201609111806_0004_m_000038, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 19:59:14,441 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0004_m_000038_0' has completed task_201609111806_0004_m_000038 successfully.
2016-09-11 19:59:14,441 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0004 has completed successfully.
2016-09-11 19:59:14,441 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0004,submitTime=1473603807142,launchTime=1473603807278,finishTime=1473604154441,numMaps=38,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=3423,reduceSlotsSeconds=1338,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 19:59:14,556 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0004_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0004_hduser
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000006_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000007_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000009_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000022_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000023_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000037_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000038_0'
2016-09-11 19:59:14,557 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_r_000003_0'
2016-09-11 19:59:14,561 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0004_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0004_conf.xml
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0004_conf.xml
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000000_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000001_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000002_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000003_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000004_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000005_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000008_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000010_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000011_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000012_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000013_0'
2016-09-11 19:59:14,563 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000014_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000015_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000016_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000017_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000018_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000019_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000020_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000021_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000024_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000025_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000026_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000027_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000028_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000029_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000030_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000031_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000032_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000033_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000034_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000035_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000036_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_r_000000_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_r_000001_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_r_000002_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_r_000004_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0004_m_000039_0'
2016-09-11 19:59:14,564 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0004' of user 'hduser'
2016-09-11 19:59:40,814 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0004.   Cache size is 3
2016-09-11 20:07:26,363 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0001.info]
2016-09-11 20:07:26,384 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0002.info]
2016-09-11 20:08:42,424 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0005 added successfully for user 'hduser' to queue 'default'
2016-09-11 20:08:42,424 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0005
2016-09-11 20:08:42,424 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0005
2016-09-11 20:08:42,425 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0005_hduser
2016-09-11 20:08:42,428 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0005_conf.xml
2016-09-11 20:08:42,457 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0005/jobToken
2016-09-11 20:08:42,459 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0005 = 0. Number of splits = 5
2016-09-11 20:08:42,459 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0005 initialized successfully with 5 map tasks and 0 reduce tasks.
2016-09-11 20:08:42,841 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0005_m_000006_0' to tip task_201609111806_0005_m_000006, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:08:48,904 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000006_0' has completed task_201609111806_0005_m_000006 successfully.
2016-09-11 20:08:48,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0005_m_000000
2016-09-11 20:08:48,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0005_m_000000_0' to tip task_201609111806_0005_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:08:49,688 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0005_m_000001
2016-09-11 20:08:49,688 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0005_m_000001_0' to tip task_201609111806_0005_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:08:49,799 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0005_m_000002
2016-09-11 20:08:49,799 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0005_m_000002_0' to tip task_201609111806_0005_m_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:08:50,108 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0005_m_000003
2016-09-11 20:08:50,108 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0005_m_000003_0' to tip task_201609111806_0005_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:08:50,986 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0005_m_000004
2016-09-11 20:08:50,986 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0005_m_000004_0' to tip task_201609111806_0005_m_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:11:33,508 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000000_0' has completed task_201609111806_0005_m_000000 successfully.
2016-09-11 20:11:44,389 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000001_0' has completed task_201609111806_0005_m_000001 successfully.
2016-09-11 20:11:58,000 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000002_0' has completed task_201609111806_0005_m_000002 successfully.
2016-09-11 20:12:11,552 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000003_0' has completed task_201609111806_0005_m_000003 successfully.
2016-09-11 20:12:21,550 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000004_0' has completed task_201609111806_0005_m_000004 successfully.
2016-09-11 20:12:21,551 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0005_m_000005_0' to tip task_201609111806_0005_m_000005, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:12:24,554 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0005_m_000005_0' has completed task_201609111806_0005_m_000005 successfully.
2016-09-11 20:12:24,555 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0005 has completed successfully.
2016-09-11 20:12:24,555 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0005,submitTime=1473604722374,launchTime=1473604722459,finishTime=1473604944555,numMaps=5,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=930,reduceSlotsSeconds=0,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 20:12:24,587 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0005_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0005_hduser
2016-09-11 20:12:24,587 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000004_0'
2016-09-11 20:12:24,587 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000005_0'
2016-09-11 20:12:24,591 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0005_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0005_conf.xml
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0005_conf.xml
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000000_0'
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000001_0'
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000002_0'
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000003_0'
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0005_m_000006_0'
2016-09-11 20:12:24,594 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0005' of user 'hduser'
2016-09-11 20:13:37,772 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0006 added successfully for user 'hduser' to queue 'default'
2016-09-11 20:13:37,772 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0006
2016-09-11 20:13:37,772 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0006
2016-09-11 20:13:37,774 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0006_hduser
2016-09-11 20:13:37,776 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0006_conf.xml
2016-09-11 20:13:37,805 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0006/jobToken
2016-09-11 20:13:37,807 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0006 = 0. Number of splits = 5
2016-09-11 20:13:37,808 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0006 initialized successfully with 5 map tasks and 0 reduce tasks.
2016-09-11 20:13:38,444 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0006_m_000006_0' to tip task_201609111806_0006_m_000006, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:13:41,448 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000006_0' has completed task_201609111806_0006_m_000006 successfully.
2016-09-11 20:13:41,449 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0006_m_000000
2016-09-11 20:13:41,449 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0006_m_000000_0' to tip task_201609111806_0006_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:13:41,595 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0006_m_000001
2016-09-11 20:13:41,595 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0006_m_000001_0' to tip task_201609111806_0006_m_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:13:42,620 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0006_m_000002
2016-09-11 20:13:42,620 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0006_m_000002_0' to tip task_201609111806_0006_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:13:42,640 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0006_m_000003
2016-09-11 20:13:42,640 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0006_m_000003_0' to tip task_201609111806_0006_m_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:13:43,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0006_m_000004
2016-09-11 20:13:43,054 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0006_m_000004_0' to tip task_201609111806_0006_m_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:19:57,098 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000000_0' has completed task_201609111806_0006_m_000000 successfully.
2016-09-11 20:20:49,199 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000002_0' has completed task_201609111806_0006_m_000002 successfully.
2016-09-11 20:20:52,442 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000001_0' has completed task_201609111806_0006_m_000001 successfully.
2016-09-11 20:21:09,437 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000004_0' has completed task_201609111806_0006_m_000004 successfully.
2016-09-11 20:21:10,798 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000003_0' has completed task_201609111806_0006_m_000003 successfully.
2016-09-11 20:21:10,798 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0006_m_000005_0' to tip task_201609111806_0006_m_000005, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:21:13,802 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0006_m_000005_0' has completed task_201609111806_0006_m_000005 successfully.
2016-09-11 20:21:13,803 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0006 has completed successfully.
2016-09-11 20:21:13,803 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0006,submitTime=1473605017723,launchTime=1473605017807,finishTime=1473605473803,numMaps=5,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2114,reduceSlotsSeconds=0,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 20:21:13,877 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0006_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0006_hduser
2016-09-11 20:21:13,877 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000003_0'
2016-09-11 20:21:13,877 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000005_0'
2016-09-11 20:21:13,880 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0006_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0006_conf.xml
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0006_conf.xml
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000000_0'
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000001_0'
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000002_0'
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000004_0'
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0006_m_000006_0'
2016-09-11 20:21:13,891 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0006' of user 'hduser'
2016-09-11 20:21:41,572 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0006.   Cache size is 4
2016-09-11 20:22:33,214 INFO org.apache.hadoop.conf.Configuration: found resource webapps/static/jobconf.xsl at file:/usr/local/hadoop-0.21.0/webapps/static/jobconf.xsl
2016-09-11 20:23:00,492 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0005.   Cache size is 5
2016-09-11 20:23:00,492 INFO org.apache.hadoop.mapred.JSPUtil: Job History file removed form cache job_201609111806_0002
2016-09-11 20:23:00,492 INFO org.apache.hadoop.conf.Configuration: found resource webapps/static/jobconf.xsl at file:/usr/local/hadoop-0.21.0/webapps/static/jobconf.xsl
2016-09-11 20:23:11,563 INFO org.apache.hadoop.conf.Configuration: found resource webapps/static/jobconf.xsl at file:/usr/local/hadoop-0.21.0/webapps/static/jobconf.xsl
2016-09-11 20:23:47,034 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0002.   Cache size is 5
2016-09-11 20:23:47,034 INFO org.apache.hadoop.mapred.JSPUtil: Job History file removed form cache job_201609111806_0001
2016-09-11 20:33:11,523 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0007 added successfully for user 'hduser' to queue 'default'
2016-09-11 20:33:11,523 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0007
2016-09-11 20:33:11,523 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0007
2016-09-11 20:33:11,525 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0007_hduser
2016-09-11 20:33:11,528 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0007_conf.xml
2016-09-11 20:33:11,556 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0007/jobToken
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0007 = 20000000000. Number of splits = 40
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000000 has split on node:/default-rack/slave4
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000001 has split on node:/default-rack/slave4
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000002 has split on node:/default-rack/slave4
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000003 has split on node:/default-rack/slave4
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000004 has split on node:/default-rack/slave4
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000005 has split on node:/default-rack/slave1
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000006 has split on node:/default-rack/slave1
2016-09-11 20:33:11,559 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000007 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000008 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000009 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000010 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000011 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000012 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000013 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000014 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000015 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000016 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000017 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000018 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000019 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000020 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000021 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000022 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000023 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000023 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000023 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000024 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000024 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000024 has split on node:/default-rack/slave4
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000025 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000025 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000025 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000026 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000026 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000026 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000027 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000027 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000027 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000028 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000028 has split on node:/default-rack/slave4
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000028 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000029 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000029 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000029 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000030 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000030 has split on node:/default-rack/slave4
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000030 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000031 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000031 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000031 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000032 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000032 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000032 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000033 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000033 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000033 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000034 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000034 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000034 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000035 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000036 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000037 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000037 has split on node:/default-rack/slave4
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000037 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000038 has split on node:/default-rack/slave1
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000038 has split on node:/default-rack/slave3
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000038 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000039 has split on node:/default-rack/slave2
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000039 has split on node:/default-rack/slave4
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0007_m_000039 has split on node:/default-rack/slave5
2016-09-11 20:33:11,560 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0007 initialized successfully with 40 map tasks and 5 reduce tasks.
2016-09-11 20:33:11,735 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0007_m_000041_0' to tip task_201609111806_0007_m_000041, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:33:20,979 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000041_0' has completed task_201609111806_0007_m_000041 successfully.
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000000_0' to tip task_201609111806_0007_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000000
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000001_0' to tip task_201609111806_0007_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000001
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000002_0' to tip task_201609111806_0007_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000002
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000003_0' to tip task_201609111806_0007_m_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000003
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000004_0' to tip task_201609111806_0007_m_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:33:20,980 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000004
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000007_0' to tip task_201609111806_0007_m_000007, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000007
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000008_0' to tip task_201609111806_0007_m_000008, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000008
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000009_0' to tip task_201609111806_0007_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000009
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000012_0' to tip task_201609111806_0007_m_000012, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000012
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000017_0' to tip task_201609111806_0007_m_000017, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:33:21,439 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000017
2016-09-11 20:33:21,824 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000010_0' to tip task_201609111806_0007_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:33:21,824 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000010
2016-09-11 20:33:21,824 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000013_0' to tip task_201609111806_0007_m_000013, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:33:21,824 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000013
2016-09-11 20:33:21,824 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000016_0' to tip task_201609111806_0007_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:33:21,825 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000016
2016-09-11 20:33:21,825 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000019_0' to tip task_201609111806_0007_m_000019, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:33:21,825 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000019
2016-09-11 20:33:21,825 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000020_0' to tip task_201609111806_0007_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:33:21,825 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000020
2016-09-11 20:33:23,357 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000011_0' to tip task_201609111806_0007_m_000011, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:33:23,357 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000011
2016-09-11 20:33:23,357 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000014_0' to tip task_201609111806_0007_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:33:23,357 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000014
2016-09-11 20:33:23,357 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000015_0' to tip task_201609111806_0007_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:33:23,357 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000015
2016-09-11 20:33:23,358 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000018_0' to tip task_201609111806_0007_m_000018, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:33:23,358 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000018
2016-09-11 20:33:23,358 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000023_0' to tip task_201609111806_0007_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:33:23,358 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000023
2016-09-11 20:33:23,854 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000005_0' to tip task_201609111806_0007_m_000005, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:33:23,854 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000005
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000006_0' to tip task_201609111806_0007_m_000006, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000006
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000021_0' to tip task_201609111806_0007_m_000021, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000021
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000022_0' to tip task_201609111806_0007_m_000022, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000022
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000025_0' to tip task_201609111806_0007_m_000025, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:33:23,855 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000025
2016-09-11 20:34:28,755 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000016_0' has completed task_201609111806_0007_m_000016 successfully.
2016-09-11 20:34:28,756 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000019_0' has completed task_201609111806_0007_m_000019 successfully.
2016-09-11 20:34:28,757 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000027_0' to tip task_201609111806_0007_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:34:28,757 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000027
2016-09-11 20:34:28,757 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000028_0' to tip task_201609111806_0007_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:34:28,757 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000028
2016-09-11 20:34:28,757 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0007_r_000000_0' to tip task_201609111806_0007_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:34:29,097 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0007_r_000001_0' to tip task_201609111806_0007_r_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:34:30,659 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0007_r_000002_0' to tip task_201609111806_0007_r_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:34:30,682 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0007_r_000003_0' to tip task_201609111806_0007_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:34:30,820 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0007_r_000004_0' to tip task_201609111806_0007_r_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:34:50,236 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000010_0' has completed task_201609111806_0007_m_000010 successfully.
2016-09-11 20:34:50,236 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000020_0' has completed task_201609111806_0007_m_000020 successfully.
2016-09-11 20:34:50,237 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000029_0' to tip task_201609111806_0007_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:34:50,237 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000029
2016-09-11 20:34:50,237 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000031_0' to tip task_201609111806_0007_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:34:50,237 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000031
2016-09-11 20:35:02,472 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000013_0' has completed task_201609111806_0007_m_000013 successfully.
2016-09-11 20:35:02,473 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000033_0' to tip task_201609111806_0007_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:35:02,473 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000033
2016-09-11 20:35:37,334 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000000_0' has completed task_201609111806_0007_m_000000 successfully.
2016-09-11 20:35:37,334 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000024_0' to tip task_201609111806_0007_m_000024, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:35:37,334 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000024
2016-09-11 20:36:03,113 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000017_0' has completed task_201609111806_0007_m_000017 successfully.
2016-09-11 20:36:03,113 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000026_0' to tip task_201609111806_0007_m_000026, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:36:03,114 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000026
2016-09-11 20:36:06,116 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000009_0' has completed task_201609111806_0007_m_000009 successfully.
2016-09-11 20:36:06,116 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000032_0' to tip task_201609111806_0007_m_000032, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:36:06,116 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000032
2016-09-11 20:36:10,648 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000012_0' has completed task_201609111806_0007_m_000012 successfully.
2016-09-11 20:36:10,648 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000038_0' to tip task_201609111806_0007_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:36:10,648 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000038
2016-09-11 20:36:16,567 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000008_0' has completed task_201609111806_0007_m_000008 successfully.
2016-09-11 20:36:16,567 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000030_0' to tip task_201609111806_0007_m_000030, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:36:16,567 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0007_m_000030
2016-09-11 20:36:25,726 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000007_0' has completed task_201609111806_0007_m_000007 successfully.
2016-09-11 20:36:25,726 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000034_0' to tip task_201609111806_0007_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:36:25,726 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0007_m_000034
2016-09-11 20:36:56,289 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000027_0' has completed task_201609111806_0007_m_000027 successfully.
2016-09-11 20:36:56,289 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000028_0' has completed task_201609111806_0007_m_000028 successfully.
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000031_0' has completed task_201609111806_0007_m_000031 successfully.
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000037_0' to tip task_201609111806_0007_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000037
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000039_0' to tip task_201609111806_0007_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0007_m_000039
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000035_0' to tip task_201609111806_0007_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:36:56,290 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0007_m_000035
2016-09-11 20:36:57,030 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000038_0' has completed task_201609111806_0007_m_000038 successfully.
2016-09-11 20:36:57,031 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0007_m_000036_0' to tip task_201609111806_0007_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:36:57,031 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0007_m_000036
2016-09-11 20:37:19,859 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000033_0' has completed task_201609111806_0007_m_000033 successfully.
2016-09-11 20:37:21,441 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000004_0' has completed task_201609111806_0007_m_000004 successfully.
2016-09-11 20:37:25,864 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000029_0' has completed task_201609111806_0007_m_000029 successfully.
2016-09-11 20:37:28,691 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000003_0' has completed task_201609111806_0007_m_000003 successfully.
2016-09-11 20:37:30,618 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000032_0' has completed task_201609111806_0007_m_000032 successfully.
2016-09-11 20:37:30,618 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000036_0' has completed task_201609111806_0007_m_000036 successfully.
2016-09-11 20:37:33,620 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000026_0' has completed task_201609111806_0007_m_000026 successfully.
2016-09-11 20:37:42,133 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000001_0' has completed task_201609111806_0007_m_000001 successfully.
2016-09-11 20:37:48,143 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000002_0' has completed task_201609111806_0007_m_000002 successfully.
2016-09-11 20:38:15,386 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000039_0' has completed task_201609111806_0007_m_000039 successfully.
2016-09-11 20:38:21,390 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000037_0' has completed task_201609111806_0007_m_000037 successfully.
2016-09-11 20:38:21,391 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000035_0' has completed task_201609111806_0007_m_000035 successfully.
2016-09-11 20:39:04,049 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000030_0' has completed task_201609111806_0007_m_000030 successfully.
2016-09-11 20:39:19,993 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000024_0' has completed task_201609111806_0007_m_000024 successfully.
2016-09-11 20:39:30,762 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000006_0' has completed task_201609111806_0007_m_000006 successfully.
2016-09-11 20:39:30,763 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000022_0' has completed task_201609111806_0007_m_000022 successfully.
2016-09-11 20:39:36,209 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000025_0' has completed task_201609111806_0007_m_000025 successfully.
2016-09-11 20:39:53,963 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000005_0' has completed task_201609111806_0007_m_000005 successfully.
2016-09-11 20:39:54,209 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000011_0' has completed task_201609111806_0007_m_000011 successfully.
2016-09-11 20:39:54,209 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000014_0' has completed task_201609111806_0007_m_000014 successfully.
2016-09-11 20:39:54,210 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000018_0' has completed task_201609111806_0007_m_000018 successfully.
2016-09-11 20:39:54,210 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000023_0' has completed task_201609111806_0007_m_000023 successfully.
2016-09-11 20:39:57,301 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000015_0' has completed task_201609111806_0007_m_000015 successfully.
2016-09-11 20:39:59,283 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000021_0' has completed task_201609111806_0007_m_000021 successfully.
2016-09-11 20:43:07,227 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000034_0' has completed task_201609111806_0007_m_000034 successfully.
2016-09-11 20:44:49,556 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_r_000000_0' has completed task_201609111806_0007_r_000000 successfully.
2016-09-11 20:45:25,374 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_r_000002_0' has completed task_201609111806_0007_r_000002 successfully.
2016-09-11 20:48:17,892 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_r_000004_0' has completed task_201609111806_0007_r_000004 successfully.
2016-09-11 20:48:28,956 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_r_000003_0' has completed task_201609111806_0007_r_000003 successfully.
2016-09-11 20:49:03,565 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_r_000001_0' has completed task_201609111806_0007_r_000001 successfully.
2016-09-11 20:49:03,566 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0007_m_000040_0' to tip task_201609111806_0007_m_000040, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:49:12,574 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0007_m_000040_0' has completed task_201609111806_0007_m_000040 successfully.
2016-09-11 20:49:12,574 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0007 has completed successfully.
2016-09-11 20:49:12,574 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0007,submitTime=1473606191473,launchTime=1473606191560,finishTime=1473607152574,numMaps=40,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=8167,reduceSlotsSeconds=3790,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0007_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0007_hduser
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000011_0'
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000014_0'
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000015_0'
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000018_0'
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000023_0'
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000040_0'
2016-09-11 20:49:12,642 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_r_000001_0'
2016-09-11 20:49:12,650 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0007_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0007_conf.xml
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0007_conf.xml
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000000_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000001_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000002_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000003_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000004_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000005_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000006_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000007_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000008_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000009_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000010_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000012_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000013_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000016_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000017_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000019_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000020_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000021_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000022_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000024_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000025_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000026_0'
2016-09-11 20:49:12,661 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000027_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000028_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000029_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000030_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000031_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000032_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000033_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000034_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000035_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000036_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000037_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000038_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000039_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_r_000000_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_r_000002_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_r_000003_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_r_000004_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0007_m_000041_0'
2016-09-11 20:49:12,662 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0007' of user 'hduser'
2016-09-11 20:49:15,034 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0008 added successfully for user 'hduser' to queue 'default'
2016-09-11 20:49:15,034 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0008
2016-09-11 20:49:15,034 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0008
2016-09-11 20:49:15,035 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0008_hduser
2016-09-11 20:49:15,037 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0008_conf.xml
2016-09-11 20:49:15,067 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0008/jobToken
2016-09-11 20:49:15,073 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0008 = 40000000000. Number of splits = 75
2016-09-11 20:49:15,073 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000000 has split on node:/default-rack/slave3
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000001 has split on node:/default-rack/slave3
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000002 has split on node:/default-rack/slave3
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000003 has split on node:/default-rack/slave3
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000004 has split on node:/default-rack/slave3
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000005 has split on node:/default-rack/slave4
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000006 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000007 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000008 has split on node:/default-rack/slave4
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000009 has split on node:/default-rack/slave4
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000010 has split on node:/default-rack/slave4
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000011 has split on node:/default-rack/slave5
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000012 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000013 has split on node:/default-rack/slave4
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000014 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000015 has split on node:/default-rack/slave5
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000016 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000017 has split on node:/default-rack/slave1
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000018 has split on node:/default-rack/slave1
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000019 has split on node:/default-rack/slave1
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000020 has split on node:/default-rack/slave1
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000021 has split on node:/default-rack/slave5
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000022 has split on node:/default-rack/slave5
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000023 has split on node:/default-rack/slave5
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000024 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000024 has split on node:/default-rack/slave1
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000024 has split on node:/default-rack/slave4
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000025 has split on node:/default-rack/slave2
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000025 has split on node:/default-rack/slave5
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000025 has split on node:/default-rack/slave1
2016-09-11 20:49:15,074 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000026 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000026 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000026 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000027 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000027 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000027 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000028 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000028 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000028 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000029 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000029 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000029 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000030 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000030 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000030 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000031 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000031 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000031 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000032 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000032 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000032 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000033 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000033 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000033 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000034 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000034 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000034 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000035 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000035 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000035 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000036 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000036 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000036 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000037 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000037 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000037 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000038 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000038 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000038 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000039 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000039 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000039 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000040 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000040 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000040 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000041 has split on node:/default-rack/slave4
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000041 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000041 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000042 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000042 has split on node:/default-rack/slave3
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000042 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000043 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000043 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000043 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000044 has split on node:/default-rack/slave5
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000044 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000044 has split on node:/default-rack/slave2
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000045 has split on node:/default-rack/slave1
2016-09-11 20:49:15,075 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000045 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000045 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000046 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000046 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000046 has split on node:/default-rack/slave3
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000047 has split on node:/default-rack/slave3
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000047 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000047 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000048 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000048 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000048 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000049 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000049 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000049 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000050 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000050 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000050 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000051 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000051 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000051 has split on node:/default-rack/slave3
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000052 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000052 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000052 has split on node:/default-rack/slave3
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000053 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000053 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000053 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000054 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000054 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000054 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000055 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000055 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000055 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000056 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000056 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000056 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000057 has split on node:/default-rack/slave3
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000057 has split on node:/default-rack/slave2
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000057 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000058 has split on node:/default-rack/slave4
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000058 has split on node:/default-rack/slave5
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000058 has split on node:/default-rack/slave1
2016-09-11 20:49:15,076 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000059 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000059 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000059 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000060 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000060 has split on node:/default-rack/slave5
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000060 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000061 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000061 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000061 has split on node:/default-rack/slave5
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000062 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000062 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000062 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000063 has split on node:/default-rack/slave5
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000063 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000063 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000064 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000064 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000064 has split on node:/default-rack/slave5
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000065 has split on node:/default-rack/slave3
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000065 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000065 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000066 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000066 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000066 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000067 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000067 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000067 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000068 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000068 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000068 has split on node:/default-rack/slave3
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000069 has split on node:/default-rack/slave3
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000069 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000069 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000070 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000071 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000071 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000071 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000072 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000072 has split on node:/default-rack/slave5
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000072 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000073 has split on node:/default-rack/slave5
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000073 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000073 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000074 has split on node:/default-rack/slave4
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000074 has split on node:/default-rack/slave2
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609111806_0008_m_000074 has split on node:/default-rack/slave1
2016-09-11 20:49:15,077 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0008 initialized successfully with 75 map tasks and 5 reduce tasks.
2016-09-11 20:49:15,147 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0008_m_000076_0' to tip task_201609111806_0008_m_000076, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:49:21,151 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000076_0' has completed task_201609111806_0008_m_000076 successfully.
2016-09-11 20:49:21,153 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000017_0' to tip task_201609111806_0008_m_000017, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000017
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000018_0' to tip task_201609111806_0008_m_000018, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000018
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000019_0' to tip task_201609111806_0008_m_000019, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000019
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000020_0' to tip task_201609111806_0008_m_000020, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000020
2016-09-11 20:49:21,154 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000024_0' to tip task_201609111806_0008_m_000024, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:49:21,155 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000024
2016-09-11 20:49:21,648 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000011_0' to tip task_201609111806_0008_m_000011, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000011
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000015_0' to tip task_201609111806_0008_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000015
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000021_0' to tip task_201609111806_0008_m_000021, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000021
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000022_0' to tip task_201609111806_0008_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000022
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000023_0' to tip task_201609111806_0008_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:49:21,649 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000023
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000000_0' to tip task_201609111806_0008_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000000
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000001_0' to tip task_201609111806_0008_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000001
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000002_0' to tip task_201609111806_0008_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000002
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000003_0' to tip task_201609111806_0008_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000003
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000004_0' to tip task_201609111806_0008_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:49:22,482 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000004
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000006_0' to tip task_201609111806_0008_m_000006, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000006
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000007_0' to tip task_201609111806_0008_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000007
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000012_0' to tip task_201609111806_0008_m_000012, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000012
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000014_0' to tip task_201609111806_0008_m_000014, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000014
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000016_0' to tip task_201609111806_0008_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:49:22,713 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000016
2016-09-11 20:49:23,174 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000005_0' to tip task_201609111806_0008_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:49:23,174 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000005
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000008_0' to tip task_201609111806_0008_m_000008, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000008
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000009_0' to tip task_201609111806_0008_m_000009, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000009
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000010_0' to tip task_201609111806_0008_m_000010, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000010
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000013_0' to tip task_201609111806_0008_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:49:23,175 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000013
2016-09-11 20:50:59,612 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000006_0' has completed task_201609111806_0008_m_000006 successfully.
2016-09-11 20:50:59,613 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000007_0' has completed task_201609111806_0008_m_000007 successfully.
2016-09-11 20:50:59,613 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000016_0' has completed task_201609111806_0008_m_000016 successfully.
2016-09-11 20:50:59,614 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000025_0' to tip task_201609111806_0008_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:50:59,614 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000025
2016-09-11 20:50:59,614 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000026_0' to tip task_201609111806_0008_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:50:59,614 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000026
2016-09-11 20:50:59,614 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000027_0' to tip task_201609111806_0008_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:50:59,615 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000027
2016-09-11 20:51:17,288 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000003_0' has completed task_201609111806_0008_m_000003 successfully.
2016-09-11 20:51:17,289 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000028_0' to tip task_201609111806_0008_m_000028, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:51:17,289 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000028
2016-09-11 20:51:17,290 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0008_r_000000_0' to tip task_201609111806_0008_r_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:51:19,014 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0008_r_000001_0' to tip task_201609111806_0008_r_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:51:19,420 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0008_r_000002_0' to tip task_201609111806_0008_r_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:51:20,840 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0008_r_000003_0' to tip task_201609111806_0008_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:51:21,433 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609111806_0008_r_000004_0' to tip task_201609111806_0008_r_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:51:23,373 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000014_0' has completed task_201609111806_0008_m_000014 successfully.
2016-09-11 20:51:23,373 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000029_0' to tip task_201609111806_0008_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:51:23,374 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000029
2016-09-11 20:51:26,427 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000001_0' has completed task_201609111806_0008_m_000001 successfully.
2016-09-11 20:51:26,428 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000031_0' to tip task_201609111806_0008_m_000031, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:51:26,428 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000031
2016-09-11 20:51:30,477 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000012_0' has completed task_201609111806_0008_m_000012 successfully.
2016-09-11 20:51:30,477 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000030_0' to tip task_201609111806_0008_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:51:30,477 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000030
2016-09-11 20:51:33,998 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000002_0' has completed task_201609111806_0008_m_000002 successfully.
2016-09-11 20:51:33,998 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000033_0' to tip task_201609111806_0008_m_000033, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:51:33,998 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000033
2016-09-11 20:51:39,020 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000004_0' has completed task_201609111806_0008_m_000004 successfully.
2016-09-11 20:51:39,021 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000042_0' to tip task_201609111806_0008_m_000042, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:51:39,022 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000042
2016-09-11 20:51:44,224 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000000_0' has completed task_201609111806_0008_m_000000 successfully.
2016-09-11 20:51:44,224 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000046_0' to tip task_201609111806_0008_m_000046, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:51:44,224 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000046
2016-09-11 20:53:20,900 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000026_0' has completed task_201609111806_0008_m_000026 successfully.
2016-09-11 20:53:20,901 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000027_0' has completed task_201609111806_0008_m_000027 successfully.
2016-09-11 20:53:20,901 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000032_0' to tip task_201609111806_0008_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:53:20,901 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000032
2016-09-11 20:53:20,901 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000034_0' to tip task_201609111806_0008_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:53:20,901 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000034
2016-09-11 20:53:29,451 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000008_0' has completed task_201609111806_0008_m_000008 successfully.
2016-09-11 20:53:29,452 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000037_0' to tip task_201609111806_0008_m_000037, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:53:29,452 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000037
2016-09-11 20:53:30,747 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000025_0' has completed task_201609111806_0008_m_000025 successfully.
2016-09-11 20:53:30,749 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000035_0' to tip task_201609111806_0008_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:53:30,749 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000035
2016-09-11 20:53:33,580 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000028_0' has completed task_201609111806_0008_m_000028 successfully.
2016-09-11 20:53:33,580 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000047_0' to tip task_201609111806_0008_m_000047, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:53:33,580 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000047
2016-09-11 20:53:39,754 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000029_0' has completed task_201609111806_0008_m_000029 successfully.
2016-09-11 20:53:39,754 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000036_0' to tip task_201609111806_0008_m_000036, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:53:39,754 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000036
2016-09-11 20:53:40,872 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000020_0' has completed task_201609111806_0008_m_000020 successfully.
2016-09-11 20:53:40,873 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000038_0' to tip task_201609111806_0008_m_000038, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:53:40,873 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000038
2016-09-11 20:53:47,999 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000030_0' has completed task_201609111806_0008_m_000030 successfully.
2016-09-11 20:53:47,999 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000040_0' to tip task_201609111806_0008_m_000040, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:53:48,000 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000040
2016-09-11 20:53:52,506 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000005_0' has completed task_201609111806_0008_m_000005 successfully.
2016-09-11 20:53:52,507 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000009_0' has completed task_201609111806_0008_m_000009 successfully.
2016-09-11 20:53:52,507 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000010_0' has completed task_201609111806_0008_m_000010 successfully.
2016-09-11 20:53:52,508 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000013_0' has completed task_201609111806_0008_m_000013 successfully.
2016-09-11 20:53:52,509 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000039_0' to tip task_201609111806_0008_m_000039, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:53:52,509 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000039
2016-09-11 20:53:52,510 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000041_0' to tip task_201609111806_0008_m_000041, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:53:52,510 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000041
2016-09-11 20:53:52,510 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000050_0' to tip task_201609111806_0008_m_000050, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:53:52,510 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000050
2016-09-11 20:53:52,510 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000051_0' to tip task_201609111806_0008_m_000051, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 20:53:52,510 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000051
2016-09-11 20:53:55,642 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000042_0' has completed task_201609111806_0008_m_000042 successfully.
2016-09-11 20:53:55,643 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000052_0' to tip task_201609111806_0008_m_000052, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:53:55,643 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000052
2016-09-11 20:54:01,650 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000031_0' has completed task_201609111806_0008_m_000031 successfully.
2016-09-11 20:54:01,650 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000057_0' to tip task_201609111806_0008_m_000057, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:54:01,650 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000057
2016-09-11 20:54:03,502 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000019_0' has completed task_201609111806_0008_m_000019 successfully.
2016-09-11 20:54:03,503 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000043_0' to tip task_201609111806_0008_m_000043, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:54:03,504 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000043
2016-09-11 20:54:06,367 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609111806_0008_m_000043_0 is 2863 ms debug.
2016-09-11 20:54:07,663 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000046_0' has completed task_201609111806_0008_m_000046 successfully.
2016-09-11 20:54:07,663 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000065_0' to tip task_201609111806_0008_m_000065, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:54:07,663 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000065
2016-09-11 20:54:09,743 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000018_0' has completed task_201609111806_0008_m_000018 successfully.
2016-09-11 20:54:09,744 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000044_0' to tip task_201609111806_0008_m_000044, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:54:09,744 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000044
2016-09-11 20:54:11,946 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000033_0' has completed task_201609111806_0008_m_000033 successfully.
2016-09-11 20:54:11,947 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000068_0' to tip task_201609111806_0008_m_000068, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 20:54:11,947 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000068
2016-09-11 20:54:12,774 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000017_0' has completed task_201609111806_0008_m_000017 successfully.
2016-09-11 20:54:12,775 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000024_0' has completed task_201609111806_0008_m_000024 successfully.
2016-09-11 20:54:12,775 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000045_0' to tip task_201609111806_0008_m_000045, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:54:12,775 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000045
2016-09-11 20:54:12,775 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000048_0' to tip task_201609111806_0008_m_000048, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 20:54:12,775 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000048
2016-09-11 20:54:23,758 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000011_0' has completed task_201609111806_0008_m_000011 successfully.
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000015_0' has completed task_201609111806_0008_m_000015 successfully.
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000022_0' has completed task_201609111806_0008_m_000022 successfully.
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000023_0' has completed task_201609111806_0008_m_000023 successfully.
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000049_0' to tip task_201609111806_0008_m_000049, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000049
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000053_0' to tip task_201609111806_0008_m_000053, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000053
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000054_0' to tip task_201609111806_0008_m_000054, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000054
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000055_0' to tip task_201609111806_0008_m_000055, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:54:23,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000055
2016-09-11 20:54:27,156 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000021_0' has completed task_201609111806_0008_m_000021 successfully.
2016-09-11 20:54:27,156 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000058_0' to tip task_201609111806_0008_m_000058, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 20:54:27,156 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000058
2016-09-11 20:59:28,948 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000034_0' has completed task_201609111806_0008_m_000034 successfully.
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000035_0' has completed task_201609111806_0008_m_000035 successfully.
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000036_0' has completed task_201609111806_0008_m_000036 successfully.
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000056_0' to tip task_201609111806_0008_m_000056, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000056
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000059_0' to tip task_201609111806_0008_m_000059, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000059
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000062_0' to tip task_201609111806_0008_m_000062, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 20:59:28,949 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000062
2016-09-11 21:00:00,581 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000032_0' has completed task_201609111806_0008_m_000032 successfully.
2016-09-11 21:00:00,581 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000064_0' to tip task_201609111806_0008_m_000064, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 21:00:00,581 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000064
2016-09-11 21:00:31,668 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000040_0' has completed task_201609111806_0008_m_000040 successfully.
2016-09-11 21:00:31,669 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000066_0' to tip task_201609111806_0008_m_000066, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 21:00:31,669 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000066
2016-09-11 21:01:22,395 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000047_0' has completed task_201609111806_0008_m_000047 successfully.
2016-09-11 21:01:22,396 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000069_0' to tip task_201609111806_0008_m_000069, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 21:01:22,404 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000069
2016-09-11 21:01:50,950 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000057_0' has completed task_201609111806_0008_m_000057 successfully.
2016-09-11 21:01:50,951 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000060_0' to tip task_201609111806_0008_m_000060, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 21:01:50,951 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0008_m_000060
2016-09-11 21:02:04,085 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000065_0' has completed task_201609111806_0008_m_000065 successfully.
2016-09-11 21:02:04,085 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000068_0' has completed task_201609111806_0008_m_000068 successfully.
2016-09-11 21:02:04,086 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000061_0' to tip task_201609111806_0008_m_000061, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 21:02:04,086 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0008_m_000061
2016-09-11 21:02:04,086 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000063_0' to tip task_201609111806_0008_m_000063, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 21:02:04,086 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0008_m_000063
2016-09-11 21:02:07,267 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000052_0' has completed task_201609111806_0008_m_000052 successfully.
2016-09-11 21:02:07,269 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000067_0' to tip task_201609111806_0008_m_000067, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 21:02:07,269 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0008_m_000067
2016-09-11 21:02:11,398 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000048_0' has completed task_201609111806_0008_m_000048 successfully.
2016-09-11 21:02:11,398 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000070_0' to tip task_201609111806_0008_m_000070, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 21:02:11,398 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000070
2016-09-11 21:02:18,304 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000039_0' has completed task_201609111806_0008_m_000039 successfully.
2016-09-11 21:02:18,305 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000041_0' has completed task_201609111806_0008_m_000041 successfully.
2016-09-11 21:02:18,306 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000050_0' has completed task_201609111806_0008_m_000050 successfully.
2016-09-11 21:02:18,306 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000051_0' has completed task_201609111806_0008_m_000051 successfully.
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000071_0' to tip task_201609111806_0008_m_000071, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000071
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000073_0' to tip task_201609111806_0008_m_000073, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000073
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000074_0' to tip task_201609111806_0008_m_000074, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609111806_0008_m_000074
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0008_m_000072_0' to tip task_201609111806_0008_m_000072, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 21:02:18,308 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609111806_0008_m_000072
2016-09-11 21:02:21,572 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000038_0' has completed task_201609111806_0008_m_000038 successfully.
2016-09-11 21:02:21,573 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000044_0' has completed task_201609111806_0008_m_000044 successfully.
2016-09-11 21:02:21,573 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000045_0' has completed task_201609111806_0008_m_000045 successfully.
2016-09-11 21:02:24,576 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000043_0' has completed task_201609111806_0008_m_000043 successfully.
2016-09-11 21:02:28,037 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000037_0' has completed task_201609111806_0008_m_000037 successfully.
2016-09-11 21:03:18,966 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000056_0' has completed task_201609111806_0008_m_000056 successfully.
2016-09-11 21:03:20,817 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000069_0' has completed task_201609111806_0008_m_000069 successfully.
2016-09-11 21:03:31,367 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000059_0' has completed task_201609111806_0008_m_000059 successfully.
2016-09-11 21:03:31,368 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000066_0' has completed task_201609111806_0008_m_000066 successfully.
2016-09-11 21:03:48,647 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000062_0' has completed task_201609111806_0008_m_000062 successfully.
2016-09-11 21:03:54,155 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000064_0' has completed task_201609111806_0008_m_000064 successfully.
2016-09-11 21:05:00,223 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000055_0' has completed task_201609111806_0008_m_000055 successfully.
2016-09-11 21:05:07,465 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000053_0' has completed task_201609111806_0008_m_000053 successfully.
2016-09-11 21:05:07,466 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000054_0' has completed task_201609111806_0008_m_000054 successfully.
2016-09-11 21:05:07,466 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000058_0' has completed task_201609111806_0008_m_000058 successfully.
2016-09-11 21:05:17,079 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000061_0' has completed task_201609111806_0008_m_000061 successfully.
2016-09-11 21:05:17,817 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000049_0' has completed task_201609111806_0008_m_000049 successfully.
2016-09-11 21:05:53,486 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000067_0' has completed task_201609111806_0008_m_000067 successfully.
2016-09-11 21:06:13,125 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000060_0' has completed task_201609111806_0008_m_000060 successfully.
2016-09-11 21:06:45,559 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000070_0' has completed task_201609111806_0008_m_000070 successfully.
2016-09-11 21:07:22,995 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000063_0' has completed task_201609111806_0008_m_000063 successfully.
2016-09-11 21:07:26,394 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0003.info]
2016-09-11 21:07:26,410 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0004.info]
2016-09-11 21:07:28,614 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000072_0' has completed task_201609111806_0008_m_000072 successfully.
2016-09-11 21:09:09,198 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000071_0' has completed task_201609111806_0008_m_000071 successfully.
2016-09-11 21:09:09,198 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000073_0' has completed task_201609111806_0008_m_000073 successfully.
2016-09-11 21:09:09,199 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000074_0' has completed task_201609111806_0008_m_000074 successfully.
2016-09-11 21:13:53,116 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_r_000002_0' has completed task_201609111806_0008_r_000002 successfully.
2016-09-11 21:15:40,826 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_r_000000_0' has completed task_201609111806_0008_r_000000 successfully.
2016-09-11 21:20:26,795 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0007.   Cache size is 5
2016-09-11 21:20:26,795 INFO org.apache.hadoop.mapred.JSPUtil: Job History file removed form cache job_201609111806_0003
2016-09-11 21:21:05,511 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_r_000001_0' has completed task_201609111806_0008_r_000001 successfully.
2016-09-11 21:23:43,617 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_r_000004_0' has completed task_201609111806_0008_r_000004 successfully.
2016-09-11 21:24:34,734 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_r_000003_0' has completed task_201609111806_0008_r_000003 successfully.
2016-09-11 21:24:34,735 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0008_m_000075_0' to tip task_201609111806_0008_m_000075, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 21:24:40,784 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0008_m_000075_0' has completed task_201609111806_0008_m_000075 successfully.
2016-09-11 21:24:40,784 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0008 has completed successfully.
2016-09-11 21:24:40,784 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0008,submitTime=1473607154959,launchTime=1473607155077,finishTime=1473609280784,numMaps=75,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=23102,reduceSlotsSeconds=8458,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0008_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0008_hduser
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000005_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000008_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000009_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000010_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000013_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000037_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000039_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000041_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000050_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000051_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000071_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000072_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000073_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000074_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000075_0'
2016-09-11 21:24:40,887 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_r_000003_0'
2016-09-11 21:24:40,895 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0008_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0008_conf.xml
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0008_conf.xml
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000000_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000001_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000002_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000003_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000004_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000006_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000007_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000011_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000012_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000014_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000015_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000016_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000017_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000018_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000019_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000020_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000021_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000022_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000023_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000024_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000025_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000026_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000027_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000028_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000029_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000030_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000031_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000032_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000033_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000034_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000035_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000036_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000038_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000040_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000042_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000043_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000044_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000045_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000046_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000047_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000048_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000049_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000052_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000053_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000054_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000055_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000056_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000057_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000058_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000059_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000060_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000061_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000062_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000063_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000064_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000065_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000066_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000067_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000068_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000069_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000070_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_r_000000_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_r_000001_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_r_000002_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_r_000004_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0008_m_000076_0'
2016-09-11 21:24:40,900 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0008' of user 'hduser'
2016-09-11 21:24:42,320 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609111806_0009 added successfully for user 'hduser' to queue 'default'
2016-09-11 21:24:42,320 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609111806_0009
2016-09-11 21:24:42,321 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609111806_0009
2016-09-11 21:24:42,322 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609111806_0009_hduser
2016-09-11 21:24:42,327 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609111806_0009_conf.xml
2016-09-11 21:24:42,354 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609111806_0009/jobToken
2016-09-11 21:24:42,357 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609111806_0009 = 0. Number of splits = 5
2016-09-11 21:24:42,357 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0009 initialized successfully with 5 map tasks and 0 reduce tasks.
2016-09-11 21:24:43,658 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609111806_0009_m_000006_0' to tip task_201609111806_0009_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 21:24:49,687 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000006_0' has completed task_201609111806_0009_m_000006 successfully.
2016-09-11 21:24:49,688 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0009_m_000000
2016-09-11 21:24:49,688 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0009_m_000000_0' to tip task_201609111806_0009_m_000000, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:33185'
2016-09-11 21:24:49,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0009_m_000001
2016-09-11 21:24:49,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0009_m_000001_0' to tip task_201609111806_0009_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 21:24:50,083 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0009_m_000002
2016-09-11 21:24:50,083 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0009_m_000002_0' to tip task_201609111806_0009_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:37567'
2016-09-11 21:24:50,559 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0009_m_000003
2016-09-11 21:24:50,559 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0009_m_000003_0' to tip task_201609111806_0009_m_000003, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 21:24:50,608 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0009_m_000004
2016-09-11 21:24:50,608 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0009_m_000004_0' to tip task_201609111806_0009_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39212'
2016-09-11 21:35:50,713 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609111806_0008.   Cache size is 5
2016-09-11 21:35:50,713 INFO org.apache.hadoop.mapred.JSPUtil: Job History file removed form cache job_201609111806_0006
2016-09-11 21:41:46,727 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000002_0' has completed task_201609111806_0009_m_000002 successfully.
2016-09-11 21:42:59,641 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000000_0' has completed task_201609111806_0009_m_000000 successfully.
2016-09-11 21:43:14,619 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000001_0' has completed task_201609111806_0009_m_000001 successfully.
2016-09-11 21:44:03,964 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000004_0' has completed task_201609111806_0009_m_000004 successfully.
2016-09-11 21:54:06,371 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave2:127.0.0.1/127.0.0.1:34871'
2016-09-11 21:54:06,372 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609111806_0009_m_000003_0 on tracker_slave2:127.0.0.1/127.0.0.1:34871: Lost task tracker: tracker_slave2:127.0.0.1/127.0.0.1:34871
2016-09-11 21:54:06,372 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000003_0'
2016-09-11 21:54:06,599 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609111806_0009_m_000003
2016-09-11 21:54:06,600 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609111806_0009_m_000003_1' to tip task_201609111806_0009_m_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 22:03:57,662 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000003_1' has completed task_201609111806_0009_m_000003 successfully.
2016-09-11 22:03:57,663 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609111806_0009_m_000005_0' to tip task_201609111806_0009_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:34280'
2016-09-11 22:04:34,142 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609111806_0009_m_000005_0' has completed task_201609111806_0009_m_000005 successfully.
2016-09-11 22:04:34,143 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609111806_0009 has completed successfully.
2016-09-11 22:04:34,143 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609111806_0009,submitTime=1473609282171,launchTime=1473609282357,finishTime=1473611674143,numMaps=5,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=6700,reduceSlotsSeconds=0,clusterMapCapacity=20,clusterReduceCapacity=8
2016-09-11 22:04:34,181 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0009_hduser to file:/usr/local/hadoop/logs/history/done/job_201609111806_0009_hduser
2016-09-11 22:04:34,181 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000001_0'
2016-09-11 22:04:34,181 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000003_1'
2016-09-11 22:04:34,181 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000005_0'
2016-09-11 22:04:34,184 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609111806_0009_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609111806_0009_conf.xml
2016-09-11 22:04:34,187 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609111806_0009_conf.xml
2016-09-11 22:04:34,187 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000000_0'
2016-09-11 22:04:34,187 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000002_0'
2016-09-11 22:04:34,187 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000004_0'
2016-09-11 22:04:34,187 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609111806_0009_m_000006_0'
2016-09-11 22:04:34,187 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609111806_0009' of user 'hduser'
2016-09-11 22:07:26,420 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0005.info]
2016-09-11 22:07:26,439 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0006.info]
2016-09-11 22:07:26,447 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0007.info]
2016-09-11 23:07:26,457 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0008.info]
2016-09-11 23:07:26,512 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609111806_0009.info]
