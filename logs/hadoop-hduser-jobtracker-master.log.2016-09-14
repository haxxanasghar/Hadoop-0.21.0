2016-09-14 00:00:27,335 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609132256_0006
2016-09-14 00:00:27,335 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609132256_0006'
2016-09-14 00:00:28,084 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609132256_0006_r_000005_0' to tip task_201609132256_0006_r_000005, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:45424'
2016-09-14 00:00:34,042 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000002_0'
2016-09-14 00:00:39,068 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609132256_0006_m_000003_0' has completed task_201609132256_0006_m_000003 successfully.
2016-09-14 00:00:39,068 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609132256_0006_m_000004_0' has completed task_201609132256_0006_m_000004 successfully.
2016-09-14 00:00:39,069 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609132256_0006_m_000017_0' has completed task_201609132256_0006_m_000017 successfully.
2016-09-14 00:00:39,069 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000006_0'
2016-09-14 00:00:54,090 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000000_0'
2016-09-14 00:01:19,241 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000007_0'
2016-09-14 00:01:19,241 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000014_0'
2016-09-14 00:01:29,712 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000015_0'
2016-09-14 00:01:29,712 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609132256_0006_m_000016_0'
2016-09-14 00:03:35,926 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609132256_0006_r_000005_0 is 187841 ms debug.
2016-09-14 00:06:55,926 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609132256_0006_r_000005_0 is 387842 ms debug.
2016-09-14 00:08:00,993 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609132256_0006
2016-09-14 00:08:00,993 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609132256_0006'
2016-09-14 00:09:58,466 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609132256_0006
2016-09-14 00:09:58,466 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609132256_0006'
2016-09-14 00:10:15,926 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609132256_0006_r_000005_0 is 587842 ms debug.
2016-09-14 00:10:30,504 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 00:10:35,418 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 00:10:35,483 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 00:10:35,485 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 00:10:35,486 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 00:10:35,487 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 00:10:35,487 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 00:10:35,487 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 00:10:35,487 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 00:10:35,493 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 00:10:35,503 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 00:10:35,506 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:10:35,509 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 00:10:35,511 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:10:35,511 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 00:10:35,530 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 00:10:35,552 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 00:10:35,554 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 00:10:35,562 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 00:10:35,563 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 00:10:35,563 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 00:10:35,563 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 00:10:35,681 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 00:10:35,682 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 00:10:35,682 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:10:35,683 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:10:35,683 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 00:10:35,683 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 00:10:35,707 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 00:10:35,768 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:10:35,770 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 452 needs additional 522 blocks to reach the threshold 0.9990 of total blocks 975. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:10:45,772 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:10:45,774 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 975 has reached the threshold 0.9990 of total blocks 975. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:10:55,780 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:10:55,785 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 975 has reached the threshold 0.9990 of total blocks 975. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:11:05,789 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:11:05,792 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 975 has reached the threshold 0.9990 of total blocks 975. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:11:15,795 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:11:15,872 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-14 00:11:15,873 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving log file from last run: file:/usr/local/hadoop/logs/history/job_201609132256_0006_hduser
2016-09-14 00:11:15,873 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609132256_0006_hduser to file:/usr/local/hadoop/logs/history/done/job_201609132256_0006_hduser.201609140010.old
2016-09-14 00:11:15,875 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/usr/local/hadoop/logs/history/job_201609132256_0006_hduser.  Ignoring exception: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:144)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:310)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:482)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:242)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:216)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:167)
	at org.apache.hadoop.fs.LocalFileSystem.copyFromLocalFile(LocalFileSystem.java:60)
	at org.apache.hadoop.fs.FileSystem.moveFromLocalFile(FileSystem.java:1482)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.moveToDoneNow(JobHistory.java:348)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.moveOldFiles(JobHistory.java:390)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.initDone(JobHistory.java:165)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1591)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)

2016-09-14 00:11:15,887 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving log file from last run: file:/usr/local/hadoop/logs/history/job_201609132256_0006_conf.xml
2016-09-14 00:11:15,887 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609132256_0006_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609132256_0006_conf.xml.201609140010.old
2016-09-14 00:11:15,893 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-14 00:11:15,893 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-14 00:11:15,896 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-14 00:11:15,902 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609062321_0002_conf.xml
2016-09-14 00:11:15,910 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609062321_0002_hduser
2016-09-14 00:11:15,910 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609062321_0001_hduser
2016-09-14 00:11:15,910 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Deleting old history file : file:/usr/local/hadoop/logs/history/done/job_201609062321_0001_conf.xml
2016-09-14 00:11:16,027 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-14 00:11:16,034 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-14 00:11:16,034 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-14 00:11:16,034 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 00:11:16,035 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-14 00:11:16,037 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-14 00:11:16,039 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-14 00:11:16,039 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609132256_0001.info]
2016-09-14 00:11:16,047 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-14 00:11:16,048 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-14 00:11:16,048 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-14 00:11:16,050 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-14 00:11:16,051 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-14 00:11:16,058 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-14 00:11:16,059 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-14 00:11:16,060 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-14 00:11:16,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-14 00:11:16,061 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-14 00:11:16,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-14 00:11:16,183 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-14 00:11:16,184 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:45218 to host slave2
2016-09-14 00:11:16,191 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-14 00:11:16,191 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:45820 to host slave1
2016-09-14 00:11:16,201 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-14 00:11:16,201 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:40583 to host slave3
2016-09-14 00:11:16,209 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-14 00:11:16,209 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:37387 to host slave4
2016-09-14 00:11:16,215 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-14 00:11:16,215 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:40201 to host slave5
2016-09-14 00:11:39,839 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-14 00:11:39,931 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140010_0001 added successfully for user 'hduser' to queue 'default'
2016-09-14 00:11:39,932 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140010_0001
2016-09-14 00:11:39,932 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140010_0001
2016-09-14 00:11:39,964 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140010_0001_hduser
2016-09-14 00:11:40,036 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140010_0001_conf.xml
2016-09-14 00:11:40,119 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140010_0001/jobToken
2016-09-14 00:11:40,128 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140010_0001 = 20000000000. Number of splits = 40
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000000 has split on node:/default-rack/slave4
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000001 has split on node:/default-rack/slave2
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000002 has split on node:/default-rack/slave3
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000003 has split on node:/default-rack/slave3
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000004 has split on node:/default-rack/slave2
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000005 has split on node:/default-rack/slave2
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000006 has split on node:/default-rack/slave3
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000007 has split on node:/default-rack/slave4
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000008 has split on node:/default-rack/slave3
2016-09-14 00:11:40,129 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000009 has split on node:/default-rack/slave3
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000010 has split on node:/default-rack/slave2
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000011 has split on node:/default-rack/slave1
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000012 has split on node:/default-rack/slave1
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000013 has split on node:/default-rack/slave1
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000014 has split on node:/default-rack/slave1
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000015 has split on node:/default-rack/slave4
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000016 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000017 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000018 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000019 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000020 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000021 has split on node:/default-rack/slave4
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000022 has split on node:/default-rack/slave4
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000023 has split on node:/default-rack/slave2
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000023 has split on node:/default-rack/slave3
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000023 has split on node:/default-rack/slave1
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000023 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000024 has split on node:/default-rack/slave3
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000024 has split on node:/default-rack/slave1
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000024 has split on node:/default-rack/slave5
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000025 has split on node:/default-rack/slave2
2016-09-14 00:11:40,130 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000025 has split on node:/default-rack/slave3
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000025 has split on node:/default-rack/slave1
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000025 has split on node:/default-rack/slave5
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000026 has split on node:/default-rack/slave1
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000026 has split on node:/default-rack/slave3
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000026 has split on node:/default-rack/slave5
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000027 has split on node:/default-rack/slave5
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000027 has split on node:/default-rack/slave1
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000027 has split on node:/default-rack/slave2
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000028 has split on node:/default-rack/slave1
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000028 has split on node:/default-rack/slave2
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000028 has split on node:/default-rack/slave5
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000029 has split on node:/default-rack/slave3
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000029 has split on node:/default-rack/slave2
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000029 has split on node:/default-rack/slave1
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000029 has split on node:/default-rack/slave5
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000030 has split on node:/default-rack/slave5
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000030 has split on node:/default-rack/slave1
2016-09-14 00:11:40,131 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000030 has split on node:/default-rack/slave3
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000031 has split on node:/default-rack/slave5
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000031 has split on node:/default-rack/slave1
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000031 has split on node:/default-rack/slave2
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000032 has split on node:/default-rack/slave3
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000032 has split on node:/default-rack/slave1
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000032 has split on node:/default-rack/slave5
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000033 has split on node:/default-rack/slave1
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000033 has split on node:/default-rack/slave3
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000033 has split on node:/default-rack/slave5
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000034 has split on node:/default-rack/slave4
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000034 has split on node:/default-rack/slave2
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000034 has split on node:/default-rack/slave1
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000034 has split on node:/default-rack/slave5
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000035 has split on node:/default-rack/slave2
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000036 has split on node:/default-rack/slave1
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000037 has split on node:/default-rack/slave1
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000037 has split on node:/default-rack/slave3
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000037 has split on node:/default-rack/slave2
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000037 has split on node:/default-rack/slave5
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000038 has split on node:/default-rack/slave3
2016-09-14 00:11:40,132 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000038 has split on node:/default-rack/slave1
2016-09-14 00:11:40,133 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000038 has split on node:/default-rack/slave5
2016-09-14 00:11:40,133 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000039 has split on node:/default-rack/slave1
2016-09-14 00:11:40,133 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000039 has split on node:/default-rack/slave3
2016-09-14 00:11:40,133 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000039 has split on node:/default-rack/slave2
2016-09-14 00:11:40,133 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140010_0001_m_000039 has split on node:/default-rack/slave5
2016-09-14 00:11:40,134 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140010_0001 initialized successfully with 40 map tasks and 5 reduce tasks.
2016-09-14 00:11:40,223 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140010_0001_m_000041_0' to tip task_201609140010_0001_m_000041, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:45820'
2016-09-14 00:12:11,220 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 00:12:16,016 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 00:12:16,080 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 00:12:16,083 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 00:12:16,083 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 00:12:16,084 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 00:12:16,084 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 00:12:16,084 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 00:12:16,085 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 00:12:16,090 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 00:12:16,100 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 00:12:16,103 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:16,106 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 00:12:16,108 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:16,108 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 00:12:16,128 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 00:12:16,150 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 00:12:16,152 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 00:12:16,160 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 00:12:16,161 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 00:12:16,161 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 00:12:16,161 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 00:12:16,282 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 00:12:16,283 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 00:12:16,283 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:16,283 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:16,284 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 00:12:16,284 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 00:12:16,308 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 00:12:16,366 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:12:16,368 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 978 has reached the threshold 0.9990 of total blocks 978. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:26,374 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:12:26,376 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 978 has reached the threshold 0.9990 of total blocks 978. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:36,383 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:12:36,387 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 978 has reached the threshold 0.9990 of total blocks 978. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 00:12:46,393 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 00:12:46,478 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-14 00:12:46,480 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving log file from last run: file:/usr/local/hadoop/logs/history/job_201609140010_0001_conf.xml
2016-09-14 00:12:46,480 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140010_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140010_0001_conf.xml.201609140012.old
2016-09-14 00:12:46,498 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving log file from last run: file:/usr/local/hadoop/logs/history/job_201609140010_0001_hduser
2016-09-14 00:12:46,499 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140010_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140010_0001_hduser.201609140012.old
2016-09-14 00:12:46,499 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/usr/local/hadoop/logs/history/job_201609140010_0001_hduser.  Ignoring exception: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:144)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:310)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:482)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:242)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:216)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:167)
	at org.apache.hadoop.fs.LocalFileSystem.copyFromLocalFile(LocalFileSystem.java:60)
	at org.apache.hadoop.fs.FileSystem.moveFromLocalFile(FileSystem.java:1482)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.moveToDoneNow(JobHistory.java:348)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.moveOldFiles(JobHistory.java:390)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.initDone(JobHistory.java:165)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1591)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)

2016-09-14 00:12:46,503 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-14 00:12:46,504 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-14 00:12:46,506 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-14 00:12:46,606 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-14 00:12:46,617 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-14 00:12:46,617 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-14 00:12:46,617 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 00:12:46,617 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-14 00:12:46,622 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-14 00:12:46,630 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-14 00:12:46,626 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-14 00:12:46,626 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-14 00:12:46,630 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-14 00:12:46,639 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-14 00:12:46,640 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-14 00:12:46,640 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-14 00:12:46,640 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-14 00:12:46,640 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-14 00:12:46,640 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-14 00:12:46,639 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-14 00:12:46,639 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-14 00:12:46,730 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-14 00:12:46,731 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:35739 to host slave3
2016-09-14 00:12:46,732 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-14 00:12:46,732 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:36545 to host slave1
2016-09-14 00:12:46,742 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-14 00:12:46,742 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:43794 to host slave5
2016-09-14 00:12:46,744 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-14 00:12:46,745 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:37574 to host slave4
2016-09-14 00:12:46,745 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-14 00:12:46,746 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:33218 to host slave2
2016-09-14 00:13:40,787 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-14 00:13:40,883 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140012_0001 added successfully for user 'hduser' to queue 'default'
2016-09-14 00:13:40,885 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140012_0001
2016-09-14 00:13:40,885 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140012_0001
2016-09-14 00:13:40,921 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140012_0001_hduser
2016-09-14 00:13:40,996 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140012_0001_conf.xml
2016-09-14 00:13:41,049 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140012_0001/jobToken
2016-09-14 00:13:41,059 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140012_0001 = 20000000000. Number of splits = 40
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000000 has split on node:/default-rack/slave4
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000001 has split on node:/default-rack/slave2
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000002 has split on node:/default-rack/slave3
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000003 has split on node:/default-rack/slave3
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000004 has split on node:/default-rack/slave2
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000005 has split on node:/default-rack/slave2
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000006 has split on node:/default-rack/slave3
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000007 has split on node:/default-rack/slave2
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000008 has split on node:/default-rack/slave3
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000009 has split on node:/default-rack/slave3
2016-09-14 00:13:41,060 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000010 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000011 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000012 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000013 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000014 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000015 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000016 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000017 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000018 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000019 has split on node:/default-rack/slave4
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000020 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000020 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000020 has split on node:/default-rack/slave2
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000021 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000021 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000021 has split on node:/default-rack/slave3
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000022 has split on node:/default-rack/slave5
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000022 has split on node:/default-rack/slave2
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000022 has split on node:/default-rack/slave1
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000023 has split on node:/default-rack/slave3
2016-09-14 00:13:41,061 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000023 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000023 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000024 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000024 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000024 has split on node:/default-rack/slave2
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000025 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000025 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000025 has split on node:/default-rack/slave2
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000026 has split on node:/default-rack/slave2
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000026 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000026 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000027 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000027 has split on node:/default-rack/slave3
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000027 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000028 has split on node:/default-rack/slave2
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000028 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000028 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000029 has split on node:/default-rack/slave1
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000029 has split on node:/default-rack/slave5
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000029 has split on node:/default-rack/slave3
2016-09-14 00:13:41,062 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000030 has split on node:/default-rack/slave5
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000030 has split on node:/default-rack/slave3
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000030 has split on node:/default-rack/slave1
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000031 has split on node:/default-rack/slave1
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000031 has split on node:/default-rack/slave5
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000031 has split on node:/default-rack/slave2
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000032 has split on node:/default-rack/slave1
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000032 has split on node:/default-rack/slave5
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000032 has split on node:/default-rack/slave2
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000033 has split on node:/default-rack/slave1
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000033 has split on node:/default-rack/slave5
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000033 has split on node:/default-rack/slave2
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000034 has split on node:/default-rack/slave5
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000034 has split on node:/default-rack/slave2
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000034 has split on node:/default-rack/slave1
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000035 has split on node:/default-rack/slave2
2016-09-14 00:13:41,063 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000036 has split on node:/default-rack/slave1
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000037 has split on node:/default-rack/slave2
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000037 has split on node:/default-rack/slave5
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000037 has split on node:/default-rack/slave1
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000038 has split on node:/default-rack/slave3
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000038 has split on node:/default-rack/slave5
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000038 has split on node:/default-rack/slave1
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000039 has split on node:/default-rack/slave5
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000039 has split on node:/default-rack/slave2
2016-09-14 00:13:41,064 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140012_0001_m_000039 has split on node:/default-rack/slave1
2016-09-14 00:13:41,066 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140012_0001 initialized successfully with 40 map tasks and 5 reduce tasks.
2016-09-14 00:13:43,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140012_0001_m_000041_0' to tip task_201609140012_0001_m_000041, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:13:46,954 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000041_0' has completed task_201609140012_0001_m_000041 successfully.
2016-09-14 00:13:46,961 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000002_0' to tip task_201609140012_0001_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000002
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000003_0' to tip task_201609140012_0001_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000003
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000006_0' to tip task_201609140012_0001_m_000006, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000006
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000008_0' to tip task_201609140012_0001_m_000008, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000008
2016-09-14 00:13:46,962 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000009_0' to tip task_201609140012_0001_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:13:46,963 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000009
2016-09-14 00:13:49,913 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000010_0' to tip task_201609140012_0001_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:13:49,914 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000010
2016-09-14 00:13:49,914 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000011_0' to tip task_201609140012_0001_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:13:49,915 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000011
2016-09-14 00:13:49,915 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000012_0' to tip task_201609140012_0001_m_000012, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:13:49,916 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000012
2016-09-14 00:13:49,916 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000013_0' to tip task_201609140012_0001_m_000013, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:13:49,917 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000013
2016-09-14 00:13:49,917 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000020_0' to tip task_201609140012_0001_m_000020, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:13:49,918 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000020
2016-09-14 00:13:49,919 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000014_0' to tip task_201609140012_0001_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:13:49,920 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000014
2016-09-14 00:13:49,920 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000015_0' to tip task_201609140012_0001_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:13:49,921 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000015
2016-09-14 00:13:49,922 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000016_0' to tip task_201609140012_0001_m_000016, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:13:49,922 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000016
2016-09-14 00:13:49,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000017_0' to tip task_201609140012_0001_m_000017, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:13:49,923 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000017
2016-09-14 00:13:49,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000018_0' to tip task_201609140012_0001_m_000018, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:13:49,924 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000018
2016-09-14 00:13:49,925 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000000_0' to tip task_201609140012_0001_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:13:49,925 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000000
2016-09-14 00:13:49,926 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000019_0' to tip task_201609140012_0001_m_000019, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:13:49,926 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000019
2016-09-14 00:13:49,927 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000001_0' to tip task_201609140012_0001_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:13:49,927 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000001
2016-09-14 00:13:49,928 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000004_0' to tip task_201609140012_0001_m_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:13:49,928 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000004
2016-09-14 00:13:49,929 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000005_0' to tip task_201609140012_0001_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:13:49,929 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000005
2016-09-14 00:13:49,930 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000007_0' to tip task_201609140012_0001_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:13:49,930 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000007
2016-09-14 00:13:49,931 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000022_0' to tip task_201609140012_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:13:49,931 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000022
2016-09-14 00:13:49,932 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000024_0' to tip task_201609140012_0001_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:13:49,932 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000024
2016-09-14 00:13:49,932 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000025_0' to tip task_201609140012_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:13:49,933 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000025
2016-09-14 00:13:49,933 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000026_0' to tip task_201609140012_0001_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:13:49,934 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000026
2016-09-14 00:15:01,691 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000019_0' has completed task_201609140012_0001_m_000019 successfully.
2016-09-14 00:15:01,693 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000021_0' to tip task_201609140012_0001_m_000021, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:15:01,693 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000021
2016-09-14 00:15:05,052 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000007_0' has completed task_201609140012_0001_m_000007 successfully.
2016-09-14 00:15:05,053 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000028_0' to tip task_201609140012_0001_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:15:05,054 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000028
2016-09-14 00:15:05,060 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000000_0' to tip task_201609140012_0001_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:15:05,784 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000001_0' to tip task_201609140012_0001_r_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:15:05,797 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000002_0' has completed task_201609140012_0001_m_000002 successfully.
2016-09-14 00:15:05,799 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000003_0' has completed task_201609140012_0001_m_000003 successfully.
2016-09-14 00:15:05,800 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000006_0' has completed task_201609140012_0001_m_000006 successfully.
2016-09-14 00:15:05,807 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000023_0' to tip task_201609140012_0001_m_000023, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:15:05,807 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000023
2016-09-14 00:15:05,808 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000027_0' to tip task_201609140012_0001_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:15:05,808 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000027
2016-09-14 00:15:05,808 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000029_0' to tip task_201609140012_0001_m_000029, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:15:05,808 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000029
2016-09-14 00:15:05,809 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000002_0' to tip task_201609140012_0001_r_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:15:07,015 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000003_0' to tip task_201609140012_0001_r_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:15:07,141 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000004_0' to tip task_201609140012_0001_r_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:15:12,637 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000026_0' has completed task_201609140012_0001_m_000026 successfully.
2016-09-14 00:15:12,638 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000031_0' to tip task_201609140012_0001_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:15:12,638 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000031
2016-09-14 00:15:16,306 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000000_0' has completed task_201609140012_0001_m_000000 successfully.
2016-09-14 00:15:16,308 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000030_0' to tip task_201609140012_0001_m_000030, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:15:16,308 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000030
2016-09-14 00:15:33,508 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000025_0' has completed task_201609140012_0001_m_000025 successfully.
2016-09-14 00:15:33,509 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000032_0' to tip task_201609140012_0001_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:15:33,509 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000032
2016-09-14 00:15:36,547 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000024_0' has completed task_201609140012_0001_m_000024 successfully.
2016-09-14 00:15:36,548 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000033_0' to tip task_201609140012_0001_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:15:36,548 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000033
2016-09-14 00:15:38,026 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000009_0' has completed task_201609140012_0001_m_000009 successfully.
2016-09-14 00:15:38,027 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000038_0' to tip task_201609140012_0001_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:15:38,027 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000038
2016-09-14 00:15:55,005 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000008_0' has completed task_201609140012_0001_m_000008 successfully.
2016-09-14 00:15:55,007 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000034_0' to tip task_201609140012_0001_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:15:55,007 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000034
2016-09-14 00:15:59,676 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000022_0' has completed task_201609140012_0001_m_000022 successfully.
2016-09-14 00:15:59,677 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000035_0' to tip task_201609140012_0001_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:15:59,677 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000035
2016-09-14 00:16:31,728 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000038_0' has completed task_201609140012_0001_m_000038 successfully.
2016-09-14 00:16:31,729 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000036_0' to tip task_201609140012_0001_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:16:31,729 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000036
2016-09-14 00:16:41,822 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000035_0' has completed task_201609140012_0001_m_000035 successfully.
2016-09-14 00:16:41,823 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000037_0' to tip task_201609140012_0001_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:16:41,823 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000037
2016-09-14 00:17:12,600 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000028_0' has completed task_201609140012_0001_m_000028 successfully.
2016-09-14 00:17:12,601 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000039_0' to tip task_201609140012_0001_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:17:12,601 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000039
2016-09-14 00:17:12,857 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000023_0' has completed task_201609140012_0001_m_000023 successfully.
2016-09-14 00:17:12,858 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000029_0' has completed task_201609140012_0001_m_000029 successfully.
2016-09-14 00:17:12,859 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000021 for speculative execution
2016-09-14 00:17:12,860 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000021_1' to tip task_201609140012_0001_m_000021, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:17:12,860 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000021
2016-09-14 00:17:18,189 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000027_0' has completed task_201609140012_0001_m_000027 successfully.
2016-09-14 00:17:26,148 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000033_0' has completed task_201609140012_0001_m_000033 successfully.
2016-09-14 00:17:26,151 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000034 for speculative execution
2016-09-14 00:17:26,152 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000034_1' to tip task_201609140012_0001_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:17:26,152 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000034
2016-09-14 00:17:33,303 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000005 for speculative execution
2016-09-14 00:17:33,303 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000005_1' to tip task_201609140012_0001_m_000005, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:17:33,303 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000005
2016-09-14 00:17:36,318 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000036_0' has completed task_201609140012_0001_m_000036 successfully.
2016-09-14 00:17:36,320 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000011 for speculative execution
2016-09-14 00:17:36,321 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000011_1' to tip task_201609140012_0001_m_000011, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:17:36,321 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000011
2016-09-14 00:17:38,207 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000031_0' has completed task_201609140012_0001_m_000031 successfully.
2016-09-14 00:17:45,987 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000004_0' has completed task_201609140012_0001_m_000004 successfully.
2016-09-14 00:17:56,300 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000037_0' has completed task_201609140012_0001_m_000037 successfully.
2016-09-14 00:17:56,301 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000012 for speculative execution
2016-09-14 00:17:56,302 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000012_1' to tip task_201609140012_0001_m_000012, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:17:56,302 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000012
2016-09-14 00:18:14,363 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000032_0' has completed task_201609140012_0001_m_000032 successfully.
2016-09-14 00:18:14,366 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000020 for speculative execution
2016-09-14 00:18:14,367 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000020_1' to tip task_201609140012_0001_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:18:14,367 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140012_0001_m_000020
2016-09-14 00:18:21,456 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000001_0' has completed task_201609140012_0001_m_000001 successfully.
2016-09-14 00:18:24,387 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000011_1' has completed task_201609140012_0001_m_000011 successfully.
2016-09-14 00:18:24,615 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000030_0' has completed task_201609140012_0001_m_000030 successfully.
2016-09-14 00:18:27,406 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000021_1' has completed task_201609140012_0001_m_000021 successfully.
2016-09-14 00:18:27,407 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000013 for speculative execution
2016-09-14 00:18:27,408 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000013_1' to tip task_201609140012_0001_m_000013, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:18:27,408 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000013
2016-09-14 00:18:32,924 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000021_0'
2016-09-14 00:18:32,924 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000021_0' to tip task_201609140012_0001_m_000021, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:18:38,791 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000039_0' has completed task_201609140012_0001_m_000039 successfully.
2016-09-14 00:18:38,957 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000021_0'
2016-09-14 00:19:49,931 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000012_1' has completed task_201609140012_0001_m_000012 successfully.
2016-09-14 00:19:55,957 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000034_1' has completed task_201609140012_0001_m_000034 successfully.
2016-09-14 00:19:55,959 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000010 for speculative execution
2016-09-14 00:19:55,960 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000010_1' to tip task_201609140012_0001_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:19:55,960 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000010
2016-09-14 00:20:03,452 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000034_0'
2016-09-14 00:20:03,452 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000034_0' to tip task_201609140012_0001_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:20:06,456 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000034_0'
2016-09-14 00:20:06,466 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000005_0' has completed task_201609140012_0001_m_000005 successfully.
2016-09-14 00:20:14,465 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000005_1'
2016-09-14 00:20:14,465 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000005_1' to tip task_201609140012_0001_m_000005, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:20:15,208 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000014_0' has completed task_201609140012_0001_m_000014 successfully.
2016-09-14 00:20:15,209 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000015_0' has completed task_201609140012_0001_m_000015 successfully.
2016-09-14 00:20:15,210 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000016_0' has completed task_201609140012_0001_m_000016 successfully.
2016-09-14 00:20:15,210 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000018_0' has completed task_201609140012_0001_m_000018 successfully.
2016-09-14 00:20:15,547 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000017 for speculative execution
2016-09-14 00:20:15,548 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000017_1' to tip task_201609140012_0001_m_000017, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:20:15,548 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000017
2016-09-14 00:20:17,469 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000005_1'
2016-09-14 00:20:20,471 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000014_0
2016-09-14 00:20:21,561 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140012_0001_m_000014_0
2016-09-14 00:20:28,734 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #3 for task attempt_201609140012_0001_m_000014_0
2016-09-14 00:20:28,734 INFO org.apache.hadoop.mapred.JobInProgress: Too many fetch-failures for output of task: attempt_201609140012_0001_m_000014_0 ... killing it
2016-09-14 00:20:28,735 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000014_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Too many fetch-failures
2016-09-14 00:20:34,766 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000020_1' has completed task_201609140012_0001_m_000020 successfully.
2016-09-14 00:21:14,145 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000010_1' has completed task_201609140012_0001_m_000010 successfully.
2016-09-14 00:21:14,147 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000014_1' to tip task_201609140012_0001_m_000014, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:21:14,148 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000014
2016-09-14 00:21:47,257 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000014_1' has completed task_201609140012_0001_m_000014 successfully.
2016-09-14 00:24:11,697 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000017_1' has completed task_201609140012_0001_m_000017 successfully.
2016-09-14 00:24:41,450 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000013_1' has completed task_201609140012_0001_m_000013 successfully.
2016-09-14 00:27:30,661 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000015_0
2016-09-14 00:27:30,662 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000018_0
2016-09-14 00:27:30,662 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000016_0
2016-09-14 00:27:32,982 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140012_0001_m_000015_0
2016-09-14 00:27:32,982 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140012_0001_m_000018_0
2016-09-14 00:27:32,982 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140012_0001_m_000016_0
2016-09-14 00:27:39,176 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #3 for task attempt_201609140012_0001_m_000015_0
2016-09-14 00:27:39,176 INFO org.apache.hadoop.mapred.JobInProgress: Too many fetch-failures for output of task: attempt_201609140012_0001_m_000015_0 ... killing it
2016-09-14 00:27:39,176 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000015_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Too many fetch-failures
2016-09-14 00:27:39,177 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #3 for task attempt_201609140012_0001_m_000018_0
2016-09-14 00:27:39,177 INFO org.apache.hadoop.mapred.JobInProgress: Too many fetch-failures for output of task: attempt_201609140012_0001_m_000018_0 ... killing it
2016-09-14 00:27:39,177 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000018_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Too many fetch-failures
2016-09-14 00:27:39,177 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #3 for task attempt_201609140012_0001_m_000016_0
2016-09-14 00:27:39,177 INFO org.apache.hadoop.mapred.JobInProgress: Too many fetch-failures for output of task: attempt_201609140012_0001_m_000016_0 ... killing it
2016-09-14 00:27:39,177 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000016_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Too many fetch-failures
2016-09-14 00:27:39,178 INFO org.apache.hadoop.mapred.JobInProgress: TaskTracker at 'slave5' turned 'flaky'
2016-09-14 00:27:39,179 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000016_1' to tip task_201609140012_0001_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:27:39,179 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000016
2016-09-14 00:27:39,668 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000018_1' to tip task_201609140012_0001_m_000018, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:27:39,668 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000018
2016-09-14 00:27:42,112 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000015_1' to tip task_201609140012_0001_m_000015, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:27:42,112 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000015
2016-09-14 00:28:03,216 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000016_1' has completed task_201609140012_0001_m_000016 successfully.
2016-09-14 00:28:42,356 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140012_0001_m_000015 for speculative execution
2016-09-14 00:28:42,357 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000015_2' to tip task_201609140012_0001_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:28:42,357 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000015
2016-09-14 00:29:06,443 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000015_2' has completed task_201609140012_0001_m_000015 successfully.
2016-09-14 00:29:06,723 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000018_1' has completed task_201609140012_0001_m_000018 successfully.
2016-09-14 00:29:11,958 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000015_1'
2016-09-14 00:29:11,959 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000015_1' to tip task_201609140012_0001_m_000015, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:29:14,962 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000015_1'
2016-09-14 00:29:26,618 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave1:127.0.0.1/127.0.0.1:36545'
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000010_0 on tracker_slave1:127.0.0.1/127.0.0.1:36545: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36545
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000010_0'
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000011_0 on tracker_slave1:127.0.0.1/127.0.0.1:36545: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36545
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000011_0'
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000012_0 on tracker_slave1:127.0.0.1/127.0.0.1:36545: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36545
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000012_0'
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000013_0 on tracker_slave1:127.0.0.1/127.0.0.1:36545: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36545
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000013_0'
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000020_0 on tracker_slave1:127.0.0.1/127.0.0.1:36545: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36545
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000020_0'
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_r_000003_0 on tracker_slave1:127.0.0.1/127.0.0.1:36545: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:36545
2016-09-14 00:29:26,619 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000003_0'
2016-09-14 00:29:26,969 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000010_0' to tip task_201609140012_0001_m_000010, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:29:27,495 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000011_0' to tip task_201609140012_0001_m_000011, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:29:27,907 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000012_0' to tip task_201609140012_0001_m_000012, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:29:30,242 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000013_0' to tip task_201609140012_0001_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:29:30,242 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000010_0'
2016-09-14 00:29:30,498 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000020_0' to tip task_201609140012_0001_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:29:30,498 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000011_0'
2016-09-14 00:29:30,911 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_r_000003_0' to tip task_201609140012_0001_r_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:29:30,911 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000012_0'
2016-09-14 00:29:33,245 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140012_0001_r_000003 for speculative execution
2016-09-14 00:29:33,245 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000003_1' to tip task_201609140012_0001_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:29:33,245 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000013_0'
2016-09-14 00:29:33,915 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140012_0001_r_000001 for speculative execution
2016-09-14 00:29:33,915 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000001_1' to tip task_201609140012_0001_r_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:29:33,915 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000003_0'
2016-09-14 00:29:38,372 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000020_0'
2016-09-14 00:30:08,432 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140012_0001_r_000004 for speculative execution
2016-09-14 00:30:08,433 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000004_1' to tip task_201609140012_0001_r_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:30:44,500 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140012_0001_r_000002 for speculative execution
2016-09-14 00:30:44,500 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000002_1' to tip task_201609140012_0001_r_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:30:47,505 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_r_000000_0' has completed task_201609140012_0001_r_000000 successfully.
2016-09-14 00:31:15,406 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_r_000002_0' has completed task_201609140012_0001_r_000002 successfully.
2016-09-14 00:31:22,562 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000002_1'
2016-09-14 00:31:22,563 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_r_000002_1' to tip task_201609140012_0001_r_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:31:25,783 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000024_0
2016-09-14 00:31:27,453 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000025_0
2016-09-14 00:31:40,795 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_r_000003_1 on tracker_slave4:127.0.0.1/127.0.0.1:37574: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:124)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.mapred.Child.main(Child.java:211)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:253)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:187)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:227)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:149)

2016-09-14 00:31:46,800 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000003_1'
2016-09-14 00:32:14,256 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_r_000004_0' has completed task_201609140012_0001_r_000004 successfully.
2016-09-14 00:32:46,619 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43794'
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000014_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Lost task tracker: tracker_slave5:127.0.0.1/127.0.0.1:43794
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000015_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Lost task tracker: tracker_slave5:127.0.0.1/127.0.0.1:43794
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000016_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Lost task tracker: tracker_slave5:127.0.0.1/127.0.0.1:43794
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000017_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Lost task tracker: tracker_slave5:127.0.0.1/127.0.0.1:43794
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000017_0'
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000018_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Lost task tracker: tracker_slave5:127.0.0.1/127.0.0.1:43794
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_r_000001_0 on tracker_slave5:127.0.0.1/127.0.0.1:43794: Lost task tracker: tracker_slave5:127.0.0.1/127.0.0.1:43794
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000001_0'
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000014_0'
2016-09-14 00:32:46,620 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000015_0'
2016-09-14 00:32:46,621 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000016_0'
2016-09-14 00:32:46,621 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000018_0'
2016-09-14 00:32:46,621 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140012_0001_r_000002_1 is 84056 ms debug.
2016-09-14 00:32:47,281 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_m_000017_0' to tip task_201609140012_0001_m_000017, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:32:47,791 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140012_0001_m_000025_0
2016-09-14 00:32:47,791 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140012_0001_r_000001_0' to tip task_201609140012_0001_r_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:32:50,284 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000017_0'
2016-09-14 00:32:50,794 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000039_0
2016-09-14 00:32:50,794 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000033_0
2016-09-14 00:32:50,794 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000020_1
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000014_1
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000031_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000012_1
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000032_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000010_1
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000037_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140012_0001_m_000024_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000034_1
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000015_2
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000028_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000035_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000022_0
2016-09-14 00:32:50,795 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140012_0001_m_000016_1
2016-09-14 00:32:53,797 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000001_0'
2016-09-14 00:35:05,965 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_r_000001_1 on tracker_slave3:127.0.0.1/127.0.0.1:35739: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:124)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.mapred.Child.main(Child.java:211)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:253)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:187)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:227)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:149)

2016-09-14 00:35:05,965 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #3 for task attempt_201609140012_0001_m_000025_0
2016-09-14 00:35:05,965 INFO org.apache.hadoop.mapred.JobInProgress: Too many fetch-failures for output of task: attempt_201609140012_0001_m_000025_0 ... killing it
2016-09-14 00:35:05,965 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000025_0 on tracker_slave2:127.0.0.1/127.0.0.1:33218: Too many fetch-failures
2016-09-14 00:35:05,965 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000025_1' to tip task_201609140012_0001_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:35:05,965 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000025
2016-09-14 00:35:11,970 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000003_2' to tip task_201609140012_0001_r_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:35:11,971 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000001_1'
2016-09-14 00:35:13,782 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140012_0001_r_000001_2' to tip task_201609140012_0001_r_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:35:26,981 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000025_1 on tracker_slave3:127.0.0.1/127.0.0.1:35739: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: blk_1883805525657771992_7146 file=/user/hduser/terasort-input20-block-512/part-m-00004
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:559)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:367)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:514)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.java:262)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:465)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:90)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:652)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:32
2016-09-14 00:35:26,981 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_r_000003_2 on tracker_slave3:127.0.0.1/127.0.0.1:35739: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#4
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:124)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.mapred.Child.main(Child.java:211)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:253)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:187)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:227)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:149)

2016-09-14 00:35:31,796 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_r_000001_2 on tracker_slave4:127.0.0.1/127.0.0.1:37574: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#4
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:124)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.mapred.Child.main(Child.java:211)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:253)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:187)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:227)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:149)

2016-09-14 00:35:35,989 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000025_1'
2016-09-14 00:35:35,989 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000003_2'
2016-09-14 00:35:37,802 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000025_2' to tip task_201609140012_0001_m_000025, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:35:37,803 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000025
2016-09-14 00:35:37,804 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000001_2'
2016-09-14 00:35:58,820 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000025_2 on tracker_slave4:127.0.0.1/127.0.0.1:37574: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: blk_1883805525657771992_7146 file=/user/hduser/terasort-input20-block-512/part-m-00004
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:559)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:367)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:514)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.java:262)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:465)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:90)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:652)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:32
2016-09-14 00:36:04,827 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140012_0001_m_000025_3' to tip task_201609140012_0001_m_000025, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:36:04,827 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140012_0001_m_000025
2016-09-14 00:36:04,827 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000025_2'
2016-09-14 00:36:06,622 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140012_0001_r_000002_1 is 284059 ms debug.
2016-09-14 00:36:22,843 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140012_0001_m_000025_3 on tracker_slave4:127.0.0.1/127.0.0.1:37574: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: blk_1883805525657771992_7146 file=/user/hduser/terasort-input20-block-512/part-m-00004
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:559)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:367)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:514)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.java:262)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:465)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:90)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:652)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:32
2016-09-14 00:36:28,849 INFO org.apache.hadoop.mapred.TaskInProgress: TaskInProgress task_201609140012_0001_m_000025 has failed 4 times.
2016-09-14 00:36:28,849 INFO org.apache.hadoop.mapred.JobInProgress: Aborting job job_201609140012_0001
2016-09-14 00:36:28,849 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609140012_0001'
2016-09-14 00:36:28,849 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609140012_0001_m_000040_0' to tip task_201609140012_0001_m_000040, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 00:36:28,850 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000025_3'
2016-09-14 00:36:31,869 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140012_0001_m_000040_0' has completed task_201609140012_0001_m_000040 successfully.
2016-09-14 00:36:31,872 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609140012_0001,submitTime=1473792220761,launchTime=1473792221064,finishTime=1473793591869,numMaps=40,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=FAILED,mapSlotSeconds=6379,reduceSlotsSeconds=3450,clusterMapCapacity=15,clusterReduceCapacity=15
2016-09-14 00:36:31,912 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 10.129.40.102:50010
2016-09-14 00:36:31,912 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_503620961786628649_9796
2016-09-14 00:36:31,913 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.102:50010
2016-09-14 00:36:31,932 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140012_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140012_0001_hduser
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000000_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000001_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000004_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000005_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000017_1'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000019_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000030_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000040_0'
2016-09-14 00:36:31,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000004_0'
2016-09-14 00:36:31,938 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140012_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140012_0001_conf.xml
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609140012_0001_conf.xml
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000002_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000003_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000006_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000007_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000008_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000009_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000010_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000011_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000012_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000013_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000014_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000015_2'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000016_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000018_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000020_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000021_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000022_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000023_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000024_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000025_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000026_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000027_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000028_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000029_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000031_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000032_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000033_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000034_1'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000035_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000036_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000037_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000038_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000039_0'
2016-09-14 00:36:31,941 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000000_0'
2016-09-14 00:36:31,942 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000002_0'
2016-09-14 00:36:31,942 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000002_1'
2016-09-14 00:36:31,942 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_r_000004_1'
2016-09-14 00:36:31,942 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140012_0001_m_000041_0'
2016-09-14 00:36:31,942 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609140012_0001' of user 'hduser'
2016-09-14 00:39:26,622 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140012_0001_r_000002_1 is 484059 ms debug.
2016-09-14 00:42:46,622 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave2:127.0.0.1/127.0.0.1:33218'
2016-09-14 00:42:46,623 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140012_0001_r_000002_1 is 684060 ms debug.
2016-09-14 00:42:46,623 INFO org.apache.hadoop.mapred.JobTracker: Launching task attempt_201609140012_0001_r_000002_1 timed out.
2016-09-14 00:49:26,623 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave3:127.0.0.1/127.0.0.1:35739'
2016-09-14 00:52:46,623 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave4:127.0.0.1/127.0.0.1:37574'
2016-09-14 01:10:54,726 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 01:10:59,730 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 01:10:59,827 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 01:10:59,830 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 01:10:59,830 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 01:10:59,831 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 01:10:59,831 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 01:10:59,831 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 01:10:59,832 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 01:10:59,837 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 01:10:59,848 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 01:10:59,851 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:10:59,854 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 01:10:59,855 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:10:59,856 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 01:10:59,876 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 01:10:59,898 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 01:10:59,900 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 01:10:59,908 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 01:10:59,909 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 01:10:59,909 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 01:10:59,909 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 01:11:00,030 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 01:11:00,031 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 01:11:00,032 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:11:00,032 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:11:00,032 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 01:11:00,032 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 01:11:00,057 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 01:11:00,130 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:11:00,131 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 611 needs additional 409 blocks to reach the threshold 0.9990 of total blocks 1022. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:11:10,134 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:11:10,135 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1022 has reached the threshold 0.9990 of total blocks 1022. Safe mode will be turned off automatically in 21 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:11:20,141 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:11:20,144 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1022 has reached the threshold 0.9990 of total blocks 1022. Safe mode will be turned off automatically in 11 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:11:30,150 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:11:30,153 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1022 has reached the threshold 0.9990 of total blocks 1022. Safe mode will be turned off automatically in 1 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:11:40,158 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:11:40,257 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-14 01:11:40,257 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-14 01:11:40,258 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-14 01:11:40,260 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-14 01:11:40,445 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-14 01:11:40,452 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-14 01:11:40,452 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-14 01:11:40,452 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 01:11:40,452 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-14 01:11:40,454 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-14 01:11:40,455 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609132256_0002.info]
2016-09-14 01:11:40,459 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-14 01:11:40,460 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-14 01:11:40,460 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-14 01:11:40,462 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-14 01:11:40,462 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-14 01:11:40,462 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-14 01:11:40,466 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-14 01:11:40,471 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609132256_0003.info]
2016-09-14 01:11:40,472 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-14 01:11:40,473 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-14 01:11:40,473 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-14 01:11:40,473 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-14 01:11:40,478 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609132256_0004.info]
2016-09-14 01:11:40,478 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-14 01:11:40,486 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609132256_0005.info]
2016-09-14 01:11:40,598 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-14 01:11:40,599 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:38938 to host slave3
2016-09-14 01:11:40,603 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-14 01:11:40,603 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:36772 to host slave4
2016-09-14 01:11:40,626 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-14 01:11:40,626 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:40491 to host slave5
2016-09-14 01:11:40,637 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-14 01:11:40,637 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:37614 to host slave2
2016-09-14 01:11:40,646 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-14 01:11:40,646 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:39735 to host slave1
2016-09-14 01:12:47,825 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-14 01:12:47,943 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140110_0001 added successfully for user 'hduser' to queue 'default'
2016-09-14 01:12:47,943 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140110_0001
2016-09-14 01:12:47,943 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140110_0001
2016-09-14 01:12:47,975 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140110_0001_hduser
2016-09-14 01:12:48,050 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140110_0001_conf.xml
2016-09-14 01:12:48,100 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140110_0001/jobToken
2016-09-14 01:12:48,110 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140110_0001 = 10000000000. Number of splits = 38
2016-09-14 01:12:48,111 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000000 has split on node:/default-rack/slave1
2016-09-14 01:12:48,111 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000001 has split on node:/default-rack/slave1
2016-09-14 01:12:48,111 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000002 has split on node:/default-rack/slave4
2016-09-14 01:12:48,111 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000003 has split on node:/default-rack/slave1
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000004 has split on node:/default-rack/slave1
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000005 has split on node:/default-rack/slave1
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000006 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000007 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000008 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000009 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000010 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000011 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000012 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000013 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000014 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000015 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000016 has split on node:/default-rack/slave1
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000016 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000016 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000017 has split on node:/default-rack/slave5
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000017 has split on node:/default-rack/slave2
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000017 has split on node:/default-rack/slave1
2016-09-14 01:12:48,112 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000018 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000018 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000018 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000019 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000019 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000019 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000020 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000020 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000020 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000021 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000021 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000021 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000022 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000022 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000022 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000023 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000023 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000023 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000024 has split on node:/default-rack/slave2
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000024 has split on node:/default-rack/slave5
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000024 has split on node:/default-rack/slave1
2016-09-14 01:12:48,113 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000025 has split on node:/default-rack/slave1
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000025 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000025 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000026 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000026 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000026 has split on node:/default-rack/slave1
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000027 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000027 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000027 has split on node:/default-rack/slave1
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000028 has split on node:/default-rack/slave1
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000028 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000028 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000029 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000029 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000029 has split on node:/default-rack/slave1
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000030 has split on node:/default-rack/slave1
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000030 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000030 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000031 has split on node:/default-rack/slave5
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000031 has split on node:/default-rack/slave2
2016-09-14 01:12:48,114 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000031 has split on node:/default-rack/slave1
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000032 has split on node:/default-rack/slave5
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000032 has split on node:/default-rack/slave2
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000032 has split on node:/default-rack/slave1
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000033 has split on node:/default-rack/slave1
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000033 has split on node:/default-rack/slave2
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000033 has split on node:/default-rack/slave5
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000034 has split on node:/default-rack/slave2
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000034 has split on node:/default-rack/slave5
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000034 has split on node:/default-rack/slave1
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000035 has split on node:/default-rack/slave5
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000035 has split on node:/default-rack/slave2
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000035 has split on node:/default-rack/slave1
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000036 has split on node:/default-rack/slave1
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000036 has split on node:/default-rack/slave2
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000036 has split on node:/default-rack/slave5
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000037 has split on node:/default-rack/slave5
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000037 has split on node:/default-rack/slave2
2016-09-14 01:12:48,115 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0001_m_000037 has split on node:/default-rack/slave1
2016-09-14 01:12:48,116 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140110_0001 initialized successfully with 38 map tasks and 5 reduce tasks.
2016-09-14 01:12:49,684 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140110_0001_m_000039_0' to tip task_201609140110_0001_m_000039, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:12:52,737 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000039_0' has completed task_201609140110_0001_m_000039 successfully.
2016-09-14 01:12:52,743 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000000_0' to tip task_201609140110_0001_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:12:52,745 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000000
2016-09-14 01:12:52,745 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000001_0' to tip task_201609140110_0001_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:12:52,745 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000001
2016-09-14 01:12:52,745 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000002_0' to tip task_201609140110_0001_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:12:52,746 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000002
2016-09-14 01:12:52,746 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000003_0' to tip task_201609140110_0001_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:12:52,746 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000003
2016-09-14 01:12:52,746 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000004_0' to tip task_201609140110_0001_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:12:52,746 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000004
2016-09-14 01:12:55,704 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000005_0' to tip task_201609140110_0001_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:12:55,705 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000005
2016-09-14 01:12:55,706 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000006_0' to tip task_201609140110_0001_m_000006, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:12:55,706 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000006
2016-09-14 01:12:55,706 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000007_0' to tip task_201609140110_0001_m_000007, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:12:55,707 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000007
2016-09-14 01:12:55,707 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000008_0' to tip task_201609140110_0001_m_000008, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:12:55,707 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000008
2016-09-14 01:12:55,708 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000009_0' to tip task_201609140110_0001_m_000009, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:12:55,708 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000009
2016-09-14 01:12:55,719 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000016_0' to tip task_201609140110_0001_m_000016, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:12:55,720 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000016
2016-09-14 01:12:55,720 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000017_0' to tip task_201609140110_0001_m_000017, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:12:55,721 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000017
2016-09-14 01:12:55,721 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000018_0' to tip task_201609140110_0001_m_000018, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:12:55,721 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000018
2016-09-14 01:12:55,722 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000019_0' to tip task_201609140110_0001_m_000019, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:12:55,722 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000019
2016-09-14 01:12:55,722 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000020_0' to tip task_201609140110_0001_m_000020, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:12:55,722 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000020
2016-09-14 01:12:55,723 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000011_0' to tip task_201609140110_0001_m_000011, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:12:55,723 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000011
2016-09-14 01:12:55,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000012_0' to tip task_201609140110_0001_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:12:55,724 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000012
2016-09-14 01:12:55,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000013_0' to tip task_201609140110_0001_m_000013, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:12:55,724 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000013
2016-09-14 01:12:55,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000014_0' to tip task_201609140110_0001_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:12:55,725 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000014
2016-09-14 01:12:55,725 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000015_0' to tip task_201609140110_0001_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:12:55,725 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000015
2016-09-14 01:12:55,726 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000010_0' to tip task_201609140110_0001_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:12:55,726 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000010
2016-09-14 01:12:55,726 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000021_0' to tip task_201609140110_0001_m_000021, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:12:55,726 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000021
2016-09-14 01:12:55,727 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000022_0' to tip task_201609140110_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:12:55,727 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000022
2016-09-14 01:12:55,727 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000023_0' to tip task_201609140110_0001_m_000023, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:12:55,727 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000023
2016-09-14 01:12:55,728 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000024_0' to tip task_201609140110_0001_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:12:55,728 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000024
2016-09-14 01:13:14,074 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000002_0' has completed task_201609140110_0001_m_000002 successfully.
2016-09-14 01:13:14,076 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000025_0' to tip task_201609140110_0001_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:13:14,076 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000025
2016-09-14 01:13:37,851 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000022_0' has completed task_201609140110_0001_m_000022 successfully.
2016-09-14 01:13:37,854 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000026_0' to tip task_201609140110_0001_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:13:37,854 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000026
2016-09-14 01:13:37,858 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000000_0' to tip task_201609140110_0001_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:13:38,099 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000001_0' to tip task_201609140110_0001_r_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:13:38,263 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000002_0' to tip task_201609140110_0001_r_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:13:38,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000003_0' to tip task_201609140110_0001_r_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:13:40,790 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000004_0' to tip task_201609140110_0001_r_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:13:44,764 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000010_0' has completed task_201609140110_0001_m_000010 successfully.
2016-09-14 01:13:44,769 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000027_0' to tip task_201609140110_0001_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:13:44,770 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000027
2016-09-14 01:13:49,932 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000021_0' has completed task_201609140110_0001_m_000021 successfully.
2016-09-14 01:13:49,935 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000024_0' has completed task_201609140110_0001_m_000024 successfully.
2016-09-14 01:13:49,936 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000028_0' to tip task_201609140110_0001_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:13:49,936 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000028
2016-09-14 01:13:49,936 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000029_0' to tip task_201609140110_0001_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:13:49,936 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000029
2016-09-14 01:14:01,826 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000007_0' has completed task_201609140110_0001_m_000007 successfully.
2016-09-14 01:14:01,827 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000030_0' to tip task_201609140110_0001_m_000030, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:14:01,827 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000030
2016-09-14 01:14:08,006 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000023_0' has completed task_201609140110_0001_m_000023 successfully.
2016-09-14 01:14:08,009 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000031_0' to tip task_201609140110_0001_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:14:08,010 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000031
2016-09-14 01:14:11,156 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000004_0' has completed task_201609140110_0001_m_000004 successfully.
2016-09-14 01:14:11,157 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000032_0' to tip task_201609140110_0001_m_000032, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:14:11,158 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000032
2016-09-14 01:14:29,182 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000001_0' has completed task_201609140110_0001_m_000001 successfully.
2016-09-14 01:14:29,184 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000033_0' to tip task_201609140110_0001_m_000033, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:14:29,185 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000033
2016-09-14 01:14:30,861 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000005_0' has completed task_201609140110_0001_m_000005 successfully.
2016-09-14 01:14:30,863 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000008_0' has completed task_201609140110_0001_m_000008 successfully.
2016-09-14 01:14:30,864 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000034_0' to tip task_201609140110_0001_m_000034, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:14:30,864 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000034
2016-09-14 01:14:30,865 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000035_0' to tip task_201609140110_0001_m_000035, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:14:30,865 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000035
2016-09-14 01:14:34,297 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000000_0' has completed task_201609140110_0001_m_000000 successfully.
2016-09-14 01:14:34,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000036_0' to tip task_201609140110_0001_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:14:34,299 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000036
2016-09-14 01:14:35,100 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000026_0' has completed task_201609140110_0001_m_000026 successfully.
2016-09-14 01:14:35,101 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000029_0' has completed task_201609140110_0001_m_000029 successfully.
2016-09-14 01:14:35,102 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000037_0' to tip task_201609140110_0001_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:14:35,102 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000037
2016-09-14 01:14:36,220 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000011_0' has completed task_201609140110_0001_m_000011 successfully.
2016-09-14 01:14:39,350 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000003_0' has completed task_201609140110_0001_m_000003 successfully.
2016-09-14 01:14:44,503 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000006_0' has completed task_201609140110_0001_m_000006 successfully.
2016-09-14 01:14:44,504 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000009_0' has completed task_201609140110_0001_m_000009 successfully.
2016-09-14 01:14:46,502 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000027_0' has completed task_201609140110_0001_m_000027 successfully.
2016-09-14 01:14:47,525 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #1 for task attempt_201609140110_0001_m_000011_0
2016-09-14 01:14:48,391 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #2 for task attempt_201609140110_0001_m_000011_0
2016-09-14 01:14:49,092 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #3 for task attempt_201609140110_0001_m_000011_0
2016-09-14 01:14:49,092 INFO org.apache.hadoop.mapred.JobInProgress: Too many fetch-failures for output of task: attempt_201609140110_0001_m_000011_0 ... killing it
2016-09-14 01:14:49,093 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140110_0001_m_000011_0 on tracker_slave5:127.0.0.1/127.0.0.1:40491: Too many fetch-failures
2016-09-14 01:14:49,518 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000011_1' to tip task_201609140110_0001_m_000011, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:14:49,518 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000011
2016-09-14 01:14:56,350 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000028_0' has completed task_201609140110_0001_m_000028 successfully.
2016-09-14 01:15:05,555 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000031_0' has completed task_201609140110_0001_m_000031 successfully.
2016-09-14 01:15:11,570 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000032 for speculative execution
2016-09-14 01:15:11,570 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000032_1' to tip task_201609140110_0001_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:15:11,570 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000032
2016-09-14 01:15:27,962 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000037_0' has completed task_201609140110_0001_m_000037 successfully.
2016-09-14 01:15:29,755 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000033 for speculative execution
2016-09-14 01:15:29,755 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000033_1' to tip task_201609140110_0001_m_000033, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:15:29,755 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000033
2016-09-14 01:15:30,976 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000034 for speculative execution
2016-09-14 01:15:30,977 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000034_1' to tip task_201609140110_0001_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:15:30,977 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000034
2016-09-14 01:15:33,989 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000035 for speculative execution
2016-09-14 01:15:33,989 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000035_1' to tip task_201609140110_0001_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:15:33,989 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000035
2016-09-14 01:15:40,588 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000016_0' has completed task_201609140110_0001_m_000016 successfully.
2016-09-14 01:15:40,589 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000018_0' has completed task_201609140110_0001_m_000018 successfully.
2016-09-14 01:15:40,589 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000019_0' has completed task_201609140110_0001_m_000019 successfully.
2016-09-14 01:15:46,050 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000011_1' has completed task_201609140110_0001_m_000011 successfully.
2016-09-14 01:15:46,601 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000017_0' has completed task_201609140110_0001_m_000017 successfully.
2016-09-14 01:15:53,427 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000020_0' has completed task_201609140110_0001_m_000020 successfully.
2016-09-14 01:16:03,510 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000025_0' has completed task_201609140110_0001_m_000025 successfully.
2016-09-14 01:16:10,186 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000032_1' has completed task_201609140110_0001_m_000032 successfully.
2016-09-14 01:16:13,203 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000035_1' has completed task_201609140110_0001_m_000035 successfully.
2016-09-14 01:16:13,203 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000036 for speculative execution
2016-09-14 01:16:13,204 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000036_1' to tip task_201609140110_0001_m_000036, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:16:13,204 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000036
2016-09-14 01:16:16,221 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000034_1' has completed task_201609140110_0001_m_000034 successfully.
2016-09-14 01:16:16,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000030 for speculative execution
2016-09-14 01:16:16,222 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000030_1' to tip task_201609140110_0001_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:16:16,222 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0001_m_000030
2016-09-14 01:16:17,545 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000032_0'
2016-09-14 01:16:17,546 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_m_000032_0' to tip task_201609140110_0001_m_000032, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:16:20,549 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000032_0'
2016-09-14 01:16:22,287 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000035_0'
2016-09-14 01:16:22,287 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_m_000035_0' to tip task_201609140110_0001_m_000035, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:16:27,633 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000034_0'
2016-09-14 01:16:27,633 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_m_000034_0' to tip task_201609140110_0001_m_000034, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:16:34,326 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000036_1' has completed task_201609140110_0001_m_000036 successfully.
2016-09-14 01:16:34,327 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000015 for speculative execution
2016-09-14 01:16:34,327 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000015_1' to tip task_201609140110_0001_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:16:34,327 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000015
2016-09-14 01:16:40,568 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000036_0'
2016-09-14 01:16:40,569 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_m_000036_0' to tip task_201609140110_0001_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:16:43,379 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000030_1' has completed task_201609140110_0001_m_000030 successfully.
2016-09-14 01:16:43,575 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000036_0'
2016-09-14 01:16:45,126 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000034_0'
2016-09-14 01:16:45,126 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000035_0'
2016-09-14 01:16:50,141 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000030_0'
2016-09-14 01:16:50,142 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_m_000030_0' to tip task_201609140110_0001_m_000030, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:16:52,426 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000015_1' has completed task_201609140110_0001_m_000015 successfully.
2016-09-14 01:16:52,427 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000014 for speculative execution
2016-09-14 01:16:52,428 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000014_1' to tip task_201609140110_0001_m_000014, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:16:52,428 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000014
2016-09-14 01:16:53,150 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000030_0'
2016-09-14 01:16:58,590 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000033_0' has completed task_201609140110_0001_m_000033 successfully.
2016-09-14 01:16:58,590 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000012 for speculative execution
2016-09-14 01:16:58,590 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000012_1' to tip task_201609140110_0001_m_000012, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:16:58,591 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000012
2016-09-14 01:17:04,165 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000033_1'
2016-09-14 01:17:04,165 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_m_000033_1' to tip task_201609140110_0001_m_000033, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:17:07,184 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140110_0001_m_000013 for speculative execution
2016-09-14 01:17:07,184 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0001_m_000013_1' to tip task_201609140110_0001_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:17:07,184 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0001_m_000013
2016-09-14 01:17:07,184 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000033_1'
2016-09-14 01:17:07,488 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000014_1' has completed task_201609140110_0001_m_000014 successfully.
2016-09-14 01:17:46,629 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000012_1' has completed task_201609140110_0001_m_000012 successfully.
2016-09-14 01:19:02,480 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000013_1' has completed task_201609140110_0001_m_000013 successfully.
2016-09-14 01:19:33,052 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140110_0001_r_000002 for speculative execution
2016-09-14 01:19:33,052 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000002_1' to tip task_201609140110_0001_r_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:19:36,056 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_r_000000_0' has completed task_201609140110_0001_r_000000 successfully.
2016-09-14 01:19:43,056 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_r_000004_0' has completed task_201609140110_0001_r_000004 successfully.
2016-09-14 01:19:43,057 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140110_0001_r_000001 for speculative execution
2016-09-14 01:19:43,057 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140110_0001_r_000001_1' to tip task_201609140110_0001_r_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:19:53,884 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_r_000003_0' has completed task_201609140110_0001_r_000003 successfully.
2016-09-14 01:21:50,322 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_r_000001_0' has completed task_201609140110_0001_r_000001 successfully.
2016-09-14 01:21:55,570 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000001_1'
2016-09-14 01:21:55,571 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140110_0001_r_000001_1' to tip task_201609140110_0001_r_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:21:57,297 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_r_000002_1' has completed task_201609140110_0001_r_000002 successfully.
2016-09-14 01:21:57,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609140110_0001_m_000038_0' to tip task_201609140110_0001_m_000038, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:21:58,576 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000001_1'
2016-09-14 01:22:00,302 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0001_m_000038_0' has completed task_201609140110_0001_m_000038 successfully.
2016-09-14 01:22:00,303 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140110_0001 has completed successfully.
2016-09-14 01:22:00,304 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609140110_0001,submitTime=1473795767795,launchTime=1473795768115,finishTime=1473796320303,numMaps=38,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=3158,reduceSlotsSeconds=1723,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 01:22:00,405 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140110_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140110_0001_hduser
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000010_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000011_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000014_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000015_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000021_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000022_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000023_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000024_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000026_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000027_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000028_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000029_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000030_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000031_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000032_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000034_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000035_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000036_1'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000037_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000038_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000000_0'
2016-09-14 01:22:00,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000002_1'
2016-09-14 01:22:00,418 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140110_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140110_0001_conf.xml
2016-09-14 01:22:00,425 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609140110_0001_conf.xml
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000000_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000001_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000002_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000003_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000004_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000005_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000006_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000007_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000008_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000009_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000011_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000012_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000012_1'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000013_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000013_1'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000014_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000015_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000016_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000017_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000018_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000019_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000020_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000025_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000033_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000001_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000002_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000003_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_r_000004_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0001_m_000039_0'
2016-09-14 01:22:00,426 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609140110_0001' of user 'hduser'
2016-09-14 01:25:00,454 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:40491'
2016-09-14 01:27:49,399 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140110_0002 added successfully for user 'hduser' to queue 'default'
2016-09-14 01:27:49,399 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140110_0002
2016-09-14 01:27:49,399 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140110_0002
2016-09-14 01:27:49,403 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140110_0002_hduser
2016-09-14 01:27:49,406 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140110_0002_conf.xml
2016-09-14 01:27:49,532 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140110_0002/jobToken
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140110_0002 = 10000000000. Number of splits = 38
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000000 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000001 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000002 has split on node:/default-rack/slave3
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000003 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000004 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000005 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000006 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000007 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000008 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000009 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000010 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000011 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000011 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000012 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000012 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000013 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000013 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000014 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000014 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000015 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000015 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000016 has split on node:/default-rack/slave2
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000016 has split on node:/default-rack/slave1
2016-09-14 01:27:49,553 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000017 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000017 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000018 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000018 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000019 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000019 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000020 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000020 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000021 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000021 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000022 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000022 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000023 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000023 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000024 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000024 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000025 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000025 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000026 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000026 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000027 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000027 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000028 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000028 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000029 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000029 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000030 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000030 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000031 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000031 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000032 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000032 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000033 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000033 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000034 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000034 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000035 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000035 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000036 has split on node:/default-rack/slave1
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000036 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000037 has split on node:/default-rack/slave2
2016-09-14 01:27:49,554 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140110_0002_m_000037 has split on node:/default-rack/slave1
2016-09-14 01:27:49,555 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140110_0002 initialized successfully with 38 map tasks and 5 reduce tasks.
2016-09-14 01:27:49,857 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140110_0002_m_000039_0' to tip task_201609140110_0002_m_000039, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:27:55,865 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0002_m_000039_0' has completed task_201609140110_0002_m_000039 successfully.
2016-09-14 01:27:55,869 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000000_0' to tip task_201609140110_0002_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:27:55,869 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000000
2016-09-14 01:27:55,869 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000001_0' to tip task_201609140110_0002_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:27:55,869 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000001
2016-09-14 01:27:55,870 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000002_0' to tip task_201609140110_0002_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:27:55,870 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000002
2016-09-14 01:27:55,870 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000003_0' to tip task_201609140110_0002_m_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:27:55,870 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000003
2016-09-14 01:27:55,870 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000004_0' to tip task_201609140110_0002_m_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36772'
2016-09-14 01:27:55,871 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000004
2016-09-14 01:27:56,987 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000005_0' to tip task_201609140110_0002_m_000005, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:27:56,988 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000005
2016-09-14 01:27:56,989 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000006_0' to tip task_201609140110_0002_m_000006, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:27:56,989 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000006
2016-09-14 01:27:56,989 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000007_0' to tip task_201609140110_0002_m_000007, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:27:56,989 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000007
2016-09-14 01:27:56,989 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000008_0' to tip task_201609140110_0002_m_000008, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:27:56,989 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000008
2016-09-14 01:27:56,990 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000009_0' to tip task_201609140110_0002_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:38938'
2016-09-14 01:27:56,990 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140110_0002_m_000009
2016-09-14 01:27:57,266 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000010_0' to tip task_201609140110_0002_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:27:57,267 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000010
2016-09-14 01:27:57,267 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000011_0' to tip task_201609140110_0002_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:27:57,267 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000011
2016-09-14 01:27:57,268 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000012_0' to tip task_201609140110_0002_m_000012, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:27:57,268 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000012
2016-09-14 01:27:57,268 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000013_0' to tip task_201609140110_0002_m_000013, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:27:57,268 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000013
2016-09-14 01:27:57,269 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000014_0' to tip task_201609140110_0002_m_000014, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39735'
2016-09-14 01:27:57,269 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000014
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000015_0' to tip task_201609140110_0002_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000015
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000016_0' to tip task_201609140110_0002_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000016
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000017_0' to tip task_201609140110_0002_m_000017, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000017
2016-09-14 01:27:57,755 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000018_0' to tip task_201609140110_0002_m_000018, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:27:57,756 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000018
2016-09-14 01:27:57,756 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140110_0002_m_000019_0' to tip task_201609140110_0002_m_000019, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:27:57,756 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140110_0002_m_000019
2016-09-14 01:28:18,536 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609140110_0002
2016-09-14 01:28:18,536 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609140110_0002'
2016-09-14 01:28:18,830 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609140110_0002_r_000005_0' to tip task_201609140110_0002_r_000005, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:37614'
2016-09-14 01:28:20,455 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140110_0002_r_000005_0 is 1625 ms debug.
2016-09-14 01:28:23,944 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000005_0'
2016-09-14 01:28:24,098 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000015_0'
2016-09-14 01:28:26,010 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000000_0'
2016-09-14 01:28:26,352 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000010_0'
2016-09-14 01:28:33,966 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000006_0'
2016-09-14 01:28:33,966 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000007_0'
2016-09-14 01:28:35,175 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140110_0002_r_000005_0' has completed task_201609140110_0002_r_000005 successfully.
2016-09-14 01:28:35,202 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609140110_0002,submitTime=1473796669041,launchTime=1473796669554,finishTime=1473796715202,numMaps=38,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=KILLED,mapSlotSeconds=250,reduceSlotsSeconds=10,clusterMapCapacity=20,clusterReduceCapacity=20
2016-09-14 01:28:35,566 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140110_0002_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140110_0002_hduser
2016-09-14 01:28:35,568 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000016_0'
2016-09-14 01:28:35,568 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000017_0'
2016-09-14 01:28:35,568 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_r_000005_0'
2016-09-14 01:28:35,573 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140110_0002_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140110_0002_conf.xml
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609140110_0002_conf.xml
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000001_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000002_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000003_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000004_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000008_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000009_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000011_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000012_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000013_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000014_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000018_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000019_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140110_0002_m_000039_0'
2016-09-14 01:28:35,585 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609140110_0002' of user 'hduser'
2016-09-14 01:28:59,883 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 01:29:04,882 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 01:29:04,946 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 01:29:04,949 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 01:29:04,949 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 01:29:04,950 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 01:29:04,950 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 01:29:04,950 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 01:29:04,951 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 01:29:04,956 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 01:29:04,966 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 01:29:04,969 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:04,972 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 01:29:04,974 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:04,974 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 01:29:04,993 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 01:29:05,016 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 01:29:05,018 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 01:29:05,025 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 01:29:05,026 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 01:29:05,026 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 01:29:05,026 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 01:29:05,140 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 01:29:05,141 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 01:29:05,141 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:05,142 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:05,142 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 01:29:05,142 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 01:29:05,166 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 01:29:05,225 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:29:05,226 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 976 needs additional 84 blocks to reach the threshold 0.9990 of total blocks 1062. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:15,229 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:29:15,230 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1062 has reached the threshold 0.9990 of total blocks 1062. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:25,236 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:29:25,239 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1062 has reached the threshold 0.9990 of total blocks 1062. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:35,245 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:29:35,249 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1062 has reached the threshold 0.9990 of total blocks 1062. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 01:29:45,256 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 01:29:45,333 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-14 01:29:45,333 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-14 01:29:45,334 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-14 01:29:45,338 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-14 01:29:45,632 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-14 01:29:45,640 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-14 01:29:45,640 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-14 01:29:45,640 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 01:29:45,640 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-14 01:29:45,640 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-14 01:29:45,641 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-14 01:29:45,642 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-14 01:29:45,649 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-14 01:29:45,650 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-14 01:29:45,650 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-14 01:29:45,654 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-14 01:29:45,660 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-14 01:29:45,660 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-14 01:29:45,660 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-14 01:29:45,661 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-14 01:29:45,661 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-14 01:29:45,661 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-14 01:29:45,979 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-14 01:29:45,981 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:39175 to host slave3
2016-09-14 01:29:46,058 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-14 01:29:46,058 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:36201 to host slave5
2016-09-14 01:29:46,096 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-14 01:29:46,096 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:40926 to host slave1
2016-09-14 01:29:46,112 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-14 01:29:46,112 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:40050 to host slave2
2016-09-14 01:29:46,174 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-14 01:29:46,174 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:36752 to host slave4
2016-09-14 01:29:59,458 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-14 01:29:59,530 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140129_0001 added successfully for user 'hduser' to queue 'default'
2016-09-14 01:29:59,531 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140129_0001
2016-09-14 01:29:59,531 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140129_0001
2016-09-14 01:29:59,565 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140129_0001_hduser
2016-09-14 01:29:59,636 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140129_0001_conf.xml
2016-09-14 01:29:59,762 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140129_0001/jobToken
2016-09-14 01:29:59,792 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140129_0001 = 10000000000. Number of splits = 38
2016-09-14 01:29:59,792 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000000 has split on node:/default-rack/slave2
2016-09-14 01:29:59,792 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000001 has split on node:/default-rack/slave2
2016-09-14 01:29:59,792 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000002 has split on node:/default-rack/slave3
2016-09-14 01:29:59,792 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000003 has split on node:/default-rack/slave2
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000004 has split on node:/default-rack/slave2
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000005 has split on node:/default-rack/slave2
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000006 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000007 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000008 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000009 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000010 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000011 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000012 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000013 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000014 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000015 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000016 has split on node:/default-rack/slave2
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000016 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000016 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000017 has split on node:/default-rack/slave2
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000017 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000017 has split on node:/default-rack/slave5
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000018 has split on node:/default-rack/slave1
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000018 has split on node:/default-rack/slave2
2016-09-14 01:29:59,793 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000018 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000019 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000019 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000019 has split on node:/default-rack/slave2
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000020 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000020 has split on node:/default-rack/slave2
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000020 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000021 has split on node:/default-rack/slave2
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000021 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000021 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000022 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000022 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000022 has split on node:/default-rack/slave2
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000023 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000023 has split on node:/default-rack/slave2
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000023 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000024 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000024 has split on node:/default-rack/slave2
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000024 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000025 has split on node:/default-rack/slave5
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000025 has split on node:/default-rack/slave1
2016-09-14 01:29:59,794 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000025 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000026 has split on node:/default-rack/slave1
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000026 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000026 has split on node:/default-rack/slave5
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000027 has split on node:/default-rack/slave1
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000027 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000027 has split on node:/default-rack/slave5
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000028 has split on node:/default-rack/slave5
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000028 has split on node:/default-rack/slave1
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000028 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000029 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000029 has split on node:/default-rack/slave1
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000029 has split on node:/default-rack/slave5
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000030 has split on node:/default-rack/slave1
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000030 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000030 has split on node:/default-rack/slave5
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000031 has split on node:/default-rack/slave1
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000031 has split on node:/default-rack/slave2
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000031 has split on node:/default-rack/slave5
2016-09-14 01:29:59,795 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000032 has split on node:/default-rack/slave2
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000032 has split on node:/default-rack/slave1
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000032 has split on node:/default-rack/slave5
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000033 has split on node:/default-rack/slave2
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000033 has split on node:/default-rack/slave1
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000033 has split on node:/default-rack/slave5
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000034 has split on node:/default-rack/slave2
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000034 has split on node:/default-rack/slave1
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000034 has split on node:/default-rack/slave5
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000035 has split on node:/default-rack/slave2
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000035 has split on node:/default-rack/slave1
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000035 has split on node:/default-rack/slave5
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000036 has split on node:/default-rack/slave2
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000036 has split on node:/default-rack/slave1
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000036 has split on node:/default-rack/slave5
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000037 has split on node:/default-rack/slave1
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000037 has split on node:/default-rack/slave2
2016-09-14 01:29:59,796 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0001_m_000037 has split on node:/default-rack/slave5
2016-09-14 01:29:59,797 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140129_0001 initialized successfully with 38 map tasks and 5 reduce tasks.
2016-09-14 01:30:01,014 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140129_0001_m_000039_0' to tip task_201609140129_0001_m_000039, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:07,107 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000039_0' has completed task_201609140129_0001_m_000039 successfully.
2016-09-14 01:30:07,116 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000002_0' to tip task_201609140129_0001_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000002
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000000_0' to tip task_201609140129_0001_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000000
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000001_0' to tip task_201609140129_0001_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000001
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000003_0' to tip task_201609140129_0001_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:07,119 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000003
2016-09-14 01:30:07,120 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000004_0' to tip task_201609140129_0001_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:07,120 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000004
2016-09-14 01:30:07,120 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000006_0' to tip task_201609140129_0001_m_000006, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:30:07,120 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000006
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000007_0' to tip task_201609140129_0001_m_000007, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000007
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000008_0' to tip task_201609140129_0001_m_000008, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000008
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000009_0' to tip task_201609140129_0001_m_000009, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000009
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000010_0' to tip task_201609140129_0001_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:30:07,121 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000010
2016-09-14 01:30:07,140 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000005_0' to tip task_201609140129_0001_m_000005, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:07,140 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000005
2016-09-14 01:30:07,140 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000016_0' to tip task_201609140129_0001_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:07,140 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000016
2016-09-14 01:30:07,140 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000017_0' to tip task_201609140129_0001_m_000017, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:07,141 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000017
2016-09-14 01:30:07,141 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000018_0' to tip task_201609140129_0001_m_000018, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:07,141 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000018
2016-09-14 01:30:07,141 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000019_0' to tip task_201609140129_0001_m_000019, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:07,141 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000019
2016-09-14 01:30:07,205 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000011_0' to tip task_201609140129_0001_m_000011, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:07,205 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000011
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000012_0' to tip task_201609140129_0001_m_000012, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000012
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000013_0' to tip task_201609140129_0001_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000013
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000014_0' to tip task_201609140129_0001_m_000014, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000014
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000015_0' to tip task_201609140129_0001_m_000015, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:07,206 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000015
2016-09-14 01:30:10,093 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000020_0' to tip task_201609140129_0001_m_000020, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000020
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000021_0' to tip task_201609140129_0001_m_000021, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000021
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000022_0' to tip task_201609140129_0001_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000022
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000023_0' to tip task_201609140129_0001_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000023
2016-09-14 01:30:10,094 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000024_0' to tip task_201609140129_0001_m_000024, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:30:10,095 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000024
2016-09-14 01:30:31,159 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000002_0' has completed task_201609140129_0001_m_000002 successfully.
2016-09-14 01:30:31,161 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000025_0' to tip task_201609140129_0001_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:31,161 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000025
2016-09-14 01:30:41,391 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000014_0' has completed task_201609140129_0001_m_000014 successfully.
2016-09-14 01:30:41,392 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000026_0' to tip task_201609140129_0001_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:41,393 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000026
2016-09-14 01:30:41,394 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000000_0' to tip task_201609140129_0001_r_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:43,173 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000001_0' has completed task_201609140129_0001_m_000001 successfully.
2016-09-14 01:30:43,175 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000027_0' to tip task_201609140129_0001_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:43,175 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000027
2016-09-14 01:30:43,176 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000001_0' to tip task_201609140129_0001_r_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:30:43,224 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000002_0' to tip task_201609140129_0001_r_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:30:43,336 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000003_0' to tip task_201609140129_0001_r_000003, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:43,781 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000004_0' to tip task_201609140129_0001_r_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:30:44,847 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000015_0' has completed task_201609140129_0001_m_000015 successfully.
2016-09-14 01:30:44,848 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000028_0' to tip task_201609140129_0001_m_000028, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:30:44,848 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000028
2016-09-14 01:30:55,722 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000016_0' has completed task_201609140129_0001_m_000016 successfully.
2016-09-14 01:30:55,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000029_0' to tip task_201609140129_0001_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:55,724 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000029
2016-09-14 01:30:58,736 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000017_0' has completed task_201609140129_0001_m_000017 successfully.
2016-09-14 01:30:58,737 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000030_0' to tip task_201609140129_0001_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:30:58,737 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000030
2016-09-14 01:31:04,758 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000018_0' has completed task_201609140129_0001_m_000018 successfully.
2016-09-14 01:31:04,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000031_0' to tip task_201609140129_0001_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:31:04,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000031
2016-09-14 01:31:16,806 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000005_0' has completed task_201609140129_0001_m_000005 successfully.
2016-09-14 01:31:16,807 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000032_0' to tip task_201609140129_0001_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:31:16,807 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000032
2016-09-14 01:31:31,879 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000019_0' has completed task_201609140129_0001_m_000019 successfully.
2016-09-14 01:31:31,881 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000033_0' to tip task_201609140129_0001_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:31:31,881 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000033
2016-09-14 01:31:56,254 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000012_0' has completed task_201609140129_0001_m_000012 successfully.
2016-09-14 01:31:56,256 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000034_0' to tip task_201609140129_0001_m_000034, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:31:56,256 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000034
2016-09-14 01:31:56,865 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000020_0' has completed task_201609140129_0001_m_000020 successfully.
2016-09-14 01:31:56,866 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000021_0' has completed task_201609140129_0001_m_000021 successfully.
2016-09-14 01:31:56,867 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000022_0' has completed task_201609140129_0001_m_000022 successfully.
2016-09-14 01:31:56,868 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000035_0' to tip task_201609140129_0001_m_000035, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:31:56,868 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000035
2016-09-14 01:31:56,868 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000036_0' to tip task_201609140129_0001_m_000036, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:31:56,868 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000036
2016-09-14 01:31:56,868 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000037_0' to tip task_201609140129_0001_m_000037, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:31:56,868 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000037
2016-09-14 01:31:59,015 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000031_0' has completed task_201609140129_0001_m_000031 successfully.
2016-09-14 01:32:02,034 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000030_0' has completed task_201609140129_0001_m_000030 successfully.
2016-09-14 01:32:02,949 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000023_0' has completed task_201609140129_0001_m_000023 successfully.
2016-09-14 01:32:02,950 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000024_0' has completed task_201609140129_0001_m_000024 successfully.
2016-09-14 01:32:10,314 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000003_0' has completed task_201609140129_0001_m_000003 successfully.
2016-09-14 01:32:14,098 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000026 for speculative execution
2016-09-14 01:32:14,098 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000026_1' to tip task_201609140129_0001_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:32:14,098 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000026
2016-09-14 01:32:20,118 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000029_0' has completed task_201609140129_0001_m_000029 successfully.
2016-09-14 01:32:20,118 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000032_0' has completed task_201609140129_0001_m_000032 successfully.
2016-09-14 01:32:20,119 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000025 for speculative execution
2016-09-14 01:32:20,119 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000025_1' to tip task_201609140129_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:32:20,119 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000025
2016-09-14 01:32:23,131 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000033_0' has completed task_201609140129_0001_m_000033 successfully.
2016-09-14 01:32:23,132 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000000 for speculative execution
2016-09-14 01:32:23,132 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000000_1' to tip task_201609140129_0001_m_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:32:23,132 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000000
2016-09-14 01:32:26,145 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000004 for speculative execution
2016-09-14 01:32:26,146 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000004_1' to tip task_201609140129_0001_m_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:32:26,146 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000004
2016-09-14 01:32:36,035 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000036_0' has completed task_201609140129_0001_m_000036 successfully.
2016-09-14 01:32:36,036 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000037_0' has completed task_201609140129_0001_m_000037 successfully.
2016-09-14 01:32:48,064 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000035_0' has completed task_201609140129_0001_m_000035 successfully.
2016-09-14 01:32:49,490 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000009_0' has completed task_201609140129_0001_m_000009 successfully.
2016-09-14 01:32:49,493 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000010_0' has completed task_201609140129_0001_m_000010 successfully.
2016-09-14 01:32:51,074 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000011 for speculative execution
2016-09-14 01:32:51,075 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000011_1' to tip task_201609140129_0001_m_000011, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:32:51,075 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000011
2016-09-14 01:32:54,085 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000027 for speculative execution
2016-09-14 01:32:54,086 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000027_1' to tip task_201609140129_0001_m_000027, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:32:54,086 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000027
2016-09-14 01:32:57,089 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000034 for speculative execution
2016-09-14 01:32:57,089 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000034_1' to tip task_201609140129_0001_m_000034, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:32:57,089 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0001_m_000034
2016-09-14 01:33:11,087 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000008_0' has completed task_201609140129_0001_m_000008 successfully.
2016-09-14 01:33:27,807 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000006_0' has completed task_201609140129_0001_m_000006 successfully.
2016-09-14 01:33:27,808 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000007_0' has completed task_201609140129_0001_m_000007 successfully.
2016-09-14 01:33:36,867 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000025_1' has completed task_201609140129_0001_m_000025 successfully.
2016-09-14 01:33:36,941 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000000_1' has completed task_201609140129_0001_m_000000 successfully.
2016-09-14 01:33:36,941 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000004_1' has completed task_201609140129_0001_m_000004 successfully.
2016-09-14 01:33:36,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000013 for speculative execution
2016-09-14 01:33:36,943 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000013_1' to tip task_201609140129_0001_m_000013, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:33:36,943 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000013
2016-09-14 01:33:42,970 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000026_1' has completed task_201609140129_0001_m_000026 successfully.
2016-09-14 01:33:48,086 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000000_0'
2016-09-14 01:33:48,086 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000004_0'
2016-09-14 01:33:48,086 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000000_0' to tip task_201609140129_0001_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:33:48,400 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000004_0' to tip task_201609140129_0001_m_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:33:53,126 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000025_0'
2016-09-14 01:33:53,126 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000027_0' has completed task_201609140129_0001_m_000027 successfully.
2016-09-14 01:33:53,127 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000025_0' to tip task_201609140129_0001_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:33:56,134 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0001_m_000028 for speculative execution
2016-09-14 01:33:56,134 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0001_m_000028_1' to tip task_201609140129_0001_m_000028, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:33:56,134 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0001_m_000028
2016-09-14 01:33:56,134 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000000_0'
2016-09-14 01:33:56,134 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000025_0'
2016-09-14 01:34:00,039 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000027_1'
2016-09-14 01:34:00,039 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000027_1' to tip task_201609140129_0001_m_000027, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:34:03,026 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000026_0'
2016-09-14 01:34:03,027 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000028_0' has completed task_201609140129_0001_m_000028 successfully.
2016-09-14 01:34:03,029 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000026_0' to tip task_201609140129_0001_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:34:04,073 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000013_1' has completed task_201609140129_0001_m_000013 successfully.
2016-09-14 01:34:10,160 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000028_1'
2016-09-14 01:34:10,160 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000028_1' to tip task_201609140129_0001_m_000028, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:34:13,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000028_1'
2016-09-14 01:34:24,533 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609140129_0001_m_000027_1 on tracker_slave5:127.0.0.1/127.0.0.1:36201: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/spill3.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:351)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:132)
	at org.apache.hadoop.mapred.MapOutputFile.getSpillFileForWrite(MapOutputFile.java:126)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1412)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1308)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:591)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:657)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:328)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInf
2016-09-14 01:34:25,014 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000013_0'
2016-09-14 01:34:25,014 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000034_0' has completed task_201609140129_0001_m_000034 successfully.
2016-09-14 01:34:25,015 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000013_0' to tip task_201609140129_0001_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:34:35,223 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000013_0'
2016-09-14 01:34:35,223 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000026_0'
2016-09-14 01:34:35,609 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000034_1'
2016-09-14 01:34:35,609 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000034_1' to tip task_201609140129_0001_m_000034, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:34:38,612 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000011_1' has completed task_201609140129_0001_m_000011 successfully.
2016-09-14 01:34:41,617 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000034_1'
2016-09-14 01:34:46,242 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000011_0'
2016-09-14 01:34:46,242 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_m_000011_0' to tip task_201609140129_0001_m_000011, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:34:49,247 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000011_0'
2016-09-14 01:34:50,972 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000004_0'
2016-09-14 01:34:50,972 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000027_1'
2016-09-14 01:35:41,807 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_r_000003_0' has completed task_201609140129_0001_r_000003 successfully.
2016-09-14 01:36:23,921 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140129_0001_r_000001 for speculative execution
2016-09-14 01:36:23,921 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000001_1' to tip task_201609140129_0001_r_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:36:25,640 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140129_0001_r_000001_1 is 1719 ms debug.
2016-09-14 01:36:41,065 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140129_0001_r_000004 for speculative execution
2016-09-14 01:36:41,066 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0001_r_000004_1' to tip task_201609140129_0001_r_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:36:44,199 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_r_000002_0' has completed task_201609140129_0001_r_000002 successfully.
2016-09-14 01:37:02,987 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_r_000000_0' has completed task_201609140129_0001_r_000000 successfully.
2016-09-14 01:38:09,448 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_r_000004_0' has completed task_201609140129_0001_r_000004 successfully.
2016-09-14 01:38:17,313 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000004_1'
2016-09-14 01:38:17,314 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0001_r_000004_1' to tip task_201609140129_0001_r_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:38:20,317 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000004_1'
2016-09-14 01:38:57,087 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_r_000001_0' has completed task_201609140129_0001_r_000001 successfully.
2016-09-14 01:38:57,090 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609140129_0001_m_000038_0' to tip task_201609140129_0001_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:39:00,093 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0001_m_000038_0' has completed task_201609140129_0001_m_000038 successfully.
2016-09-14 01:39:00,094 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140129_0001 has completed successfully.
2016-09-14 01:39:00,095 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609140129_0001,submitTime=1473796799418,launchTime=1473796799796,finishTime=1473797340094,numMaps=38,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=3609,reduceSlotsSeconds=1969,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 01:39:00,218 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140129_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140129_0001_hduser
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000001_0'
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000002_0'
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000003_0'
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000027_0'
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000038_0'
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000039_0'
2016-09-14 01:39:00,220 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000001_0'
2016-09-14 01:39:00,232 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140129_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140129_0001_conf.xml
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609140129_0001_conf.xml
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000000_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000004_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000005_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000006_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000007_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000008_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000009_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000010_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000011_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000012_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000013_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000014_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000015_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000016_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000017_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000018_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000019_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000020_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000021_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000022_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000023_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000024_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000025_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000026_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000028_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000029_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000030_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000031_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000032_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000033_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000034_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000035_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000036_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_m_000037_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000000_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000001_1'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000002_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000003_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0001_r_000004_0'
2016-09-14 01:39:00,239 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609140129_0001' of user 'hduser'
2016-09-14 01:41:54,600 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140129_0002 added successfully for user 'hduser' to queue 'default'
2016-09-14 01:41:54,601 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140129_0002
2016-09-14 01:41:54,601 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140129_0002
2016-09-14 01:41:54,604 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140129_0002_hduser
2016-09-14 01:41:54,611 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140129_0002_conf.xml
2016-09-14 01:41:54,642 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140129_0002/jobToken
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140129_0002 = 10000000000. Number of splits = 38
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000000 has split on node:/default-rack/slave1
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000001 has split on node:/default-rack/slave1
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000002 has split on node:/default-rack/slave3
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000003 has split on node:/default-rack/slave1
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000004 has split on node:/default-rack/slave1
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000005 has split on node:/default-rack/slave1
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000006 has split on node:/default-rack/slave2
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000007 has split on node:/default-rack/slave2
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000008 has split on node:/default-rack/slave2
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000009 has split on node:/default-rack/slave2
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000010 has split on node:/default-rack/slave2
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000011 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000012 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000013 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000014 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000015 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000016 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000016 has split on node:/default-rack/slave1
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000016 has split on node:/default-rack/slave2
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000017 has split on node:/default-rack/slave5
2016-09-14 01:41:54,666 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000017 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000017 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000018 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000018 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000018 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000019 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000019 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000019 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000020 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000020 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000020 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000021 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000021 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000021 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000022 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000022 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000022 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000023 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000023 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000023 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000024 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000024 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000024 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000025 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000025 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000025 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000026 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000026 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000026 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000027 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000027 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000027 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000028 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000028 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000028 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000029 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000029 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000029 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000030 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000030 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000030 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000031 has split on node:/default-rack/slave1
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000031 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000031 has split on node:/default-rack/slave5
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000032 has split on node:/default-rack/slave2
2016-09-14 01:41:54,667 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000032 has split on node:/default-rack/slave1
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000032 has split on node:/default-rack/slave5
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000033 has split on node:/default-rack/slave5
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000033 has split on node:/default-rack/slave1
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000033 has split on node:/default-rack/slave2
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000034 has split on node:/default-rack/slave2
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000034 has split on node:/default-rack/slave1
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000034 has split on node:/default-rack/slave5
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000035 has split on node:/default-rack/slave5
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000035 has split on node:/default-rack/slave1
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000035 has split on node:/default-rack/slave2
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000036 has split on node:/default-rack/slave5
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000036 has split on node:/default-rack/slave1
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000036 has split on node:/default-rack/slave2
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000037 has split on node:/default-rack/slave2
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000037 has split on node:/default-rack/slave1
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0002_m_000037 has split on node:/default-rack/slave5
2016-09-14 01:41:54,668 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140129_0002 initialized successfully with 38 map tasks and 5 reduce tasks.
2016-09-14 01:41:55,460 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140129_0002_m_000039_0' to tip task_201609140129_0002_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:41:58,464 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000039_0' has completed task_201609140129_0002_m_000039 successfully.
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000006_0' to tip task_201609140129_0002_m_000006, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000006
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000007_0' to tip task_201609140129_0002_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000007
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000008_0' to tip task_201609140129_0002_m_000008, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000008
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000009_0' to tip task_201609140129_0002_m_000009, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000009
2016-09-14 01:41:58,466 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000010_0' to tip task_201609140129_0002_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:41:58,467 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000010
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000011_0' to tip task_201609140129_0002_m_000011, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000011
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000012_0' to tip task_201609140129_0002_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000012
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000013_0' to tip task_201609140129_0002_m_000013, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000013
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000014_0' to tip task_201609140129_0002_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:41:58,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000014
2016-09-14 01:41:58,943 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000015_0' to tip task_201609140129_0002_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:41:58,943 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000015
2016-09-14 01:42:00,324 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000002_0' to tip task_201609140129_0002_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:00,325 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000002
2016-09-14 01:42:00,325 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000000_0' to tip task_201609140129_0002_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:00,325 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000000
2016-09-14 01:42:00,326 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000001_0' to tip task_201609140129_0002_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:00,326 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000001
2016-09-14 01:42:00,326 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000003_0' to tip task_201609140129_0002_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:00,326 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000003
2016-09-14 01:42:00,326 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000004_0' to tip task_201609140129_0002_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:00,326 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000004
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000005_0' to tip task_201609140129_0002_m_000005, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000005
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000016_0' to tip task_201609140129_0002_m_000016, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000016
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000017_0' to tip task_201609140129_0002_m_000017, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000017
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000018_0' to tip task_201609140129_0002_m_000018, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000018
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000019_0' to tip task_201609140129_0002_m_000019, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:00,456 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000019
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000020_0' to tip task_201609140129_0002_m_000020, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000020
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000021_0' to tip task_201609140129_0002_m_000021, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000021
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000022_0' to tip task_201609140129_0002_m_000022, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000022
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000023_0' to tip task_201609140129_0002_m_000023, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:42:00,604 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000023
2016-09-14 01:42:00,605 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000024_0' to tip task_201609140129_0002_m_000024, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:42:00,605 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000024
2016-09-14 01:42:18,340 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000002_0' has completed task_201609140129_0002_m_000002 successfully.
2016-09-14 01:42:18,340 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000025_0' to tip task_201609140129_0002_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:18,341 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000025
2016-09-14 01:42:46,872 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000006_0' has completed task_201609140129_0002_m_000006 successfully.
2016-09-14 01:42:46,873 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000026_0' to tip task_201609140129_0002_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:42:46,873 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000026
2016-09-14 01:42:46,873 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000000_0' to tip task_201609140129_0002_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:42:47,156 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000001_0' to tip task_201609140129_0002_r_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:42:48,362 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000001_0' has completed task_201609140129_0002_m_000001 successfully.
2016-09-14 01:42:48,363 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000027_0' to tip task_201609140129_0002_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:48,363 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000027
2016-09-14 01:42:48,363 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000002_0' to tip task_201609140129_0002_r_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:42:48,495 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000003_0' to tip task_201609140129_0002_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:48,710 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000004_0' to tip task_201609140129_0002_r_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:42:49,917 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000007_0' has completed task_201609140129_0002_m_000007 successfully.
2016-09-14 01:42:49,919 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000008_0' has completed task_201609140129_0002_m_000008 successfully.
2016-09-14 01:42:49,921 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000010_0' has completed task_201609140129_0002_m_000010 successfully.
2016-09-14 01:42:49,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000028_0' to tip task_201609140129_0002_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:42:49,923 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000028
2016-09-14 01:42:49,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000029_0' to tip task_201609140129_0002_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:42:49,923 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000029
2016-09-14 01:42:49,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000030_0' to tip task_201609140129_0002_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:42:49,923 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000030
2016-09-14 01:42:54,501 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000018_0' has completed task_201609140129_0002_m_000018 successfully.
2016-09-14 01:42:54,503 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000031_0' to tip task_201609140129_0002_m_000031, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:42:54,503 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000031
2016-09-14 01:43:00,516 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000019_0' has completed task_201609140129_0002_m_000019 successfully.
2016-09-14 01:43:00,517 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000032_0' to tip task_201609140129_0002_m_000032, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:43:00,517 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000032
2016-09-14 01:43:12,395 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000009_0' has completed task_201609140129_0002_m_000009 successfully.
2016-09-14 01:43:12,398 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000033_0' to tip task_201609140129_0002_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:43:12,398 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000033
2016-09-14 01:43:47,506 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000025_0' has completed task_201609140129_0002_m_000025 successfully.
2016-09-14 01:43:47,507 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000034_0' to tip task_201609140129_0002_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:43:47,507 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0002_m_000034
2016-09-14 01:43:47,971 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000029_0' has completed task_201609140129_0002_m_000029 successfully.
2016-09-14 01:43:47,972 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000035_0' to tip task_201609140129_0002_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:43:47,972 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000035
2016-09-14 01:43:52,903 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000015_0' has completed task_201609140129_0002_m_000015 successfully.
2016-09-14 01:43:52,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000036_0' to tip task_201609140129_0002_m_000036, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:43:52,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000036
2016-09-14 01:43:54,973 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000026_0' has completed task_201609140129_0002_m_000026 successfully.
2016-09-14 01:43:54,975 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000037_0' to tip task_201609140129_0002_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:43:54,975 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000037
2016-09-14 01:43:56,761 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000013_0' has completed task_201609140129_0002_m_000013 successfully.
2016-09-14 01:44:00,057 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000028_0' has completed task_201609140129_0002_m_000028 successfully.
2016-09-14 01:44:03,652 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000005_0' has completed task_201609140129_0002_m_000005 successfully.
2016-09-14 01:44:06,675 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000030_0' has completed task_201609140129_0002_m_000030 successfully.
2016-09-14 01:44:11,586 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000000_0' has completed task_201609140129_0002_m_000000 successfully.
2016-09-14 01:44:11,587 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000004_0' has completed task_201609140129_0002_m_000004 successfully.
2016-09-14 01:44:14,591 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0002_m_000032 for speculative execution
2016-09-14 01:44:14,592 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000032_1' to tip task_201609140129_0002_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:44:14,592 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000032
2016-09-14 01:44:14,594 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000003_0' has completed task_201609140129_0002_m_000003 successfully.
2016-09-14 01:44:16,807 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000011_0' has completed task_201609140129_0002_m_000011 successfully.
2016-09-14 01:44:16,809 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000012_0' has completed task_201609140129_0002_m_000012 successfully.
2016-09-14 01:44:16,811 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000014_0' has completed task_201609140129_0002_m_000014 successfully.
2016-09-14 01:44:17,600 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000033_0' has completed task_201609140129_0002_m_000033 successfully.
2016-09-14 01:44:22,007 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000017_0' has completed task_201609140129_0002_m_000017 successfully.
2016-09-14 01:44:26,633 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000037_0' has completed task_201609140129_0002_m_000037 successfully.
2016-09-14 01:44:26,634 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0002_m_000027 for speculative execution
2016-09-14 01:44:26,635 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000027_1' to tip task_201609140129_0002_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:44:26,635 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000027
2016-09-14 01:44:28,041 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000016_0' has completed task_201609140129_0002_m_000016 successfully.
2016-09-14 01:44:31,875 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000036_0' has completed task_201609140129_0002_m_000036 successfully.
2016-09-14 01:44:35,957 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000020_0' has completed task_201609140129_0002_m_000020 successfully.
2016-09-14 01:44:35,958 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000021_0' has completed task_201609140129_0002_m_000021 successfully.
2016-09-14 01:44:43,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0002_m_000031 for speculative execution
2016-09-14 01:44:43,942 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000031_1' to tip task_201609140129_0002_m_000031, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:44:43,942 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000031
2016-09-14 01:44:48,906 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000035_0' has completed task_201609140129_0002_m_000035 successfully.
2016-09-14 01:44:49,972 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0002_m_000034 for speculative execution
2016-09-14 01:44:49,972 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0002_m_000034_1' to tip task_201609140129_0002_m_000034, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:44:49,972 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0002_m_000034
2016-09-14 01:44:57,075 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000022_0' has completed task_201609140129_0002_m_000022 successfully.
2016-09-14 01:44:57,075 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000023_0' has completed task_201609140129_0002_m_000023 successfully.
2016-09-14 01:45:00,714 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000024_0' has completed task_201609140129_0002_m_000024 successfully.
2016-09-14 01:45:00,955 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000032_1' has completed task_201609140129_0002_m_000032 successfully.
2016-09-14 01:45:02,063 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000031_1' has completed task_201609140129_0002_m_000031 successfully.
2016-09-14 01:45:06,713 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000032_0'
2016-09-14 01:45:06,713 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0002_m_000032_0' to tip task_201609140129_0002_m_000032, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:45:12,203 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000031_0'
2016-09-14 01:45:12,203 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0002_m_000031_0' to tip task_201609140129_0002_m_000031, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:45:12,995 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000027_1' has completed task_201609140129_0002_m_000027 successfully.
2016-09-14 01:45:19,804 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000027_0'
2016-09-14 01:45:19,805 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0002_m_000027_0' to tip task_201609140129_0002_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:45:22,809 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000027_0'
2016-09-14 01:45:30,215 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000031_0'
2016-09-14 01:45:30,215 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000032_0'
2016-09-14 01:45:32,403 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000034_1' has completed task_201609140129_0002_m_000034 successfully.
2016-09-14 01:45:38,967 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000034_0'
2016-09-14 01:45:38,968 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0002_m_000034_0' to tip task_201609140129_0002_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:45:41,971 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000034_0'
2016-09-14 01:46:50,833 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_r_000000_0' has completed task_201609140129_0002_r_000000 successfully.
2016-09-14 01:47:30,631 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_r_000004_0' has completed task_201609140129_0002_r_000004 successfully.
2016-09-14 01:47:54,022 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140129_0002_r_000002 for speculative execution
2016-09-14 01:47:54,023 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000002_1' to tip task_201609140129_0002_r_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:48:25,267 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140129_0002_r_000003 for speculative execution
2016-09-14 01:48:25,267 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0002_r_000003_1' to tip task_201609140129_0002_r_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:48:28,285 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_r_000001_0' has completed task_201609140129_0002_r_000001 successfully.
2016-09-14 01:48:55,403 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_r_000003_0' has completed task_201609140129_0002_r_000003 successfully.
2016-09-14 01:49:03,419 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000003_1'
2016-09-14 01:49:03,420 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0002_r_000003_1' to tip task_201609140129_0002_r_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:49:06,454 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000003_1'
2016-09-14 01:49:28,728 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_r_000002_0' has completed task_201609140129_0002_r_000002 successfully.
2016-09-14 01:49:28,728 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609140129_0002_m_000038_0' to tip task_201609140129_0002_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:49:34,759 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0002_m_000038_0' has completed task_201609140129_0002_m_000038 successfully.
2016-09-14 01:49:34,760 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140129_0002 has completed successfully.
2016-09-14 01:49:34,760 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609140129_0002,submitTime=1473797514542,launchTime=1473797514668,finishTime=1473797974760,numMaps=38,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=3434,reduceSlotsSeconds=1622,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 01:49:34,989 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140129_0002_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140129_0002_hduser
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000000_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000001_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000002_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000003_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000004_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000025_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000038_0'
2016-09-14 01:49:34,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000002_0'
2016-09-14 01:49:34,994 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140129_0002_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140129_0002_conf.xml
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609140129_0002_conf.xml
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000005_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000006_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000007_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000008_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000009_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000010_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000011_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000012_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000013_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000014_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000015_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000016_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000017_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000018_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000019_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000020_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000021_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000022_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000023_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000024_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000026_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000027_1'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000028_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000029_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000030_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000031_1'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000032_1'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000033_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000034_1'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000035_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000036_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000037_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000000_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000001_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000002_1'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000003_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_r_000004_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0002_m_000039_0'
2016-09-14 01:49:34,997 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609140129_0002' of user 'hduser'
2016-09-14 01:53:10,622 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609140129_0003 added successfully for user 'hduser' to queue 'default'
2016-09-14 01:53:10,622 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609140129_0003
2016-09-14 01:53:10,622 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609140129_0003
2016-09-14 01:53:10,625 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609140129_0003_hduser
2016-09-14 01:53:10,631 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609140129_0003_conf.xml
2016-09-14 01:53:10,664 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609140129_0003/jobToken
2016-09-14 01:53:10,667 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609140129_0003 = 20000000000. Number of splits = 40
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000000 has split on node:/default-rack/slave4
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000001 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000002 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000003 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000004 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000005 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000006 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000007 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000008 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000009 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000010 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000011 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000012 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000013 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000014 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000015 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000016 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000017 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000018 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000019 has split on node:/default-rack/slave4
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000020 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000020 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000020 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000021 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000021 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000021 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000022 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000022 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000022 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000023 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000023 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000023 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000024 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000024 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000024 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000025 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000025 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000025 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000026 has split on node:/default-rack/slave5
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000026 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000026 has split on node:/default-rack/slave2
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000027 has split on node:/default-rack/slave1
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000027 has split on node:/default-rack/slave3
2016-09-14 01:53:10,668 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000027 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000028 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000028 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000028 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000029 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000029 has split on node:/default-rack/slave3
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000029 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000030 has split on node:/default-rack/slave3
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000030 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000030 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000031 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000031 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000031 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000032 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000032 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000032 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000033 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000033 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000033 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000034 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000034 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000034 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000035 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000036 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000037 has split on node:/default-rack/slave4
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000038 has split on node:/default-rack/slave2
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000038 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000038 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000039 has split on node:/default-rack/slave1
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000039 has split on node:/default-rack/slave3
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609140129_0003_m_000039 has split on node:/default-rack/slave5
2016-09-14 01:53:10,669 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140129_0003 initialized successfully with 40 map tasks and 5 reduce tasks.
2016-09-14 01:53:10,763 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609140129_0003_m_000041_0' to tip task_201609140129_0003_m_000041, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:53:16,770 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000041_0' has completed task_201609140129_0003_m_000041 successfully.
2016-09-14 01:53:16,772 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000000_0' to tip task_201609140129_0003_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:53:16,772 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000000
2016-09-14 01:53:16,772 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000019_0' to tip task_201609140129_0003_m_000019, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:53:16,772 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000019
2016-09-14 01:53:16,772 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000037_0' to tip task_201609140129_0003_m_000037, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:53:16,773 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000037
2016-09-14 01:53:16,773 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000001_0' to tip task_201609140129_0003_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:53:16,773 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000001
2016-09-14 01:53:16,773 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000002_0' to tip task_201609140129_0003_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:53:16,773 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000002
2016-09-14 01:53:17,099 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000003_0' to tip task_201609140129_0003_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000003
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000006_0' to tip task_201609140129_0003_m_000006, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000006
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000008_0' to tip task_201609140129_0003_m_000008, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000008
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000009_0' to tip task_201609140129_0003_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000009
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000021_0' to tip task_201609140129_0003_m_000021, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:53:17,100 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000021
2016-09-14 01:53:17,412 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000004_0' to tip task_201609140129_0003_m_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:53:17,412 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000004
2016-09-14 01:53:17,412 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000005_0' to tip task_201609140129_0003_m_000005, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:53:17,412 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000005
2016-09-14 01:53:17,413 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000007_0' to tip task_201609140129_0003_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:53:17,413 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000007
2016-09-14 01:53:17,413 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000020_0' to tip task_201609140129_0003_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:53:17,413 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000020
2016-09-14 01:53:17,413 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000022_0' to tip task_201609140129_0003_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:53:17,413 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000022
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000014_0' to tip task_201609140129_0003_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000014
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000015_0' to tip task_201609140129_0003_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000015
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000016_0' to tip task_201609140129_0003_m_000016, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000016
2016-09-14 01:53:18,746 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000017_0' to tip task_201609140129_0003_m_000017, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:53:18,747 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000017
2016-09-14 01:53:18,747 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000018_0' to tip task_201609140129_0003_m_000018, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:53:18,747 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000018
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000010_0' to tip task_201609140129_0003_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000010
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000011_0' to tip task_201609140129_0003_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000011
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000012_0' to tip task_201609140129_0003_m_000012, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000012
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000013_0' to tip task_201609140129_0003_m_000013, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000013
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000023_0' to tip task_201609140129_0003_m_000023, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:53:19,253 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000023
2016-09-14 01:54:16,373 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000037_0' has completed task_201609140129_0003_m_000037 successfully.
2016-09-14 01:54:16,373 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000024_0' to tip task_201609140129_0003_m_000024, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:54:16,373 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000024
2016-09-14 01:54:42,618 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000004_0' has completed task_201609140129_0003_m_000004 successfully.
2016-09-14 01:54:42,619 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000005_0' has completed task_201609140129_0003_m_000005 successfully.
2016-09-14 01:54:42,620 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000025_0' to tip task_201609140129_0003_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:54:42,620 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000025
2016-09-14 01:54:42,621 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000026_0' to tip task_201609140129_0003_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:54:42,621 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000026
2016-09-14 01:54:42,621 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000000_0' to tip task_201609140129_0003_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:54:43,289 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000001_0' to tip task_201609140129_0003_r_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 01:54:43,485 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000002_0' to tip task_201609140129_0003_r_000002, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 01:54:43,657 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000003_0' to tip task_201609140129_0003_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:54:45,488 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000004_0' to tip task_201609140129_0003_r_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:54:50,212 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000000_0' has completed task_201609140129_0003_m_000000 successfully.
2016-09-14 01:54:50,213 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000019_0' has completed task_201609140129_0003_m_000019 successfully.
2016-09-14 01:54:50,214 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000027_0' to tip task_201609140129_0003_m_000027, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:54:50,214 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000027
2016-09-14 01:54:50,214 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000028_0' to tip task_201609140129_0003_m_000028, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:54:50,214 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000028
2016-09-14 01:55:04,190 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000020_0' has completed task_201609140129_0003_m_000020 successfully.
2016-09-14 01:55:04,190 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000022_0' has completed task_201609140129_0003_m_000022 successfully.
2016-09-14 01:55:04,190 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000031_0' to tip task_201609140129_0003_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:55:04,191 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000031
2016-09-14 01:55:04,191 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000032_0' to tip task_201609140129_0003_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:55:04,191 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000032
2016-09-14 01:55:08,227 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000002_0' has completed task_201609140129_0003_m_000002 successfully.
2016-09-14 01:55:08,228 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000029_0' to tip task_201609140129_0003_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:55:08,228 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000029
2016-09-14 01:55:29,172 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000008_0' has completed task_201609140129_0003_m_000008 successfully.
2016-09-14 01:55:29,173 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000009_0' has completed task_201609140129_0003_m_000009 successfully.
2016-09-14 01:55:29,173 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000030_0' to tip task_201609140129_0003_m_000030, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:55:29,173 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000030
2016-09-14 01:55:29,173 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000039_0' to tip task_201609140129_0003_m_000039, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:55:29,173 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000039
2016-09-14 01:55:30,418 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000007_0' has completed task_201609140129_0003_m_000007 successfully.
2016-09-14 01:55:30,419 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000033_0' to tip task_201609140129_0003_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:55:30,419 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000033
2016-09-14 01:55:34,351 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000003_0' has completed task_201609140129_0003_m_000003 successfully.
2016-09-14 01:55:34,352 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000034_0' to tip task_201609140129_0003_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:55:34,353 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000034
2016-09-14 01:55:39,392 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000006_0' has completed task_201609140129_0003_m_000006 successfully.
2016-09-14 01:55:39,392 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000021_0' has completed task_201609140129_0003_m_000021 successfully.
2016-09-14 01:55:39,393 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000035_0' to tip task_201609140129_0003_m_000035, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:55:39,393 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000035
2016-09-14 01:55:39,393 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000036_0' to tip task_201609140129_0003_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:55:39,393 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000036
2016-09-14 01:56:09,521 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000039_0' has completed task_201609140129_0003_m_000039 successfully.
2016-09-14 01:56:09,522 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000038_0' to tip task_201609140129_0003_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:56:09,522 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000038
2016-09-14 01:56:27,777 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000030_0' has completed task_201609140129_0003_m_000030 successfully.
2016-09-14 01:56:52,730 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000025_0' has completed task_201609140129_0003_m_000025 successfully.
2016-09-14 01:56:52,731 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000035 for speculative execution
2016-09-14 01:56:52,732 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000035_1' to tip task_201609140129_0003_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:56:52,732 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000035
2016-09-14 01:56:54,875 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000001 for speculative execution
2016-09-14 01:56:54,875 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000001_1' to tip task_201609140129_0003_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:56:54,875 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000001
2016-09-14 01:57:16,365 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000026_0' has completed task_201609140129_0003_m_000026 successfully.
2016-09-14 01:57:16,367 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000036 for speculative execution
2016-09-14 01:57:16,367 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000036_1' to tip task_201609140129_0003_m_000036, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:57:16,367 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000036
2016-09-14 01:57:20,564 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000032_0' has completed task_201609140129_0003_m_000032 successfully.
2016-09-14 01:57:20,565 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000034 for speculative execution
2016-09-14 01:57:20,566 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000034_1' to tip task_201609140129_0003_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:57:20,566 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000034
2016-09-14 01:57:25,502 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000031_0' has completed task_201609140129_0003_m_000031 successfully.
2016-09-14 01:57:59,791 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000015_0' has completed task_201609140129_0003_m_000015 successfully.
2016-09-14 01:57:59,793 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000016_0' has completed task_201609140129_0003_m_000016 successfully.
2016-09-14 01:57:59,793 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000018_0' has completed task_201609140129_0003_m_000018 successfully.
2016-09-14 01:58:03,329 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000014_0' has completed task_201609140129_0003_m_000014 successfully.
2016-09-14 01:58:05,388 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000035_1' has completed task_201609140129_0003_m_000035 successfully.
2016-09-14 01:58:08,046 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000017_0' has completed task_201609140129_0003_m_000017 successfully.
2016-09-14 01:58:09,986 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000033_0' has completed task_201609140129_0003_m_000033 successfully.
2016-09-14 01:58:09,987 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000024 for speculative execution
2016-09-14 01:58:09,987 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000024_1' to tip task_201609140129_0003_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:58:09,988 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000024
2016-09-14 01:58:11,934 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000035_0'
2016-09-14 01:58:11,935 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000035_0' to tip task_201609140129_0003_m_000035, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:58:14,942 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000035_0'
2016-09-14 01:58:29,952 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000038_0' has completed task_201609140129_0003_m_000038 successfully.
2016-09-14 01:58:46,591 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000036_1' has completed task_201609140129_0003_m_000036 successfully.
2016-09-14 01:58:46,591 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000029 for speculative execution
2016-09-14 01:58:46,592 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000029_1' to tip task_201609140129_0003_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 01:58:46,592 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000029
2016-09-14 01:58:53,006 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000036_0'
2016-09-14 01:58:53,006 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000036_0' to tip task_201609140129_0003_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:58:56,009 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000027 for speculative execution
2016-09-14 01:58:56,010 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000027_1' to tip task_201609140129_0003_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:58:56,010 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000027
2016-09-14 01:58:56,010 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000036_0'
2016-09-14 01:59:22,748 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000034_1' has completed task_201609140129_0003_m_000034 successfully.
2016-09-14 01:59:28,069 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000034_0'
2016-09-14 01:59:28,071 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000034_0' to tip task_201609140129_0003_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:59:31,074 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000027_1' has completed task_201609140129_0003_m_000027 successfully.
2016-09-14 01:59:31,076 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000011 for speculative execution
2016-09-14 01:59:31,076 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000011_1' to tip task_201609140129_0003_m_000011, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:59:31,076 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000011
2016-09-14 01:59:31,076 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000034_0'
2016-09-14 01:59:40,111 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000001_1' has completed task_201609140129_0003_m_000001 successfully.
2016-09-14 01:59:40,112 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000023 for speculative execution
2016-09-14 01:59:40,112 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000023_1' to tip task_201609140129_0003_m_000023, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 01:59:40,112 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609140129_0003_m_000023
2016-09-14 01:59:45,185 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000027_0'
2016-09-14 01:59:45,185 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000027_0' to tip task_201609140129_0003_m_000027, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 01:59:45,642 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609140129_0003_m_000027_0 is 457 ms debug.
2016-09-14 01:59:58,264 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000001_0'
2016-09-14 01:59:58,264 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000001_0' to tip task_201609140129_0003_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 02:00:01,898 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000024_1' has completed task_201609140129_0003_m_000024 successfully.
2016-09-14 02:00:01,899 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000010 for speculative execution
2016-09-14 02:00:01,899 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000010_1' to tip task_201609140129_0003_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 02:00:01,899 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000010
2016-09-14 02:00:04,270 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000028_0' has completed task_201609140129_0003_m_000028 successfully.
2016-09-14 02:00:09,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000024_0'
2016-09-14 02:00:09,589 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000024_0' to tip task_201609140129_0003_m_000024, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 02:00:33,053 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000013_0' has completed task_201609140129_0003_m_000013 successfully.
2016-09-14 02:00:35,055 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609140129_0003_m_000012 for speculative execution
2016-09-14 02:00:35,055 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609140129_0003_m_000012_1' to tip task_201609140129_0003_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 02:00:35,056 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609140129_0003_m_000012
2016-09-14 02:00:39,712 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000001_0'
2016-09-14 02:00:39,712 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000024_0'
2016-09-14 02:00:39,712 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000027_0'
2016-09-14 02:00:41,951 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000012_0' has completed task_201609140129_0003_m_000012 successfully.
2016-09-14 02:00:46,978 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000010_0' has completed task_201609140129_0003_m_000010 successfully.
2016-09-14 02:00:46,978 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000023_0' has completed task_201609140129_0003_m_000023 successfully.
2016-09-14 02:00:49,535 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000012_1'
2016-09-14 02:00:49,536 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000012_1' to tip task_201609140129_0003_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 02:00:52,538 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000012_1'
2016-09-14 02:00:53,044 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000010_1'
2016-09-14 02:00:53,044 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000010_1' to tip task_201609140129_0003_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 02:00:53,349 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000011_0' has completed task_201609140129_0003_m_000011 successfully.
2016-09-14 02:00:56,682 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000029_1' has completed task_201609140129_0003_m_000029 successfully.
2016-09-14 02:00:56,683 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000010_1'
2016-09-14 02:00:56,744 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000023_1'
2016-09-14 02:00:56,744 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000023_1' to tip task_201609140129_0003_m_000023, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 02:01:01,754 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000011_1'
2016-09-14 02:01:01,754 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000011_1' to tip task_201609140129_0003_m_000011, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:39175'
2016-09-14 02:01:03,955 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000029_0'
2016-09-14 02:01:03,956 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609140129_0003_m_000029_0' to tip task_201609140129_0003_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 02:01:04,756 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000011_1'
2016-09-14 02:01:04,757 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000023_1'
2016-09-14 02:01:12,964 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000029_0'
2016-09-14 02:04:45,513 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_r_000000_0' has completed task_201609140129_0003_r_000000 successfully.
2016-09-14 02:05:18,631 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140129_0003_r_000001 for speculative execution
2016-09-14 02:05:18,631 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000001_1' to tip task_201609140129_0003_r_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 02:06:20,484 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_r_000002_0' has completed task_201609140129_0003_r_000002 successfully.
2016-09-14 02:06:58,133 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609140129_0003_r_000004 for speculative execution
2016-09-14 02:06:58,133 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609140129_0003_r_000004_1' to tip task_201609140129_0003_r_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:36752'
2016-09-14 02:07:01,226 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_r_000003_0' has completed task_201609140129_0003_r_000003 successfully.
2016-09-14 02:11:29,062 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_r_000004_0' has completed task_201609140129_0003_r_000004 successfully.
2016-09-14 02:11:29,723 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_r_000001_1' has completed task_201609140129_0003_r_000001 successfully.
2016-09-14 02:11:29,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609140129_0003_m_000040_0' to tip task_201609140129_0003_m_000040, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 02:11:35,846 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609140129_0003_m_000040_0' has completed task_201609140129_0003_m_000040 successfully.
2016-09-14 02:11:35,846 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609140129_0003 has completed successfully.
2016-09-14 02:11:35,846 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609140129_0003,submitTime=1473798190556,launchTime=1473798190669,finishTime=1473799295846,numMaps=40,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=7241,reduceSlotsSeconds=3400,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140129_0003_hduser to file:/usr/local/hadoop/logs/history/done/job_201609140129_0003_hduser
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000004_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000005_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000007_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000020_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000022_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000024_1'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000025_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000026_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000029_1'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000031_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000032_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000033_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000034_1'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000035_1'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000036_1'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000040_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000000_0'
2016-09-14 02:11:35,969 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000001_1'
2016-09-14 02:11:35,979 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000010_0'
2016-09-14 02:11:35,979 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000011_0'
2016-09-14 02:11:35,979 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000012_0'
2016-09-14 02:11:35,979 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000013_0'
2016-09-14 02:11:35,979 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000023_0'
2016-09-14 02:11:35,979 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000002_0'
2016-09-14 02:11:35,986 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609140129_0003_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609140129_0003_conf.xml
2016-09-14 02:11:36,008 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609140129_0003_conf.xml
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000000_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000001_1'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000002_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000003_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000006_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000008_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000009_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000014_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000015_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000016_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000017_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000018_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000019_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000021_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000027_1'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000028_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000030_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000037_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000038_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000039_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000001_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000003_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000004_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_r_000004_1'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609140129_0003_m_000041_0'
2016-09-14 02:11:36,009 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609140129_0003' of user 'hduser'
2016-09-14 02:29:45,699 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609140012_0001.info]
2016-09-14 02:29:45,737 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609140110_0001.info]
2016-09-14 02:29:45,745 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609140110_0002.info]
2016-09-14 02:53:05,645 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave1:127.0.0.1/127.0.0.1:40926'
2016-09-14 03:13:05,647 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40050'
2016-09-14 03:29:45,649 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:36201'
2016-09-14 03:29:45,755 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609140129_0001.info]
2016-09-14 03:29:45,803 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609140129_0002.info]
2016-09-14 03:29:45,820 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609140129_0003.info]
2016-09-14 13:42:15,139 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 13:42:20,627 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 13:42:20,692 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 13:42:20,695 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 13:42:20,696 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 13:42:20,696 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 13:42:20,696 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 13:42:20,696 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 13:42:20,697 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 13:42:20,714 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 13:42:20,724 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 13:42:20,727 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:20,730 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 13:42:20,732 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:20,732 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 13:42:20,755 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 13:42:20,779 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 13:42:20,780 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 13:42:20,788 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 13:42:20,789 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 13:42:20,789 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 13:42:20,789 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 13:42:21,025 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 13:42:21,026 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 13:42:21,027 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:21,027 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:21,027 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 13:42:21,028 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 13:42:21,133 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 13:42:21,222 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:42:21,224 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 480 needs additional 757 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:31,228 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:42:31,229 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:41,234 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:42:41,237 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:42:51,241 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:42:51,250 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:43:01,256 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:43:01,258 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:43:11,261 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:43:11,262 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:43:21,264 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:43:21,265 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:43:31,267 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:43:31,268 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:43:41,271 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:43:41,272 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:43:51,276 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:43:51,278 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:44:01,280 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:44:01,281 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:44:11,284 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:44:11,285 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:44:21,290 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:44:21,293 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:44:31,521 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:44:31,522 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:44:41,526 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:44:41,528 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:44:51,531 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:44:51,532 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:45:01,534 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:45:01,535 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:45:11,537 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:45:11,538 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:45:21,540 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:45:21,541 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:45:31,543 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:45:31,544 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:45:41,545 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:45:41,546 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:45:51,548 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:45:51,549 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:46:01,551 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:46:01,552 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:46:11,554 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:46:11,555 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:46:21,556 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:46:21,557 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:46:31,559 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:46:31,560 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:46:41,562 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:46:41,563 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:46:51,564 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:46:51,565 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:47:01,567 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:47:01,568 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:47:11,569 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:47:11,570 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:47:21,572 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:47:21,573 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:47:31,577 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:47:31,579 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:47:41,581 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:47:41,583 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:47:51,584 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:47:51,585 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:48:01,587 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:48:01,588 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:48:11,589 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:48:11,590 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:48:21,592 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:48:21,593 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:48:31,594 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:48:31,595 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:48:41,597 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:48:41,597 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:48:51,602 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:48:51,604 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:49:01,606 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:49:01,607 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:49:11,609 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:49:11,610 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:49:21,612 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:49:21,613 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:49:31,615 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:49:31,617 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:49:41,618 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:49:41,620 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:49:51,622 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:49:51,623 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:50:01,624 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:50:01,626 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:50:11,627 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:50:11,628 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:50:21,631 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:50:21,634 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:50:31,635 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:50:31,637 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:50:41,638 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:50:41,639 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:50:51,641 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:50:51,644 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:51:01,646 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:51:01,649 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:51:11,651 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:51:11,651 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:51:21,653 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:51:21,654 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:51:31,655 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:51:31,656 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:51:41,660 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:51:41,664 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:51:51,666 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:51:51,667 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:52:01,668 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:52:01,669 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:52:11,670 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:52:11,671 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:52:21,673 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:52:21,674 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:52:31,676 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:52:31,678 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:52:41,679 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:52:41,680 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:52:51,682 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:52:51,683 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:53:01,684 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:53:01,685 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:53:11,687 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:53:11,687 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:53:21,691 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:53:21,692 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:53:31,694 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:53:31,695 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:53:41,698 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:53:41,700 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:53:51,702 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:53:51,703 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:54:01,704 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:54:01,705 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:54:11,706 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:54:11,707 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:54:21,708 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:54:21,709 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:54:31,711 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:54:31,711 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:54:41,714 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:54:41,716 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:54:51,718 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:54:51,718 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:55:01,720 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:55:01,721 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:55:11,722 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:55:11,723 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:55:21,724 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:55:21,725 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:55:31,726 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:55:31,727 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:55:41,728 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:55:41,729 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:55:51,731 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:55:51,732 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:56:01,733 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:56:01,734 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:56:11,737 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:56:11,738 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:56:21,740 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:56:21,741 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:56:31,743 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:56:31,745 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:56:41,746 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:56:41,747 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:56:51,749 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:56:51,750 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:01,752 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:57:01,753 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:11,756 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:57:11,758 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:21,916 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:57:21,917 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:31,919 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:57:31,920 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:41,921 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:57:41,922 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:45,145 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 13:57:49,924 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 13:57:49,988 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 13:57:49,990 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 13:57:49,991 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 13:57:49,992 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 13:57:49,992 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 13:57:49,992 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 13:57:49,992 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 13:57:49,997 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 13:57:50,007 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 13:57:50,010 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:50,013 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 13:57:50,015 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:50,015 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 13:57:50,034 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 13:57:50,057 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 13:57:50,059 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 13:57:50,067 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 13:57:50,067 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 13:57:50,067 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 13:57:50,068 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 13:57:50,195 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 13:57:50,196 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 13:57:50,196 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:50,197 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:57:50,197 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 13:57:50,197 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 13:57:50,236 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 13:57:50,305 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:57:50,306 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:58:00,309 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:58:00,310 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:58:10,312 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:58:10,314 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:58:20,316 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:58:20,318 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:58:30,321 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:58:30,323 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:58:40,329 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:58:40,332 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:58:50,334 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:58:50,335 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:59:00,338 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:59:00,339 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:59:10,341 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:59:10,342 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:59:20,344 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:59:20,345 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:59:30,350 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:59:30,353 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:59:40,356 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:59:40,357 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 13:59:50,361 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 13:59:50,364 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:00:00,366 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:00:00,367 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:00:10,369 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:00:10,370 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:00:20,372 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:00:20,374 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:00:30,375 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:00:30,376 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:00:40,378 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:00:40,379 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:00:50,381 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:00:50,382 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:01:00,383 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:01:00,384 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:01:10,386 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:01:10,387 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:01:20,389 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:01:20,390 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:01:30,392 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:01:30,393 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:01:40,394 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:01:40,402 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:01:50,404 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:01:50,405 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:02:00,407 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:02:00,408 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:02:10,409 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:02:10,410 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:02:20,412 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:02:20,420 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:02:30,422 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:02:30,423 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:02:40,426 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:02:40,428 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:02:50,430 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:02:50,431 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:03:00,433 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:03:00,434 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:03:10,436 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:03:10,436 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:03:20,438 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:03:20,439 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:03:30,440 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:03:30,441 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:03:40,443 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:03:40,444 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:03:50,445 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:03:50,447 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:04:00,448 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:04:00,449 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:04:10,452 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:04:10,455 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:04:20,456 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:04:20,457 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:04:30,459 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:04:30,460 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:04:40,462 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:04:40,463 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:04:50,466 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:04:50,467 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:05:00,468 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:05:00,469 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:05:10,471 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:05:10,472 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:05:20,473 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:05:20,474 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:05:30,475 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:05:30,476 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:05:40,478 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:05:40,479 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:05:50,481 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:05:50,482 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:06:00,483 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:06:00,484 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:06:10,486 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:06:10,488 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:06:20,489 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:06:20,490 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:06:30,491 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:06:30,492 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:06:40,494 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:06:40,495 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:06:50,496 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:06:50,497 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:00,498 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:07:00,499 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:10,501 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:07:10,502 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:20,503 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:07:20,504 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:26,345 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 14:07:31,051 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 14:07:31,115 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 14:07:31,118 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 14:07:31,119 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 14:07:31,119 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 14:07:31,119 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 14:07:31,120 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 14:07:31,120 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 14:07:31,125 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 14:07:31,135 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 14:07:31,138 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:31,141 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 14:07:31,143 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:31,143 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 14:07:31,163 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 14:07:31,185 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 14:07:31,187 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 14:07:31,195 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 14:07:31,195 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 14:07:31,195 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 14:07:31,195 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 14:07:31,313 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 14:07:31,314 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 14:07:31,314 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:31,315 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:31,315 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 14:07:31,315 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 14:07:31,339 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 14:07:31,399 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:07:31,400 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:41,406 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:07:41,409 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:07:51,412 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:07:51,414 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:08:01,419 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:08:01,422 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:08:11,425 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:08:11,427 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:08:21,429 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:08:21,430 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:08:31,432 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:08:31,433 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:08:41,437 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:08:41,439 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:08:51,441 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:08:51,442 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:09:01,445 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:09:01,449 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:09:11,452 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:09:11,455 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:09:21,458 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:09:21,462 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:09:31,467 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:09:31,469 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:09:41,474 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:09:41,477 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:09:51,479 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:09:51,480 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:10:01,487 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:10:01,491 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:10:11,494 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:10:11,495 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:10:21,496 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:10:21,497 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:10:31,504 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:10:31,505 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:10:41,506 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:10:41,507 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:10:51,509 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:10:51,510 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:11:01,511 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:11:01,513 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:11:11,516 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:11:11,518 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:11:21,520 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:11:21,521 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:11:31,525 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:11:31,528 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:11:41,529 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:11:41,530 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:11:51,534 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:11:51,537 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:12:01,541 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:12:01,543 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:12:11,547 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:12:11,550 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:12:21,552 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:12:21,553 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:12:31,554 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:12:31,555 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:12:41,557 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:12:41,558 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:12:51,559 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:12:51,560 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:13:01,564 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:13:01,566 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:13:11,568 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:13:11,571 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:13:21,573 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:13:21,574 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:13:31,575 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:13:31,576 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:13:41,577 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:13:41,578 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:13:51,580 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:13:51,581 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:14:01,582 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:14:01,583 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:14:11,585 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:14:11,586 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:14:21,587 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:14:21,589 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:14:31,590 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:14:31,591 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:14:41,594 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:14:41,596 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:14:51,598 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:14:51,599 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:15:01,601 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:15:01,603 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:15:11,605 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:15:11,607 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:15:21,608 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:15:21,609 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:15:31,611 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:15:31,611 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:15:41,613 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:15:41,614 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:15:51,615 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:15:51,616 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:16:01,617 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:16:01,618 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:16:11,620 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:16:11,620 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:16:21,622 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:16:21,623 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:16:31,624 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:16:31,625 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:16:41,626 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:16:41,627 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:16:51,629 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:16:51,629 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:17:01,631 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:17:01,632 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:17:11,633 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:17:11,634 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:17:21,635 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:17:21,636 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:17:31,638 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:17:31,639 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:17:41,641 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:17:41,645 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:17:51,646 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:17:51,647 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:18:01,652 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:18:01,654 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:18:11,656 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:18:11,656 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:18:21,659 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:18:21,661 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:18:31,664 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:18:31,666 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:18:41,668 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:18:41,669 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:18:51,673 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:18:51,679 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:19:01,681 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:19:01,682 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:19:11,684 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:19:11,685 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:19:21,686 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:19:21,688 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:19:31,691 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:19:31,694 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:19:41,696 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:19:41,696 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:19:51,699 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:19:51,702 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:20:01,703 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:20:01,704 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:20:11,706 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:20:11,706 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:20:21,708 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:20:21,709 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:20:31,712 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:20:31,715 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:20:41,716 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:20:41,717 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:20:51,721 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:20:51,723 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:21:01,724 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:21:01,725 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:21:11,727 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:21:11,727 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:21:21,731 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:21:21,734 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:21:31,736 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:21:31,737 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:21:41,739 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:21:41,740 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:21:51,741 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:21:51,742 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:22:01,743 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:22:01,744 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:22:11,746 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:22:11,746 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:22:21,748 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:22:21,748 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:22:31,750 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:22:31,751 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:22:41,752 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:22:41,753 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:22:51,755 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:22:51,755 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:23:01,757 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:23:01,757 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:23:11,759 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:23:11,759 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:23:21,761 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:23:21,763 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:23:31,765 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:23:31,765 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:23:41,767 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:23:41,768 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:23:51,769 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:23:51,772 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:24:01,773 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:24:01,774 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:24:11,775 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:24:11,776 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:24:21,778 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:24:21,778 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:24:31,780 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:24:31,781 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:24:41,782 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:24:41,783 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:24:51,788 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:24:51,790 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:25:01,791 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:25:01,792 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:25:11,793 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:25:11,795 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:25:21,797 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:25:21,799 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:25:31,801 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:25:31,802 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:25:41,804 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:25:41,804 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:25:51,806 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:25:51,807 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:26:01,808 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:26:01,809 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:26:11,810 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:26:11,811 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:26:21,812 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:26:21,813 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:26:31,814 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:26:31,815 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:26:41,817 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:26:41,818 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:26:51,820 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:26:51,822 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:27:01,825 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:27:01,828 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:27:11,830 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:27:11,831 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:27:21,832 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:27:21,833 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:27:31,836 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:27:31,838 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:27:41,840 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:27:41,841 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:27:51,842 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:27:51,844 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:28:01,845 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:28:01,846 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:28:11,850 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:28:11,852 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:28:21,854 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:28:21,855 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:28:31,857 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:28:31,857 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:28:41,870 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:28:41,872 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:28:51,874 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:28:51,875 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:29:01,876 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:29:01,877 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:29:11,879 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:29:11,881 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:29:21,882 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:29:21,883 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:29:31,884 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:29:31,885 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:29:41,886 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:29:41,887 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:29:51,888 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:29:51,889 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:30:01,891 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:30:01,892 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:30:11,893 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:30:11,894 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:30:21,895 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:30:21,896 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:30:31,897 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:30:31,897 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:30:41,899 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:30:41,899 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:30:51,900 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:30:51,901 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:31:01,902 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:31:01,903 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:31:11,904 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:31:11,905 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:31:21,906 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:31:21,907 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:31:31,908 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:31:31,909 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:31:41,910 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:31:41,910 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:31:51,912 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:31:51,912 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:32:01,913 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:32:01,914 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:32:11,916 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:32:11,916 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:32:21,919 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:32:21,921 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:32:31,922 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:32:31,923 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:32:41,924 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:32:41,925 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:32:51,926 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:32:51,927 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:33:01,928 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:33:01,930 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:33:11,931 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:33:11,932 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:33:21,933 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:33:21,934 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:33:31,935 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:33:31,936 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:33:41,937 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:33:41,938 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:33:51,939 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:33:51,940 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:34:01,941 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:34:01,942 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:34:11,945 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:34:11,946 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:34:21,950 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:34:21,952 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:34:31,953 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:34:31,954 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:34:41,955 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:34:41,956 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:34:51,957 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:34:51,958 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:35:01,959 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:35:01,960 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:35:11,961 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:35:11,961 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:35:21,963 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:35:21,964 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:35:31,965 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:35:31,966 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:35:41,969 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:35:41,983 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:35:51,985 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:35:51,986 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:36:01,987 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:36:01,988 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:36:11,989 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:36:11,990 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:36:21,991 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:36:21,992 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:36:31,993 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:36:31,994 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:36:41,997 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:36:41,998 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:36:52,001 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:36:52,002 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:37:02,003 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:37:02,004 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:37:12,005 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:37:12,006 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:37:22,007 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:37:22,008 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:37:32,009 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:37:32,009 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:37:42,011 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:37:42,013 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:37:52,014 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:37:52,015 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:38:02,016 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:38:02,018 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:38:12,019 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:38:12,019 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:38:22,020 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:38:22,021 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:38:32,023 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:38:32,025 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:38:42,026 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:38:42,027 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:38:52,028 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:38:52,029 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:39:02,030 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:39:02,031 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:39:12,032 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:39:12,032 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:39:22,037 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:39:22,037 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:39:32,039 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:39:32,039 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:39:42,042 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:39:42,044 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:39:52,045 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:39:52,046 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:40:02,047 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:40:02,048 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:40:12,049 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:40:12,049 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:40:22,050 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:40:22,051 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:40:32,052 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:40:32,053 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:40:42,054 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:40:42,055 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:40:52,057 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:40:52,058 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:41:02,059 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:41:02,060 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:41:12,061 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:41:12,062 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:41:22,063 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:41:22,063 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:41:32,065 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:41:32,067 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:41:42,068 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:41:42,070 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:41:52,071 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:41:52,072 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:42:02,073 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:42:02,073 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:42:12,074 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:42:12,075 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:42:22,076 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:42:22,077 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:42:32,078 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:42:32,079 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:42:42,080 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:42:42,081 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:42:52,082 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:42:52,082 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:43:02,084 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:43:02,086 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:43:12,087 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:43:12,087 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:43:22,088 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:43:22,089 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:43:32,090 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:43:32,091 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:43:42,092 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:43:42,093 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:43:52,094 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:43:52,096 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:44:02,099 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:44:02,100 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:44:12,102 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:44:12,103 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:44:22,104 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:44:22,104 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:44:32,105 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:44:32,106 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:44:42,107 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:44:42,108 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:44:52,109 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:44:52,109 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:45:02,110 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:45:02,111 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:45:12,112 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:45:12,113 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:45:22,114 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:45:22,114 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:45:32,115 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:45:32,116 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:45:42,117 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:45:42,118 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:45:52,119 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:45:52,119 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:46:02,121 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:46:02,121 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:46:12,122 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:46:12,123 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:46:22,124 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:46:22,125 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:46:32,126 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:46:32,126 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:46:42,127 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:46:42,128 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:46:52,129 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:46:52,130 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:47:02,131 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:47:02,131 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:47:12,132 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:47:12,133 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:47:22,134 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:47:22,135 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:47:32,136 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:47:32,138 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:47:42,139 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:47:42,139 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:47:52,141 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:47:52,141 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:48:02,142 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:48:02,143 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:48:12,145 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:48:12,147 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:48:22,150 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:48:22,151 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:48:32,154 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:48:32,156 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:48:42,157 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:48:42,158 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:48:52,160 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:48:52,162 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:49:02,164 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:49:02,164 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:49:12,166 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:49:12,171 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:49:22,173 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:49:22,175 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:49:32,176 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:49:32,177 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:49:42,178 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:49:42,179 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:49:52,180 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:49:52,181 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:50:02,182 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:50:02,183 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:50:12,184 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:50:12,185 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:50:22,186 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:50:22,186 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:50:32,188 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:50:32,189 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:50:42,191 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:50:42,193 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:50:52,194 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:50:52,194 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:51:02,195 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:51:02,196 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:51:12,197 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:51:12,198 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:51:22,199 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:51:22,200 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:51:32,201 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:51:32,201 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:51:42,202 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:51:42,203 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:51:52,204 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:51:52,204 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:52:02,205 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:52:02,206 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:52:12,207 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:52:12,208 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:52:22,209 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:52:22,210 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:52:32,211 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:52:32,212 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:52:42,214 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:52:42,214 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:52:52,215 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:52:52,216 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:53:02,217 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:53:02,218 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:53:12,219 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:53:12,219 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:53:22,220 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:53:22,221 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:53:32,222 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:53:32,222 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:53:42,226 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:53:42,227 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:53:52,228 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:53:52,229 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:54:02,230 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:54:02,230 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:54:12,231 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:54:12,232 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:54:22,233 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:54:22,233 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:54:32,234 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:54:32,235 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:54:42,236 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:54:42,236 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:54:52,238 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:54:52,238 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:55:02,239 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:55:02,240 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:55:12,241 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:55:12,242 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:55:22,243 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:55:22,243 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:55:32,244 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:55:32,245 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:55:42,246 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:55:42,246 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:55:52,249 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:55:52,250 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:56:02,251 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:56:02,252 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:56:12,253 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:56:12,254 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:56:22,255 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:56:22,256 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:56:32,257 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:56:32,257 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:56:42,259 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:56:42,260 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:56:52,261 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:56:52,262 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:57:02,263 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:57:02,264 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:57:12,264 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:57:12,265 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:57:22,267 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:57:22,269 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:57:32,271 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:57:32,273 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:57:42,274 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:57:42,274 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:57:52,275 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:57:52,276 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:58:02,277 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:58:02,277 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:58:12,279 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:58:12,279 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:58:22,280 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:58:22,281 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:58:32,282 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:58:32,283 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:58:42,285 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:58:42,285 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:58:52,287 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:58:52,288 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:59:02,289 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:59:02,289 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:59:12,291 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:59:12,291 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:59:22,293 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:59:22,294 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:59:32,296 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:59:32,298 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:59:42,299 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:59:42,299 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 14:59:52,300 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 14:59:52,301 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:00:02,302 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:00:02,303 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:00:12,305 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:00:12,306 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:00:22,307 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:00:22,308 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:00:32,309 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:00:32,317 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:00:42,318 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:00:42,319 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:00:52,320 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:00:52,321 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:01:02,322 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:01:02,323 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:01:12,323 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:01:12,324 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:01:22,325 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:01:22,326 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:01:32,326 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:01:32,327 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:01:42,328 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:01:42,329 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:01:52,329 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:01:52,330 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:02:02,331 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:02:02,332 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:02:12,332 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:02:12,333 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:02:22,334 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:02:22,335 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:02:32,336 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:02:32,336 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:02:42,337 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:02:42,338 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:02:52,339 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:02:52,339 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:03:02,340 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:03:02,341 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:03:12,342 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:03:12,342 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:03:22,343 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:03:22,344 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:03:32,346 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:03:32,347 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:03:42,349 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:03:42,349 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:03:52,350 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:03:52,351 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:04:02,352 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:04:02,353 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:04:12,354 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:04:12,354 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:04:22,355 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:04:22,356 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:04:32,358 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:04:32,359 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:04:42,360 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:04:42,361 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:04:52,363 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:04:52,364 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:05:02,366 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:05:02,366 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:05:12,367 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:05:12,368 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:05:22,528 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:05:22,529 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:05:32,529 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:05:32,530 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:05:42,531 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:05:42,532 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:05:52,533 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:05:52,533 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:06:02,534 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:06:02,535 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:06:12,536 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:06:12,536 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:06:22,537 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:06:22,538 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:06:32,539 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:06:32,539 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:06:42,541 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:06:42,542 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:06:52,544 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:06:52,544 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:07:02,545 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:07:02,546 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:07:12,547 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:07:12,547 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:07:22,549 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:07:22,550 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:07:32,551 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:07:32,552 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:07:42,553 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:07:42,554 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:07:52,556 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:07:52,557 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:08:02,558 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:08:02,559 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:08:12,560 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:08:12,561 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:08:22,563 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:08:22,565 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:08:32,567 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:08:32,569 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:08:42,570 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:08:42,570 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:08:52,571 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:08:52,574 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:09:02,575 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:09:02,576 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:09:12,577 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:09:12,577 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:09:22,579 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:09:22,581 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:09:32,582 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:09:32,582 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:09:42,583 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:09:42,584 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:09:52,585 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:09:52,585 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:10:02,586 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:10:02,587 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:10:12,589 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:10:12,590 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:10:22,592 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:10:22,594 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:10:32,595 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:10:32,596 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:10:42,597 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:10:42,597 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:10:52,598 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:10:52,599 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:11:02,600 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:11:02,601 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:11:12,603 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:11:12,604 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:11:22,606 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:11:22,607 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:11:32,609 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:11:32,610 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:11:42,611 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:11:42,611 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:11:52,613 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:11:52,615 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:12:02,616 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:12:02,617 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:12:12,617 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:12:12,618 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:12:22,620 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:12:22,621 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:12:32,622 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:12:32,622 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:12:42,624 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:12:42,626 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:12:52,627 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:12:52,627 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:13:02,629 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:13:02,629 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:13:12,631 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:13:12,633 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:13:22,635 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:13:22,636 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:13:32,638 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:13:32,639 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:13:42,641 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:13:42,643 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:13:52,645 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:13:52,646 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:14:02,647 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:14:02,647 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:14:12,649 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:14:12,651 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:14:22,652 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:14:22,653 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:14:32,654 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:14:32,654 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:14:42,655 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:14:42,656 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:14:52,657 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:14:52,658 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:15:02,659 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:15:02,659 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:15:12,660 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:15:12,661 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:15:22,662 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:15:22,662 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:15:32,663 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:15:32,664 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:15:42,664 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:15:42,665 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:15:52,666 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:15:52,666 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:16:02,667 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:16:02,668 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:16:12,669 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:16:12,669 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:16:22,670 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:16:22,671 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:16:32,671 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:16:32,672 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:16:42,673 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:16:42,673 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:16:52,674 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:16:52,675 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:17:02,678 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:17:02,678 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:17:12,679 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:17:12,680 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:17:22,681 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:17:22,681 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:17:32,682 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:17:32,683 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:17:42,683 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:17:42,684 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:17:52,685 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:17:52,686 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:18:02,686 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:18:02,687 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:18:12,688 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:18:12,689 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:18:22,690 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:18:22,690 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:18:32,692 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:18:32,693 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:18:42,694 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:18:42,695 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:18:52,696 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:18:52,697 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:19:02,699 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:19:02,700 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:19:12,701 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:19:12,702 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:19:22,703 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:19:22,704 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:19:32,705 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:19:32,706 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:19:42,707 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:19:42,707 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:19:52,708 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:19:52,709 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:20:02,710 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:20:02,712 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:20:12,713 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:20:12,713 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:20:22,714 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:20:22,715 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:20:32,717 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:20:32,718 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:20:42,719 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:20:42,720 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:20:52,731 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:20:52,732 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:21:02,735 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:21:02,738 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:21:12,740 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:21:12,741 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:21:22,742 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:21:22,743 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:21:32,744 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:21:32,745 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:21:42,746 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:21:42,747 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:21:52,748 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:21:52,749 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:22:02,750 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:22:02,752 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:22:12,753 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:22:12,753 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:22:22,754 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:22:22,755 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:22:32,756 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:22:32,756 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:22:42,757 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:22:42,758 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:22:52,758 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:22:52,759 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:23:02,760 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:23:02,760 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:23:12,761 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:23:12,762 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:23:22,763 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:23:22,764 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:23:32,766 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:23:32,767 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:23:42,768 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:23:42,769 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:23:52,770 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:23:52,770 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:24:02,771 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:24:02,772 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:24:12,773 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:24:12,774 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:24:22,775 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:24:22,775 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:24:32,777 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:24:32,778 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:24:42,779 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:24:42,780 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:24:52,781 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:24:52,781 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:25:02,782 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:25:02,783 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:25:12,786 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:25:12,786 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:25:22,787 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:25:22,788 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:25:32,789 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:25:32,801 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:25:42,802 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:25:42,802 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:25:52,803 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:25:52,804 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:26:02,805 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:26:02,805 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:26:12,806 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:26:12,807 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:26:22,809 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:26:22,810 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:26:32,811 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:26:32,812 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:26:42,814 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:26:42,815 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:26:52,816 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:26:52,817 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:27:02,818 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:27:02,818 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:27:12,819 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:27:12,820 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:27:22,821 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:27:22,821 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:27:32,822 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:27:32,823 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:27:42,824 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:27:42,825 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:27:52,826 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:27:52,826 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:28:02,827 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:28:02,828 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:28:12,829 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:28:12,829 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:28:22,830 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:28:22,831 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:28:32,831 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:28:32,832 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:28:42,833 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:28:42,833 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:28:52,835 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:28:52,837 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:29:02,839 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:29:02,839 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:29:12,840 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:29:12,841 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:29:22,842 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:29:22,843 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:29:32,844 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:29:32,844 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:29:42,845 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:29:42,846 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:29:52,847 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:29:52,847 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:30:02,848 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:30:02,849 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:30:12,850 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:30:12,851 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:30:22,852 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:30:22,852 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:30:32,853 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:30:32,854 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:30:42,854 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:30:42,855 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:30:52,856 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:30:52,856 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:31:02,857 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:31:02,858 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:31:12,858 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:31:12,859 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:31:22,860 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:31:22,860 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:31:32,861 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:31:32,862 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:31:42,863 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:31:42,863 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:31:52,864 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:31:52,865 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:32:02,866 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:32:02,866 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:32:12,867 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:32:12,868 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:32:22,869 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:32:22,869 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:32:32,870 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:32:32,870 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:32:42,871 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:32:42,872 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:32:52,873 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:32:52,874 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:33:02,876 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:33:02,877 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:33:12,879 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:33:12,880 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:33:22,881 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:33:22,882 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:33:32,883 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:33:32,885 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:33:42,887 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:33:42,889 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:33:52,890 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:33:52,890 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:34:02,892 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:34:02,893 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:34:12,895 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:34:12,896 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:34:22,897 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:34:22,897 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:34:32,899 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:34:32,900 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:34:42,901 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:34:42,903 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:34:52,904 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:34:52,905 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:35:02,905 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:35:02,906 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:35:12,907 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:35:12,908 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:35:22,910 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:35:22,911 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:35:32,914 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:35:32,915 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:35:42,916 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:35:42,917 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:35:52,918 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:35:52,918 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:36:02,919 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:36:02,920 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:36:12,921 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:36:12,922 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:36:22,923 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:36:22,924 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:36:32,926 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:36:32,928 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:36:42,929 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:36:42,930 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:36:52,930 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:36:52,931 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:37:02,932 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:37:02,932 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:37:12,934 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:37:12,934 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:37:22,935 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:37:22,936 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:37:32,937 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:37:32,937 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:37:42,939 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:37:42,939 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:37:52,940 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:37:52,941 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:38:02,941 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:38:02,942 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:38:12,943 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:38:12,943 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:38:22,944 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:38:22,945 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:38:32,947 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:38:32,958 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:38:42,960 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:38:42,962 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:38:52,963 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:38:52,964 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:39:02,965 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:39:02,965 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:39:12,966 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:39:12,967 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:39:22,968 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:39:22,968 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:39:32,969 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:39:32,970 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:39:42,972 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:39:42,974 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:39:52,975 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:39:52,977 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:40:02,977 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:40:02,978 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:40:12,979 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:40:12,980 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:40:22,982 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:40:22,983 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:40:32,984 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:40:32,985 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:40:42,986 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:40:42,986 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:40:52,987 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:40:52,988 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:41:02,990 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:41:02,991 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:41:12,992 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:41:12,993 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:41:22,994 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:41:22,995 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:41:32,996 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:41:32,996 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:41:42,997 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:41:42,998 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:41:52,999 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:41:53,000 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:42:03,001 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:42:03,002 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:42:13,002 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:42:13,003 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:42:23,004 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:42:23,004 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:42:33,005 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:42:33,006 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:42:43,007 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:42:43,008 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:42:53,010 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:42:53,011 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:43:03,012 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:43:03,013 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:43:13,015 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:43:13,017 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:43:23,019 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:43:23,020 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:43:33,021 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:43:33,021 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:43:43,023 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:43:43,023 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:43:53,025 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:43:53,026 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:44:03,027 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:44:03,028 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:44:13,029 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:44:13,029 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:44:23,031 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:44:23,031 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:44:33,032 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:44:33,033 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:44:43,034 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:44:43,034 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:44:53,036 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:44:53,037 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:45:03,038 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:45:03,039 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:45:13,040 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:45:13,040 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:45:23,041 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:45:23,042 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:45:33,042 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:45:33,043 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:45:43,044 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:45:43,044 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:45:53,045 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:45:53,046 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:46:03,047 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:46:03,047 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:46:13,048 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:46:13,048 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:46:23,049 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:46:23,050 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:46:33,051 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:46:33,051 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:46:43,052 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:46:43,053 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:46:53,054 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:46:53,055 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:47:03,056 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:47:03,057 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:47:13,058 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:47:13,058 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:47:23,059 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:47:23,060 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:47:33,060 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:47:33,061 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:47:43,063 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:47:43,064 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:47:53,065 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:47:53,065 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:48:03,066 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:48:03,067 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:48:13,068 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:48:13,068 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:48:23,069 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:48:23,069 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:48:33,070 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:48:33,071 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:48:43,072 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:48:43,072 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:48:53,073 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:48:53,073 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:49:03,074 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:49:03,075 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:49:13,076 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:49:13,077 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:49:23,078 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:49:23,078 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:49:33,080 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:49:33,081 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:49:43,083 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:49:43,083 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:49:53,084 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:49:53,085 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:50:03,085 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:50:03,086 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:50:13,087 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:50:13,087 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:50:23,088 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:50:23,089 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:50:33,089 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:50:33,090 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:50:43,092 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:50:43,093 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:50:53,094 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:50:53,106 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:51:03,107 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:51:03,108 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:51:13,109 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:51:13,109 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:51:23,110 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:51:23,111 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:51:33,111 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:51:33,112 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:51:43,113 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:51:43,113 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:51:53,114 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:51:53,115 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:52:03,115 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:52:03,116 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:52:13,117 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:52:13,117 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:52:23,119 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:52:23,120 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:52:33,121 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:52:33,122 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:52:43,123 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:52:43,124 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:52:53,125 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:52:53,125 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:53:03,127 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:53:03,128 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:53:13,129 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:53:13,130 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:53:23,131 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:53:23,132 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:53:33,134 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:53:33,135 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:53:43,136 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:53:43,137 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:53:53,138 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:53:53,138 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:54:03,139 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:54:03,140 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:54:13,141 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:54:13,141 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:54:23,142 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:54:23,142 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:54:33,143 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:54:33,144 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:54:43,145 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:54:43,146 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:54:53,147 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:54:53,148 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:55:03,149 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:55:03,150 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:55:13,151 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:55:13,151 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:55:23,152 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:55:23,153 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:55:33,153 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:55:33,154 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:55:43,155 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:55:43,155 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:55:53,156 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:55:53,157 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:56:03,157 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:56:03,158 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:56:13,159 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:56:13,160 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:56:23,160 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:56:23,161 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:56:33,162 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:56:33,162 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:56:43,163 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:56:43,164 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:56:53,165 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:56:53,165 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:57:03,166 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:57:03,167 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:57:13,168 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:57:13,168 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:57:23,169 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:57:23,170 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:57:33,171 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:57:33,172 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:57:43,174 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:57:43,175 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:57:53,176 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:57:53,177 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:03,178 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:58:03,178 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:13,048 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 15:58:17,740 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 15:58:17,805 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 15:58:17,808 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 15:58:17,808 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 15:58:17,809 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 15:58:17,809 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 15:58:17,809 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 15:58:17,810 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 15:58:17,815 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 15:58:17,826 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 15:58:17,829 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:17,832 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 15:58:17,833 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:17,833 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 15:58:17,853 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 15:58:17,876 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 15:58:17,878 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 15:58:17,886 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 15:58:17,886 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 15:58:17,886 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 15:58:17,886 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 15:58:18,021 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 15:58:18,022 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 15:58:18,022 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:18,022 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:18,022 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 15:58:18,022 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 15:58:18,047 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 15:58:18,107 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:58:18,109 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:28,111 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:58:28,112 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:38,115 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:58:38,116 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:48,118 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:58:48,119 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:58:58,123 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:58:58,127 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:59:08,129 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:59:08,130 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:59:18,132 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:59:18,133 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:59:28,135 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:59:28,136 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:59:38,138 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:59:38,139 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:59:48,141 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:59:48,141 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 15:59:58,143 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 15:59:58,144 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:00:08,146 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:00:08,147 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:00:18,149 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:00:18,150 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:00:28,152 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:00:28,153 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:00:38,154 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:00:38,155 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:00:48,157 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:00:48,158 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:00:58,160 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:00:58,161 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 616 needs additional 621 blocks to reach the threshold 0.9990 of total blocks 1239. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 16:01:08,163 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 16:01:08,222 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-14 16:01:08,223 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-14 16:01:08,224 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-14 16:01:08,226 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-14 16:01:08,422 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-14 16:01:08,430 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-14 16:01:08,430 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-14 16:01:08,430 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 16:01:08,430 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-14 16:01:08,431 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-14 16:01:08,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-14 16:01:08,431 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-14 16:01:08,438 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-14 16:01:08,445 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-14 16:01:08,447 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-14 16:01:08,447 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-14 16:01:08,447 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-14 16:01:08,448 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-14 16:01:08,448 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-14 16:01:08,448 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-14 16:01:08,448 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-14 16:01:08,454 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-14 16:01:08,543 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-14 16:01:08,544 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:40811 to host slave2
2016-09-14 16:01:08,578 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-14 16:01:08,578 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:34635 to host slave5
2016-09-14 16:01:08,657 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-14 16:01:08,658 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:34641 to host slave1
2016-09-14 16:01:08,677 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-14 16:01:08,677 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:43656 to host slave4
2016-09-14 16:01:08,695 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-14 16:01:08,695 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:34946 to host slave3
2016-09-14 16:02:10,441 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-14 16:02:10,497 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609141558_0001 added successfully for user 'hduser' to queue 'default'
2016-09-14 16:02:10,498 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609141558_0001
2016-09-14 16:02:10,498 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609141558_0001
2016-09-14 16:02:10,543 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609141558_0001_hduser
2016-09-14 16:02:10,709 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609141558_0001_conf.xml
2016-09-14 16:02:10,763 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609141558_0001/jobToken
2016-09-14 16:02:10,774 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609141558_0001 = 0. Number of splits = 5
2016-09-14 16:02:10,775 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0001 initialized successfully with 5 map tasks and 0 reduce tasks.
2016-09-14 16:02:11,647 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609141558_0001_m_000006_0' to tip task_201609141558_0001_m_000006, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:02:14,685 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000006_0' has completed task_201609141558_0001_m_000006 successfully.
2016-09-14 16:02:14,691 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0001_m_000000
2016-09-14 16:02:14,691 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000000_0' to tip task_201609141558_0001_m_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:02:14,725 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0001_m_000001
2016-09-14 16:02:14,725 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000001_0' to tip task_201609141558_0001_m_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:02:14,756 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0001_m_000002
2016-09-14 16:02:14,756 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000002_0' to tip task_201609141558_0001_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:02:14,760 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0001_m_000003
2016-09-14 16:02:14,760 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000003_0' to tip task_201609141558_0001_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:02:17,663 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0001_m_000004
2016-09-14 16:02:17,663 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000004_0' to tip task_201609141558_0001_m_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:03:17,891 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000003_0' has completed task_201609141558_0001_m_000003 successfully.
2016-09-14 16:03:17,894 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0001_m_000004 for speculative execution
2016-09-14 16:03:17,894 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000004_1' to tip task_201609141558_0001_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:03:31,010 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000002_0' has completed task_201609141558_0001_m_000002 successfully.
2016-09-14 16:03:31,013 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0001_m_000001 for speculative execution
2016-09-14 16:03:31,013 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0001_m_000001_1' to tip task_201609141558_0001_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:04:04,766 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000000_0' has completed task_201609141558_0001_m_000000 successfully.
2016-09-14 16:04:25,122 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000001_0' has completed task_201609141558_0001_m_000001 successfully.
2016-09-14 16:04:30,093 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000004_1' has completed task_201609141558_0001_m_000004 successfully.
2016-09-14 16:04:30,095 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609141558_0001_m_000005_0' to tip task_201609141558_0001_m_000005, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:04:30,195 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000001_1'
2016-09-14 16:04:30,196 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0001_m_000001_1' to tip task_201609141558_0001_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:04:33,202 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000001_1'
2016-09-14 16:04:35,719 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000004_0'
2016-09-14 16:04:35,719 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0001_m_000004_0' to tip task_201609141558_0001_m_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:04:39,114 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0001_m_000005_0' has completed task_201609141558_0001_m_000005 successfully.
2016-09-14 16:04:39,121 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0001 has completed successfully.
2016-09-14 16:04:39,121 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609141558_0001,submitTime=1473849130392,launchTime=1473849130774,finishTime=1473849279121,numMaps=5,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=450,reduceSlotsSeconds=0,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 16:04:39,249 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609141558_0001_hduser
2016-09-14 16:04:39,269 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000003_0'
2016-09-14 16:04:39,269 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000004_1'
2016-09-14 16:04:39,269 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000005_0'
2016-09-14 16:04:39,269 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000002_0'
2016-09-14 16:04:39,279 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609141558_0001_conf.xml
2016-09-14 16:04:39,283 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609141558_0001_conf.xml
2016-09-14 16:04:39,283 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000000_0'
2016-09-14 16:04:39,283 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000001_0'
2016-09-14 16:04:39,283 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000004_0'
2016-09-14 16:04:39,283 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0001_m_000006_0'
2016-09-14 16:04:39,283 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609141558_0001' of user 'hduser'
2016-09-14 16:06:34,162 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609141558_0002 added successfully for user 'hduser' to queue 'default'
2016-09-14 16:06:34,163 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609141558_0002
2016-09-14 16:06:34,163 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609141558_0002
2016-09-14 16:06:34,166 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609141558_0002_hduser
2016-09-14 16:06:34,169 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609141558_0002_conf.xml
2016-09-14 16:06:34,196 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609141558_0002/jobToken
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609141558_0002 = 10000000000. Number of splits = 40
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000000 has split on node:/default-rack/slave2
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000001 has split on node:/default-rack/slave1
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000002 has split on node:/default-rack/slave5
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000003 has split on node:/default-rack/slave5
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000004 has split on node:/default-rack/slave3
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000005 has split on node:/default-rack/slave5
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000006 has split on node:/default-rack/slave5
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000007 has split on node:/default-rack/slave1
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000008 has split on node:/default-rack/slave1
2016-09-14 16:06:34,201 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000009 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000010 has split on node:/default-rack/slave2
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000011 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000012 has split on node:/default-rack/slave1
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000013 has split on node:/default-rack/slave1
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000014 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000015 has split on node:/default-rack/slave2
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000016 has split on node:/default-rack/slave2
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000017 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000018 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000019 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000020 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000021 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000022 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000022 has split on node:/default-rack/slave5
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000022 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000023 has split on node:/default-rack/slave2
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000023 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000023 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000024 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000024 has split on node:/default-rack/slave5
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000024 has split on node:/default-rack/slave3
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000025 has split on node:/default-rack/slave4
2016-09-14 16:06:34,202 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000025 has split on node:/default-rack/slave2
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000025 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000026 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000026 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000026 has split on node:/default-rack/slave2
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000027 has split on node:/default-rack/slave1
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000027 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000027 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000028 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000028 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000028 has split on node:/default-rack/slave1
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000029 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000029 has split on node:/default-rack/slave2
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000029 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000030 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000030 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000030 has split on node:/default-rack/slave2
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000031 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000031 has split on node:/default-rack/slave5
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000031 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000032 has split on node:/default-rack/slave5
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000032 has split on node:/default-rack/slave1
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000032 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000033 has split on node:/default-rack/slave4
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000033 has split on node:/default-rack/slave3
2016-09-14 16:06:34,203 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000033 has split on node:/default-rack/slave2
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000034 has split on node:/default-rack/slave1
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000034 has split on node:/default-rack/slave4
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000034 has split on node:/default-rack/slave2
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000035 has split on node:/default-rack/slave5
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000036 has split on node:/default-rack/slave4
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000037 has split on node:/default-rack/slave2
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000038 has split on node:/default-rack/slave4
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000038 has split on node:/default-rack/slave3
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000038 has split on node:/default-rack/slave1
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000039 has split on node:/default-rack/slave4
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000039 has split on node:/default-rack/slave3
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0002_m_000039 has split on node:/default-rack/slave1
2016-09-14 16:06:34,204 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0002 initialized successfully with 40 map tasks and 5 reduce tasks.
2016-09-14 16:06:34,215 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609141558_0002_m_000041_0' to tip task_201609141558_0002_m_000041, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:06:40,222 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000041_0' has completed task_201609141558_0002_m_000041 successfully.
2016-09-14 16:06:40,224 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000001_0' to tip task_201609141558_0002_m_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:06:40,224 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000001
2016-09-14 16:06:40,224 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000007_0' to tip task_201609141558_0002_m_000007, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000007
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000008_0' to tip task_201609141558_0002_m_000008, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000008
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000012_0' to tip task_201609141558_0002_m_000012, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000012
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000013_0' to tip task_201609141558_0002_m_000013, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:06:40,225 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000013
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000000_0' to tip task_201609141558_0002_m_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000000
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000010_0' to tip task_201609141558_0002_m_000010, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000010
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000015_0' to tip task_201609141558_0002_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000015
2016-09-14 16:06:40,874 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000016_0' to tip task_201609141558_0002_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:06:40,875 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000016
2016-09-14 16:06:40,875 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000023_0' to tip task_201609141558_0002_m_000023, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:06:40,875 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000023
2016-09-14 16:06:41,837 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000002_0' to tip task_201609141558_0002_m_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:06:41,837 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000002
2016-09-14 16:06:41,837 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000003_0' to tip task_201609141558_0002_m_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:06:41,837 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000003
2016-09-14 16:06:41,837 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000005_0' to tip task_201609141558_0002_m_000005, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:06:41,837 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000005
2016-09-14 16:06:41,838 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000006_0' to tip task_201609141558_0002_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:06:41,838 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000006
2016-09-14 16:06:41,838 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000022_0' to tip task_201609141558_0002_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:06:41,838 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000022
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000004_0' to tip task_201609141558_0002_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000004
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000018_0' to tip task_201609141558_0002_m_000018, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000018
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000019_0' to tip task_201609141558_0002_m_000019, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000019
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000020_0' to tip task_201609141558_0002_m_000020, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000020
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000021_0' to tip task_201609141558_0002_m_000021, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:06:42,349 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000021
2016-09-14 16:06:42,722 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000009_0' to tip task_201609141558_0002_m_000009, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:06:42,722 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000009
2016-09-14 16:06:42,723 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000011_0' to tip task_201609141558_0002_m_000011, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:06:42,723 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000011
2016-09-14 16:06:42,723 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000014_0' to tip task_201609141558_0002_m_000014, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:06:42,723 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000014
2016-09-14 16:06:42,723 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000017_0' to tip task_201609141558_0002_m_000017, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:06:42,724 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000017
2016-09-14 16:06:42,724 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000024_0' to tip task_201609141558_0002_m_000024, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:06:42,724 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000024
2016-09-14 16:07:12,205 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000022_0' has completed task_201609141558_0002_m_000022 successfully.
2016-09-14 16:07:12,209 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000031_0' to tip task_201609141558_0002_m_000031, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:07:12,209 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000031
2016-09-14 16:07:14,820 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000004_0' has completed task_201609141558_0002_m_000004 successfully.
2016-09-14 16:07:14,821 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000019_0' has completed task_201609141558_0002_m_000019 successfully.
2016-09-14 16:07:14,822 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000020_0' has completed task_201609141558_0002_m_000020 successfully.
2016-09-14 16:07:14,823 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000025_0' to tip task_201609141558_0002_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:14,823 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000025
2016-09-14 16:07:14,823 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000026_0' to tip task_201609141558_0002_m_000026, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:14,823 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000026
2016-09-14 16:07:14,823 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000027_0' to tip task_201609141558_0002_m_000027, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:14,823 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000027
2016-09-14 16:07:14,826 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000000_0' to tip task_201609141558_0002_r_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:15,212 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000001_0' to tip task_201609141558_0002_r_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:07:16,083 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000000_0' has completed task_201609141558_0002_m_000000 successfully.
2016-09-14 16:07:16,084 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000023_0' has completed task_201609141558_0002_m_000023 successfully.
2016-09-14 16:07:16,085 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000029_0' to tip task_201609141558_0002_m_000029, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:16,085 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000029
2016-09-14 16:07:16,085 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000030_0' to tip task_201609141558_0002_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:16,086 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000030
2016-09-14 16:07:16,086 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000002_0' to tip task_201609141558_0002_r_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:17,333 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000003_0' to tip task_201609141558_0002_r_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:07:17,524 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000004_0' to tip task_201609141558_0002_r_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:07:19,773 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000018_0' has completed task_201609141558_0002_m_000018 successfully.
2016-09-14 16:07:19,774 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000021_0' has completed task_201609141558_0002_m_000021 successfully.
2016-09-14 16:07:19,776 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000028_0' to tip task_201609141558_0002_m_000028, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:19,776 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000028
2016-09-14 16:07:19,776 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000033_0' to tip task_201609141558_0002_m_000033, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:19,776 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000033
2016-09-14 16:07:20,115 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000010_0' has completed task_201609141558_0002_m_000010 successfully.
2016-09-14 16:07:20,116 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000015_0' has completed task_201609141558_0002_m_000015 successfully.
2016-09-14 16:07:20,117 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000016_0' has completed task_201609141558_0002_m_000016 successfully.
2016-09-14 16:07:20,117 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000034_0' to tip task_201609141558_0002_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:20,117 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000034
2016-09-14 16:07:20,118 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000037_0' to tip task_201609141558_0002_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:20,118 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000037
2016-09-14 16:07:20,118 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000032_0' to tip task_201609141558_0002_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:20,118 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0002_m_000032
2016-09-14 16:07:35,051 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000024_0' has completed task_201609141558_0002_m_000024 successfully.
2016-09-14 16:07:35,052 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000036_0' to tip task_201609141558_0002_m_000036, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:07:35,052 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000036
2016-09-14 16:07:35,129 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000037_0' has completed task_201609141558_0002_m_000037 successfully.
2016-09-14 16:07:35,130 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000035_0' to tip task_201609141558_0002_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:07:35,130 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0002_m_000035
2016-09-14 16:07:55,627 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000025_0' has completed task_201609141558_0002_m_000025 successfully.
2016-09-14 16:07:55,628 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000038_0' to tip task_201609141558_0002_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:07:55,628 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000038
2016-09-14 16:07:58,582 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000017_0' has completed task_201609141558_0002_m_000017 successfully.
2016-09-14 16:07:58,584 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000039_0' to tip task_201609141558_0002_m_000039, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:07:58,584 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0002_m_000039
2016-09-14 16:08:03,987 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000029_0' has completed task_201609141558_0002_m_000029 successfully.
2016-09-14 16:08:03,988 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000030_0' has completed task_201609141558_0002_m_000030 successfully.
2016-09-14 16:08:06,993 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000034_0' has completed task_201609141558_0002_m_000034 successfully.
2016-09-14 16:08:09,996 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000035_0' has completed task_201609141558_0002_m_000035 successfully.
2016-09-14 16:08:12,842 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000002_0' has completed task_201609141558_0002_m_000002 successfully.
2016-09-14 16:08:12,843 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000005_0' has completed task_201609141558_0002_m_000005 successfully.
2016-09-14 16:08:12,843 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000006_0' has completed task_201609141558_0002_m_000006 successfully.
2016-09-14 16:08:12,999 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0002_m_000031 for speculative execution
2016-09-14 16:08:13,000 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000031_1' to tip task_201609141558_0002_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:08:13,000 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0002_m_000031
2016-09-14 16:08:13,822 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000013_0' has completed task_201609141558_0002_m_000013 successfully.
2016-09-14 16:08:15,852 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000003_0' has completed task_201609141558_0002_m_000003 successfully.
2016-09-14 16:08:16,638 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000009_0' has completed task_201609141558_0002_m_000009 successfully.
2016-09-14 16:08:16,639 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000011_0' has completed task_201609141558_0002_m_000011 successfully.
2016-09-14 16:08:16,651 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000038_0' has completed task_201609141558_0002_m_000038 successfully.
2016-09-14 16:08:19,648 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000014_0' has completed task_201609141558_0002_m_000014 successfully.
2016-09-14 16:08:19,662 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000026_0' has completed task_201609141558_0002_m_000026 successfully.
2016-09-14 16:08:19,663 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000027_0' has completed task_201609141558_0002_m_000027 successfully.
2016-09-14 16:08:19,663 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000028_0' has completed task_201609141558_0002_m_000028 successfully.
2016-09-14 16:08:22,908 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000033_0' has completed task_201609141558_0002_m_000033 successfully.
2016-09-14 16:08:31,330 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000032_0' has completed task_201609141558_0002_m_000032 successfully.
2016-09-14 16:08:31,332 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0002_m_000007 for speculative execution
2016-09-14 16:08:31,333 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000007_1' to tip task_201609141558_0002_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:08:31,333 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0002_m_000007
2016-09-14 16:08:34,839 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000008_0' has completed task_201609141558_0002_m_000008 successfully.
2016-09-14 16:08:34,840 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000012_0' has completed task_201609141558_0002_m_000012 successfully.
2016-09-14 16:08:35,781 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0002_m_000036 for speculative execution
2016-09-14 16:08:35,781 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0002_m_000036_1' to tip task_201609141558_0002_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:08:35,781 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0002_m_000036
2016-09-14 16:08:37,844 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000001_0' has completed task_201609141558_0002_m_000001 successfully.
2016-09-14 16:08:37,845 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000007_0' has completed task_201609141558_0002_m_000007 successfully.
2016-09-14 16:08:45,347 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000007_1'
2016-09-14 16:08:45,348 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0002_m_000007_1' to tip task_201609141558_0002_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:08:48,361 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000007_1'
2016-09-14 16:08:49,678 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000036_0' has completed task_201609141558_0002_m_000036 successfully.
2016-09-14 16:08:49,678 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000039_0' has completed task_201609141558_0002_m_000039 successfully.
2016-09-14 16:08:56,940 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000036_1'
2016-09-14 16:08:56,940 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0002_m_000036_1' to tip task_201609141558_0002_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:08:59,944 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000036_1'
2016-09-14 16:09:03,900 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000031_0' has completed task_201609141558_0002_m_000031 successfully.
2016-09-14 16:09:11,434 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000031_1'
2016-09-14 16:09:11,434 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0002_m_000031_1' to tip task_201609141558_0002_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:09:14,444 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000031_1'
2016-09-14 16:10:01,504 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_r_000002_0' has completed task_201609141558_0002_r_000002 successfully.
2016-09-14 16:10:13,513 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609141558_0002_r_000001 for speculative execution
2016-09-14 16:10:13,513 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000001_1' to tip task_201609141558_0002_r_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:10:33,013 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_r_000000_0' has completed task_201609141558_0002_r_000000 successfully.
2016-09-14 16:10:42,018 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609141558_0002_r_000004 for speculative execution
2016-09-14 16:10:42,019 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0002_r_000004_1' to tip task_201609141558_0002_r_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:11:27,700 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_r_000003_0' has completed task_201609141558_0002_r_000003 successfully.
2016-09-14 16:11:50,259 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_r_000004_0' has completed task_201609141558_0002_r_000004 successfully.
2016-09-14 16:11:56,083 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000004_1'
2016-09-14 16:11:56,083 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0002_r_000004_1' to tip task_201609141558_0002_r_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:11:59,086 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000004_1'
2016-09-14 16:12:05,147 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_r_000001_0' has completed task_201609141558_0002_r_000001 successfully.
2016-09-14 16:12:05,148 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609141558_0002_m_000040_0' to tip task_201609141558_0002_m_000040, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:12:07,383 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000001_1'
2016-09-14 16:12:07,383 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0002_r_000001_1' to tip task_201609141558_0002_r_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:12:10,385 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000001_1'
2016-09-14 16:12:14,157 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0002_m_000040_0' has completed task_201609141558_0002_m_000040 successfully.
2016-09-14 16:12:14,158 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0002 has completed successfully.
2016-09-14 16:12:14,158 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609141558_0002,submitTime=1473849394063,launchTime=1473849394204,finishTime=1473849734158,numMaps=40,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2476,reduceSlotsSeconds=1159,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 16:12:14,195 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0002_hduser to file:/usr/local/hadoop/logs/history/done/job_201609141558_0002_hduser
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000002_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000003_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000005_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000006_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000022_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000031_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000040_0'
2016-09-14 16:12:14,199 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000001_0'
2016-09-14 16:12:14,201 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0002_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609141558_0002_conf.xml
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609141558_0002_conf.xml
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000000_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000001_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000004_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000007_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000008_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000009_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000010_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000011_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000012_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000013_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000014_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000015_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000016_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000017_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000018_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000019_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000020_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000021_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000023_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000024_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000025_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000026_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000027_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000028_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000029_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000030_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000032_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000033_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000034_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000035_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000036_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000037_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000038_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000039_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000000_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000002_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000003_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_r_000004_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0002_m_000041_0'
2016-09-14 16:12:14,204 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609141558_0002' of user 'hduser'
2016-09-14 16:14:51,266 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609141558_0003 added successfully for user 'hduser' to queue 'default'
2016-09-14 16:14:51,267 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609141558_0003
2016-09-14 16:14:51,267 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609141558_0003
2016-09-14 16:14:51,279 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609141558_0003_hduser
2016-09-14 16:14:51,283 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609141558_0003_conf.xml
2016-09-14 16:14:51,308 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609141558_0003/jobToken
2016-09-14 16:14:51,310 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609141558_0003 = 0. Number of splits = 5
2016-09-14 16:14:51,310 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0003 initialized successfully with 5 map tasks and 0 reduce tasks.
2016-09-14 16:14:51,879 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609141558_0003_m_000006_0' to tip task_201609141558_0003_m_000006, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:14:57,913 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000006_0' has completed task_201609141558_0003_m_000006 successfully.
2016-09-14 16:14:57,915 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0003_m_000000
2016-09-14 16:14:57,915 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000000_0' to tip task_201609141558_0003_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:14:58,485 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0003_m_000001
2016-09-14 16:14:58,485 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000001_0' to tip task_201609141558_0003_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:14:59,176 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0003_m_000002
2016-09-14 16:14:59,176 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000002_0' to tip task_201609141558_0003_m_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:14:59,322 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0003_m_000003
2016-09-14 16:14:59,323 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000003_0' to tip task_201609141558_0003_m_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:14:59,370 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609141558_0003_m_000004
2016-09-14 16:14:59,370 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000004_0' to tip task_201609141558_0003_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:20:41,925 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0003_m_000003 for speculative execution
2016-09-14 16:20:41,926 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000003_1' to tip task_201609141558_0003_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:20:44,929 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000002_0' has completed task_201609141558_0003_m_000002 successfully.
2016-09-14 16:21:43,330 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000000_0' has completed task_201609141558_0003_m_000000 successfully.
2016-09-14 16:21:43,330 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0003_m_000004 for speculative execution
2016-09-14 16:21:43,331 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0003_m_000004_1' to tip task_201609141558_0003_m_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:22:29,563 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000001_0' has completed task_201609141558_0003_m_000001 successfully.
2016-09-14 16:22:57,007 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000004_0' has completed task_201609141558_0003_m_000004 successfully.
2016-09-14 16:23:03,933 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000004_1'
2016-09-14 16:23:03,933 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0003_m_000004_1' to tip task_201609141558_0003_m_000004, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:23:07,054 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000004_1'
2016-09-14 16:23:40,922 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000003_0' has completed task_201609141558_0003_m_000003 successfully.
2016-09-14 16:23:40,923 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609141558_0003_m_000005_0' to tip task_201609141558_0003_m_000005, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:23:48,903 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000003_1'
2016-09-14 16:23:48,903 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0003_m_000003_1' to tip task_201609141558_0003_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:23:51,906 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000003_1'
2016-09-14 16:23:55,935 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0003_m_000005_0' has completed task_201609141558_0003_m_000005 successfully.
2016-09-14 16:23:55,937 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0003 has completed successfully.
2016-09-14 16:23:55,937 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609141558_0003,submitTime=1473849891209,launchTime=1473849891310,finishTime=1473850435937,numMaps=5,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2212,reduceSlotsSeconds=0,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 16:23:55,980 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0003_hduser to file:/usr/local/hadoop/logs/history/done/job_201609141558_0003_hduser
2016-09-14 16:23:55,981 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000003_0'
2016-09-14 16:23:55,981 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000005_0'
2016-09-14 16:23:55,986 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0003_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609141558_0003_conf.xml
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609141558_0003_conf.xml
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000000_0'
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000001_0'
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000002_0'
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000004_0'
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0003_m_000006_0'
2016-09-14 16:23:55,990 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609141558_0003' of user 'hduser'
2016-09-14 16:32:45,257 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609141558_0004 added successfully for user 'hduser' to queue 'default'
2016-09-14 16:32:45,257 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609141558_0004
2016-09-14 16:32:45,257 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609141558_0004
2016-09-14 16:32:45,261 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609141558_0004_hduser
2016-09-14 16:32:45,263 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609141558_0004_conf.xml
2016-09-14 16:32:45,290 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609141558_0004/jobToken
2016-09-14 16:32:45,301 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609141558_0004 = 40000000000. Number of splits = 150
2016-09-14 16:32:45,301 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000000 has split on node:/default-rack/slave3
2016-09-14 16:32:45,301 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000001 has split on node:/default-rack/slave5
2016-09-14 16:32:45,301 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000002 has split on node:/default-rack/slave5
2016-09-14 16:32:45,301 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000003 has split on node:/default-rack/slave3
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000004 has split on node:/default-rack/slave1
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000005 has split on node:/default-rack/slave1
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000006 has split on node:/default-rack/slave3
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000007 has split on node:/default-rack/slave1
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000008 has split on node:/default-rack/slave3
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000009 has split on node:/default-rack/slave3
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000010 has split on node:/default-rack/slave1
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000011 has split on node:/default-rack/slave1
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000012 has split on node:/default-rack/slave5
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000013 has split on node:/default-rack/slave5
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000014 has split on node:/default-rack/slave5
2016-09-14 16:32:45,302 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000015 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000016 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000017 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000018 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000019 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000020 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000021 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000022 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000023 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000024 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000025 has split on node:/default-rack/slave3
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000025 has split on node:/default-rack/slave5
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000025 has split on node:/default-rack/slave1
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000026 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000026 has split on node:/default-rack/slave1
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000026 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000027 has split on node:/default-rack/slave5
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000027 has split on node:/default-rack/slave1
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000027 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000028 has split on node:/default-rack/slave2
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000028 has split on node:/default-rack/slave1
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000028 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000029 has split on node:/default-rack/slave5
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000029 has split on node:/default-rack/slave4
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000029 has split on node:/default-rack/slave1
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000030 has split on node:/default-rack/slave1
2016-09-14 16:32:45,310 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000030 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000030 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000031 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000031 has split on node:/default-rack/slave4
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000031 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000032 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000032 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000032 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000033 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000033 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000033 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000034 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000034 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000034 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000035 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000035 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000035 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000036 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000036 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000036 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000037 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000037 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000037 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000038 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000038 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000038 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000039 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000039 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000039 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000040 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000040 has split on node:/default-rack/slave4
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000040 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000041 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000041 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000041 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000042 has split on node:/default-rack/slave4
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000042 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000042 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000043 has split on node:/default-rack/slave4
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000043 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000043 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000044 has split on node:/default-rack/slave4
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000044 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000044 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000045 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000045 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000045 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000046 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000046 has split on node:/default-rack/slave5
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000046 has split on node:/default-rack/slave3
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000047 has split on node:/default-rack/slave2
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000047 has split on node:/default-rack/slave1
2016-09-14 16:32:45,311 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000047 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000048 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000048 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000048 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000049 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000049 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000049 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000050 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000050 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000050 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000051 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000051 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000051 has split on node:/default-rack/slave2
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000052 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000052 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000052 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000053 has split on node:/default-rack/slave2
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000053 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000053 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000054 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000054 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000054 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000055 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000055 has split on node:/default-rack/slave2
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000055 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000056 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000056 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000056 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000057 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000057 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000057 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000058 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000058 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000058 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000059 has split on node:/default-rack/slave2
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000059 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000059 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000060 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000060 has split on node:/default-rack/slave2
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000060 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000061 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000061 has split on node:/default-rack/slave1
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000061 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000062 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000062 has split on node:/default-rack/slave3
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000062 has split on node:/default-rack/slave4
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000063 has split on node:/default-rack/slave2
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000063 has split on node:/default-rack/slave5
2016-09-14 16:32:45,312 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000063 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000064 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000064 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000064 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000065 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000065 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000065 has split on node:/default-rack/slave1
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000066 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000066 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000066 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000067 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000067 has split on node:/default-rack/slave1
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000067 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000068 has split on node:/default-rack/slave1
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000068 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000068 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000069 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000069 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000069 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000070 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000070 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000070 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000071 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000071 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000071 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000072 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000072 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000072 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000073 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000073 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000073 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000074 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000074 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000074 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000075 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000075 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000075 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000076 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000076 has split on node:/default-rack/slave1
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000076 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000077 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000077 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000077 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000078 has split on node:/default-rack/slave3
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000078 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000078 has split on node:/default-rack/slave4
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000079 has split on node:/default-rack/slave2
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000079 has split on node:/default-rack/slave5
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000079 has split on node:/default-rack/slave1
2016-09-14 16:32:45,313 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000080 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000080 has split on node:/default-rack/slave2
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000080 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000081 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000081 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000081 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000082 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000082 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000082 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000083 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000083 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000083 has split on node:/default-rack/slave2
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000084 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000084 has split on node:/default-rack/slave2
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000084 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000085 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000085 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000085 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000086 has split on node:/default-rack/slave2
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000086 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000086 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000087 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000087 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000087 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000088 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000088 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000088 has split on node:/default-rack/slave2
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000089 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000089 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000089 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000090 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000090 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000090 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000091 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000091 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000091 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000092 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000092 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000092 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000093 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000093 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000093 has split on node:/default-rack/slave2
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000094 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000094 has split on node:/default-rack/slave3
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000094 has split on node:/default-rack/slave5
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000095 has split on node:/default-rack/slave4
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000095 has split on node:/default-rack/slave1
2016-09-14 16:32:45,314 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000095 has split on node:/default-rack/slave3
2016-09-14 16:32:45,315 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000096 has split on node:/default-rack/slave5
2016-09-14 16:32:45,315 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000096 has split on node:/default-rack/slave1
2016-09-14 16:32:45,315 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000096 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000097 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000097 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000097 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000098 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000098 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000098 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000099 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000099 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000099 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000100 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000100 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000100 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000101 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000101 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000101 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000102 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000102 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000102 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000103 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000103 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000103 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000104 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000104 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000104 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000105 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000105 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000105 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000106 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000106 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000106 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000107 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000107 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000107 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000108 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000108 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000108 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000109 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000109 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000109 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000110 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000110 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000110 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000111 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000111 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000111 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000112 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000112 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000112 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000113 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000113 has split on node:/default-rack/slave1
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000113 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000114 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000114 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000114 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000115 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000115 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000115 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000116 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000116 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000116 has split on node:/default-rack/slave4
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000117 has split on node:/default-rack/slave3
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000117 has split on node:/default-rack/slave5
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000117 has split on node:/default-rack/slave2
2016-09-14 16:32:45,316 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000118 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000118 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000118 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000119 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000119 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000119 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000120 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000120 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000120 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000121 has split on node:/default-rack/slave1
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000121 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000121 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000122 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000122 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000122 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000123 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000123 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000123 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000124 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000124 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000124 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000125 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000125 has split on node:/default-rack/slave1
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000125 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000126 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000126 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000126 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000127 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000127 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000127 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000128 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000128 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000128 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000129 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000129 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000129 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000130 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000130 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000130 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000131 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000131 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000131 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000132 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000132 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000132 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000133 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000133 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000133 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000134 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000134 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000134 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000135 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000135 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000135 has split on node:/default-rack/slave1
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000136 has split on node:/default-rack/slave2
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000136 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000136 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000137 has split on node:/default-rack/slave1
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000137 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000137 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000138 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000138 has split on node:/default-rack/slave3
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000138 has split on node:/default-rack/slave5
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000139 has split on node:/default-rack/slave4
2016-09-14 16:32:45,317 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000139 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000139 has split on node:/default-rack/slave1
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000140 has split on node:/default-rack/slave5
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000140 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000140 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000141 has split on node:/default-rack/slave1
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000141 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000141 has split on node:/default-rack/slave5
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000142 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000142 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000142 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000143 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000143 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000143 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000144 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000144 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000144 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000145 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000145 has split on node:/default-rack/slave1
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000145 has split on node:/default-rack/slave5
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000146 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000146 has split on node:/default-rack/slave5
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000146 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000147 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000147 has split on node:/default-rack/slave1
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000147 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000148 has split on node:/default-rack/slave2
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000148 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000148 has split on node:/default-rack/slave5
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000149 has split on node:/default-rack/slave1
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000149 has split on node:/default-rack/slave3
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609141558_0004_m_000149 has split on node:/default-rack/slave4
2016-09-14 16:32:45,318 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0004 initialized successfully with 150 map tasks and 5 reduce tasks.
2016-09-14 16:32:45,651 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609141558_0004_m_000151_0' to tip task_201609141558_0004_m_000151, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:32:51,656 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000151_0' has completed task_201609141558_0004_m_000151 successfully.
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000015_0' to tip task_201609141558_0004_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000015
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000016_0' to tip task_201609141558_0004_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000016
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000017_0' to tip task_201609141558_0004_m_000017, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000017
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000018_0' to tip task_201609141558_0004_m_000018, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000018
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000019_0' to tip task_201609141558_0004_m_000019, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:32:51,657 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000019
2016-09-14 16:32:52,176 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000000_0' to tip task_201609141558_0004_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000000
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000003_0' to tip task_201609141558_0004_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000003
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000006_0' to tip task_201609141558_0004_m_000006, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000006
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000008_0' to tip task_201609141558_0004_m_000008, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000008
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000009_0' to tip task_201609141558_0004_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:32:52,177 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000009
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000020_0' to tip task_201609141558_0004_m_000020, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000020
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000021_0' to tip task_201609141558_0004_m_000021, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000021
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000022_0' to tip task_201609141558_0004_m_000022, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000022
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000023_0' to tip task_201609141558_0004_m_000023, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000023
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000024_0' to tip task_201609141558_0004_m_000024, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:32:53,213 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000024
2016-09-14 16:32:53,377 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000001_0' to tip task_201609141558_0004_m_000001, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:32:53,377 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000001
2016-09-14 16:32:53,377 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000002_0' to tip task_201609141558_0004_m_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:32:53,377 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000002
2016-09-14 16:32:53,377 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000012_0' to tip task_201609141558_0004_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:32:53,377 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000012
2016-09-14 16:32:53,378 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000013_0' to tip task_201609141558_0004_m_000013, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:32:53,378 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000013
2016-09-14 16:32:53,378 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000014_0' to tip task_201609141558_0004_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:32:53,378 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000014
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000004_0' to tip task_201609141558_0004_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000004
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000005_0' to tip task_201609141558_0004_m_000005, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000005
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000007_0' to tip task_201609141558_0004_m_000007, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000007
2016-09-14 16:32:54,299 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000010_0' to tip task_201609141558_0004_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:32:54,300 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000010
2016-09-14 16:32:54,300 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000011_0' to tip task_201609141558_0004_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:32:54,300 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000011
2016-09-14 16:33:28,877 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000003_0' has completed task_201609141558_0004_m_000003 successfully.
2016-09-14 16:33:28,878 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000025_0' to tip task_201609141558_0004_m_000025, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:33:28,878 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000025
2016-09-14 16:33:33,780 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000016_0' has completed task_201609141558_0004_m_000016 successfully.
2016-09-14 16:33:33,781 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000026_0' to tip task_201609141558_0004_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:33:33,781 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000026
2016-09-14 16:33:37,907 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000006_0' has completed task_201609141558_0004_m_000006 successfully.
2016-09-14 16:33:37,908 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000008_0' has completed task_201609141558_0004_m_000008 successfully.
2016-09-14 16:33:37,908 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000009_0' has completed task_201609141558_0004_m_000009 successfully.
2016-09-14 16:33:37,909 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000030_0' to tip task_201609141558_0004_m_000030, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:33:37,909 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000030
2016-09-14 16:33:37,909 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000032_0' to tip task_201609141558_0004_m_000032, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:33:37,909 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000032
2016-09-14 16:33:37,909 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000033_0' to tip task_201609141558_0004_m_000033, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:33:37,909 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000033
2016-09-14 16:33:39,785 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000017_0' has completed task_201609141558_0004_m_000017 successfully.
2016-09-14 16:33:39,786 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000027_0' to tip task_201609141558_0004_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:33:39,786 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000027
2016-09-14 16:33:40,911 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000000_0' has completed task_201609141558_0004_m_000000 successfully.
2016-09-14 16:33:40,912 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000034_0' to tip task_201609141558_0004_m_000034, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:33:40,912 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000034
2016-09-14 16:33:44,975 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000015_0' has completed task_201609141558_0004_m_000015 successfully.
2016-09-14 16:33:44,977 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000028_0' to tip task_201609141558_0004_m_000028, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:33:44,977 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000028
2016-09-14 16:33:44,977 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0004_r_000000_0' to tip task_201609141558_0004_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:33:45,354 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0004_r_000001_0' to tip task_201609141558_0004_r_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:33:46,883 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0004_r_000002_0' to tip task_201609141558_0004_r_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:33:46,917 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0004_r_000003_0' to tip task_201609141558_0004_r_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:33:48,368 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0004_r_000004_0' to tip task_201609141558_0004_r_000004, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:33:50,074 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000018_0' has completed task_201609141558_0004_m_000018 successfully.
2016-09-14 16:33:50,074 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000019_0' has completed task_201609141558_0004_m_000019 successfully.
2016-09-14 16:33:50,075 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000035_0' to tip task_201609141558_0004_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:33:50,075 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000035
2016-09-14 16:33:50,075 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000037_0' to tip task_201609141558_0004_m_000037, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:33:50,075 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000037
2016-09-14 16:34:35,100 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000027_0' has completed task_201609141558_0004_m_000027 successfully.
2016-09-14 16:34:35,101 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000039_0' to tip task_201609141558_0004_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:34:35,101 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000039
2016-09-14 16:34:40,350 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000026_0' has completed task_201609141558_0004_m_000026 successfully.
2016-09-14 16:34:40,350 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000041_0' to tip task_201609141558_0004_m_000041, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:34:40,350 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000041
2016-09-14 16:34:42,432 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000021_0' has completed task_201609141558_0004_m_000021 successfully.
2016-09-14 16:34:42,433 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000022_0' has completed task_201609141558_0004_m_000022 successfully.
2016-09-14 16:34:42,433 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000029_0' to tip task_201609141558_0004_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:34:42,433 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000029
2016-09-14 16:34:42,433 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000031_0' to tip task_201609141558_0004_m_000031, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:34:42,433 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000031
2016-09-14 16:34:42,651 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000032_0' has completed task_201609141558_0004_m_000032 successfully.
2016-09-14 16:34:42,651 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000036_0' to tip task_201609141558_0004_m_000036, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:34:42,652 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000036
2016-09-14 16:34:45,394 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000028_0' has completed task_201609141558_0004_m_000028 successfully.
2016-09-14 16:34:45,395 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000045_0' to tip task_201609141558_0004_m_000045, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:34:45,395 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000045
2016-09-14 16:34:48,982 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000033_0' has completed task_201609141558_0004_m_000033 successfully.
2016-09-14 16:34:48,983 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000034_0' has completed task_201609141558_0004_m_000034 successfully.
2016-09-14 16:34:48,983 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000038_0' to tip task_201609141558_0004_m_000038, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:34:48,983 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000038
2016-09-14 16:34:48,983 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000040_0' to tip task_201609141558_0004_m_000040, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:34:48,983 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000040
2016-09-14 16:34:49,151 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000035_0' has completed task_201609141558_0004_m_000035 successfully.
2016-09-14 16:34:49,151 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000047_0' to tip task_201609141558_0004_m_000047, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:34:49,151 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000047
2016-09-14 16:34:52,216 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000023_0' has completed task_201609141558_0004_m_000023 successfully.
2016-09-14 16:34:52,216 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000042_0' to tip task_201609141558_0004_m_000042, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:34:52,216 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000042
2016-09-14 16:34:52,268 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000037_0' has completed task_201609141558_0004_m_000037 successfully.
2016-09-14 16:34:52,269 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000051_0' to tip task_201609141558_0004_m_000051, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:34:52,269 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000051
2016-09-14 16:34:54,576 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000005_0' has completed task_201609141558_0004_m_000005 successfully.
2016-09-14 16:34:54,577 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000011_0' has completed task_201609141558_0004_m_000011 successfully.
2016-09-14 16:34:54,577 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000043_0' to tip task_201609141558_0004_m_000043, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:34:54,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000043
2016-09-14 16:34:54,577 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000044_0' to tip task_201609141558_0004_m_000044, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:34:54,577 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000044
2016-09-14 16:34:56,364 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000030_0' has completed task_201609141558_0004_m_000030 successfully.
2016-09-14 16:34:56,365 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000046_0' to tip task_201609141558_0004_m_000046, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:34:56,365 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000046
2016-09-14 16:34:59,092 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000020_0' has completed task_201609141558_0004_m_000020 successfully.
2016-09-14 16:34:59,092 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000024_0' has completed task_201609141558_0004_m_000024 successfully.
2016-09-14 16:34:59,093 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000048_0' to tip task_201609141558_0004_m_000048, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:34:59,093 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000048
2016-09-14 16:34:59,093 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000049_0' to tip task_201609141558_0004_m_000049, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:34:59,093 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000049
2016-09-14 16:35:01,773 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000025_0' has completed task_201609141558_0004_m_000025 successfully.
2016-09-14 16:35:01,774 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000054_0' to tip task_201609141558_0004_m_000054, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:35:01,774 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000054
2016-09-14 16:35:02,083 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000007_0' has completed task_201609141558_0004_m_000007 successfully.
2016-09-14 16:35:02,083 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000050_0' to tip task_201609141558_0004_m_000050, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:35:02,084 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000050
2016-09-14 16:35:05,086 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000004_0' has completed task_201609141558_0004_m_000004 successfully.
2016-09-14 16:35:05,087 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000010_0' has completed task_201609141558_0004_m_000010 successfully.
2016-09-14 16:35:05,087 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000052_0' to tip task_201609141558_0004_m_000052, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:35:05,087 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000052
2016-09-14 16:35:05,087 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000053_0' to tip task_201609141558_0004_m_000053, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:35:05,087 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000053
2016-09-14 16:35:34,857 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000001_0' has completed task_201609141558_0004_m_000001 successfully.
2016-09-14 16:35:34,858 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000002_0' has completed task_201609141558_0004_m_000002 successfully.
2016-09-14 16:35:34,858 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000012_0' has completed task_201609141558_0004_m_000012 successfully.
2016-09-14 16:35:34,858 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000013_0' has completed task_201609141558_0004_m_000013 successfully.
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000014_0' has completed task_201609141558_0004_m_000014 successfully.
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000055_0' to tip task_201609141558_0004_m_000055, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000055
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000056_0' to tip task_201609141558_0004_m_000056, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000056
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000057_0' to tip task_201609141558_0004_m_000057, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000057
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000058_0' to tip task_201609141558_0004_m_000058, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000058
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000059_0' to tip task_201609141558_0004_m_000059, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:35:34,859 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000059
2016-09-14 16:35:46,774 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000039_0' has completed task_201609141558_0004_m_000039 successfully.
2016-09-14 16:35:46,774 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000041_0' has completed task_201609141558_0004_m_000041 successfully.
2016-09-14 16:35:46,775 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000060_0' to tip task_201609141558_0004_m_000060, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:35:46,775 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000060
2016-09-14 16:35:46,775 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000063_0' to tip task_201609141558_0004_m_000063, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:35:46,775 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000063
2016-09-14 16:35:52,782 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000045_0' has completed task_201609141558_0004_m_000045 successfully.
2016-09-14 16:35:52,783 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000065_0' to tip task_201609141558_0004_m_000065, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:35:52,783 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000065
2016-09-14 16:36:17,430 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000047_0' has completed task_201609141558_0004_m_000047 successfully.
2016-09-14 16:36:17,430 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000066_0' to tip task_201609141558_0004_m_000066, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:36:17,430 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000066
2016-09-14 16:36:39,475 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000063_0' has completed task_201609141558_0004_m_000063 successfully.
2016-09-14 16:36:39,475 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000067_0' to tip task_201609141558_0004_m_000067, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:36:39,475 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000067
2016-09-14 16:37:30,789 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000029_0' has completed task_201609141558_0004_m_000029 successfully.
2016-09-14 16:37:30,790 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000031_0' has completed task_201609141558_0004_m_000031 successfully.
2016-09-14 16:37:30,790 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000042_0' has completed task_201609141558_0004_m_000042 successfully.
2016-09-14 16:37:30,790 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000048_0' has completed task_201609141558_0004_m_000048 successfully.
2016-09-14 16:37:30,790 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000049_0' has completed task_201609141558_0004_m_000049 successfully.
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000062_0' to tip task_201609141558_0004_m_000062, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000062
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000064_0' to tip task_201609141558_0004_m_000064, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000064
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000070_0' to tip task_201609141558_0004_m_000070, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000070
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000071_0' to tip task_201609141558_0004_m_000071, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000071
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000072_0' to tip task_201609141558_0004_m_000072, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:37:30,791 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000072
2016-09-14 16:37:51,539 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000060_0' has completed task_201609141558_0004_m_000060 successfully.
2016-09-14 16:37:51,540 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000069_0' to tip task_201609141558_0004_m_000069, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:37:51,540 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000069
2016-09-14 16:38:03,547 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000065_0' has completed task_201609141558_0004_m_000065 successfully.
2016-09-14 16:38:03,548 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000073_0' to tip task_201609141558_0004_m_000073, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:38:03,548 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000073
2016-09-14 16:38:26,612 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000036_0' has completed task_201609141558_0004_m_000036 successfully.
2016-09-14 16:38:26,613 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000061_0' to tip task_201609141558_0004_m_000061, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:38:26,613 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000061
2016-09-14 16:38:33,511 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000038_0' has completed task_201609141558_0004_m_000038 successfully.
2016-09-14 16:38:33,512 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000068_0' to tip task_201609141558_0004_m_000068, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:38:33,512 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000068
2016-09-14 16:38:33,569 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000066_0' has completed task_201609141558_0004_m_000066 successfully.
2016-09-14 16:38:33,570 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000075_0' to tip task_201609141558_0004_m_000075, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:38:33,570 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000075
2016-09-14 16:38:36,515 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000040_0' has completed task_201609141558_0004_m_000040 successfully.
2016-09-14 16:38:36,516 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000074_0' to tip task_201609141558_0004_m_000074, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:38:36,516 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000074
2016-09-14 16:38:37,751 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000051_0' has completed task_201609141558_0004_m_000051 successfully.
2016-09-14 16:38:37,751 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000079_0' to tip task_201609141558_0004_m_000079, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:38:37,751 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000079
2016-09-14 16:38:42,599 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000046_0' has completed task_201609141558_0004_m_000046 successfully.
2016-09-14 16:38:42,599 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000077_0' to tip task_201609141558_0004_m_000077, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:38:42,599 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000077
2016-09-14 16:38:45,603 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000054_0' has completed task_201609141558_0004_m_000054 successfully.
2016-09-14 16:38:45,604 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000078_0' to tip task_201609141558_0004_m_000078, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:38:45,604 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000078
2016-09-14 16:38:51,429 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000043_0' has completed task_201609141558_0004_m_000043 successfully.
2016-09-14 16:38:51,429 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000050_0' has completed task_201609141558_0004_m_000050 successfully.
2016-09-14 16:38:51,429 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000052_0' has completed task_201609141558_0004_m_000052 successfully.
2016-09-14 16:38:51,430 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000076_0' to tip task_201609141558_0004_m_000076, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:38:51,430 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000076
2016-09-14 16:38:51,430 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000081_0' to tip task_201609141558_0004_m_000081, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:38:51,430 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000081
2016-09-14 16:38:51,430 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000082_0' to tip task_201609141558_0004_m_000082, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:38:51,430 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000082
2016-09-14 16:38:54,433 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000044_0' has completed task_201609141558_0004_m_000044 successfully.
2016-09-14 16:38:54,434 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000053_0' has completed task_201609141558_0004_m_000053 successfully.
2016-09-14 16:38:54,435 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000085_0' to tip task_201609141558_0004_m_000085, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:38:54,435 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000085
2016-09-14 16:38:54,435 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000088_0' to tip task_201609141558_0004_m_000088, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:38:54,435 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000088
2016-09-14 16:39:00,802 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000073_0' has completed task_201609141558_0004_m_000073 successfully.
2016-09-14 16:39:00,803 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000080_0' to tip task_201609141558_0004_m_000080, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:39:00,803 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000080
2016-09-14 16:39:06,807 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000067_0' has completed task_201609141558_0004_m_000067 successfully.
2016-09-14 16:39:06,808 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000083_0' to tip task_201609141558_0004_m_000083, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:39:06,808 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000083
2016-09-14 16:39:46,447 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000056_0' has completed task_201609141558_0004_m_000056 successfully.
2016-09-14 16:39:46,447 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000057_0' has completed task_201609141558_0004_m_000057 successfully.
2016-09-14 16:39:46,448 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000084_0' to tip task_201609141558_0004_m_000084, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:39:46,448 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000084
2016-09-14 16:39:46,448 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000087_0' to tip task_201609141558_0004_m_000087, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:39:46,448 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000087
2016-09-14 16:40:26,717 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000055_0' has completed task_201609141558_0004_m_000055 successfully.
2016-09-14 16:40:26,717 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000091_0' to tip task_201609141558_0004_m_000091, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:40:26,717 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000091
2016-09-14 16:40:27,445 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000069_0' has completed task_201609141558_0004_m_000069 successfully.
2016-09-14 16:40:27,446 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000086_0' to tip task_201609141558_0004_m_000086, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:40:27,446 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000086
2016-09-14 16:40:40,894 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000059_0' has completed task_201609141558_0004_m_000059 successfully.
2016-09-14 16:40:40,895 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000092_0' to tip task_201609141558_0004_m_000092, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:40:40,895 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000092
2016-09-14 16:40:44,520 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000058_0' has completed task_201609141558_0004_m_000058 successfully.
2016-09-14 16:40:44,521 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000094_0' to tip task_201609141558_0004_m_000094, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:40:44,521 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000094
2016-09-14 16:40:58,830 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000079_0' has completed task_201609141558_0004_m_000079 successfully.
2016-09-14 16:40:58,830 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000093_0' to tip task_201609141558_0004_m_000093, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:40:58,830 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000093
2016-09-14 16:41:03,854 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000075_0' has completed task_201609141558_0004_m_000075 successfully.
2016-09-14 16:41:03,854 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000097_0' to tip task_201609141558_0004_m_000097, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:41:03,854 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000097
2016-09-14 16:41:31,479 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000083_0' has completed task_201609141558_0004_m_000083 successfully.
2016-09-14 16:41:31,479 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000098_0' to tip task_201609141558_0004_m_000098, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:41:31,480 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000098
2016-09-14 16:41:43,493 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000080_0' has completed task_201609141558_0004_m_000080 successfully.
2016-09-14 16:41:43,493 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000106_0' to tip task_201609141558_0004_m_000106, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:41:43,493 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000106
2016-09-14 16:41:47,195 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000068_0' has completed task_201609141558_0004_m_000068 successfully.
2016-09-14 16:41:47,196 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000089_0' to tip task_201609141558_0004_m_000089, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:41:47,196 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000089
2016-09-14 16:41:52,980 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000074_0' has completed task_201609141558_0004_m_000074 successfully.
2016-09-14 16:41:52,981 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000090_0' to tip task_201609141558_0004_m_000090, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:41:52,981 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000090
2016-09-14 16:41:55,984 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000061_0' has completed task_201609141558_0004_m_000061 successfully.
2016-09-14 16:41:55,984 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000077_0' has completed task_201609141558_0004_m_000077 successfully.
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000078_0' has completed task_201609141558_0004_m_000078 successfully.
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000095_0' to tip task_201609141558_0004_m_000095, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000095
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000096_0' to tip task_201609141558_0004_m_000096, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000096
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000099_0' to tip task_201609141558_0004_m_000099, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:41:55,985 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000099
2016-09-14 16:42:26,318 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000064_0' has completed task_201609141558_0004_m_000064 successfully.
2016-09-14 16:42:26,318 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000072_0' has completed task_201609141558_0004_m_000072 successfully.
2016-09-14 16:42:26,319 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000102_0' to tip task_201609141558_0004_m_000102, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:42:26,319 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000102
2016-09-14 16:42:26,319 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000103_0' to tip task_201609141558_0004_m_000103, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:42:26,319 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000103
2016-09-14 16:42:41,114 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000062_0' has completed task_201609141558_0004_m_000062 successfully.
2016-09-14 16:42:41,114 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000070_0' has completed task_201609141558_0004_m_000070 successfully.
2016-09-14 16:42:41,114 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000071_0' has completed task_201609141558_0004_m_000071 successfully.
2016-09-14 16:42:41,115 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000105_0' to tip task_201609141558_0004_m_000105, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:42:41,115 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000105
2016-09-14 16:42:41,115 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000107_0' to tip task_201609141558_0004_m_000107, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:42:41,115 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000107
2016-09-14 16:42:41,115 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000108_0' to tip task_201609141558_0004_m_000108, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:42:41,115 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000108
2016-09-14 16:43:08,705 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000098_0' has completed task_201609141558_0004_m_000098 successfully.
2016-09-14 16:43:08,718 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000110_0' to tip task_201609141558_0004_m_000110, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:43:08,718 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000110
2016-09-14 16:43:13,819 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000097_0' has completed task_201609141558_0004_m_000097 successfully.
2016-09-14 16:43:13,819 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000111_0' to tip task_201609141558_0004_m_000111, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:43:13,819 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000111
2016-09-14 16:43:35,982 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000081_0' has completed task_201609141558_0004_m_000081 successfully.
2016-09-14 16:43:35,983 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000082_0' has completed task_201609141558_0004_m_000082 successfully.
2016-09-14 16:43:35,983 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000085_0' has completed task_201609141558_0004_m_000085 successfully.
2016-09-14 16:43:35,983 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000100_0' to tip task_201609141558_0004_m_000100, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:43:35,983 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000100
2016-09-14 16:43:35,983 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000101_0' to tip task_201609141558_0004_m_000101, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:43:35,983 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000101
2016-09-14 16:43:35,984 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000104_0' to tip task_201609141558_0004_m_000104, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:43:35,984 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000104
2016-09-14 16:43:37,834 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000086_0' has completed task_201609141558_0004_m_000086 successfully.
2016-09-14 16:43:37,835 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000093_0' has completed task_201609141558_0004_m_000093 successfully.
2016-09-14 16:43:37,835 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000106_0' has completed task_201609141558_0004_m_000106 successfully.
2016-09-14 16:43:37,835 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000112_0' to tip task_201609141558_0004_m_000112, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:43:37,836 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000112
2016-09-14 16:43:37,836 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000113_0' to tip task_201609141558_0004_m_000113, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:43:37,836 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000113
2016-09-14 16:43:37,836 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000114_0' to tip task_201609141558_0004_m_000114, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:43:37,836 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000114
2016-09-14 16:43:38,028 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000089_0' has completed task_201609141558_0004_m_000089 successfully.
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000090_0' has completed task_201609141558_0004_m_000090 successfully.
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000095_0' has completed task_201609141558_0004_m_000095 successfully.
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000109_0' to tip task_201609141558_0004_m_000109, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000109
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000115_0' to tip task_201609141558_0004_m_000115, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000115
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000117_0' to tip task_201609141558_0004_m_000117, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:43:38,029 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000117
2016-09-14 16:43:38,987 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000088_0' has completed task_201609141558_0004_m_000088 successfully.
2016-09-14 16:43:38,988 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000121_0' to tip task_201609141558_0004_m_000121, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:43:38,988 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000121
2016-09-14 16:43:43,273 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000096_0' has completed task_201609141558_0004_m_000096 successfully.
2016-09-14 16:43:43,273 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000118_0' to tip task_201609141558_0004_m_000118, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:43:43,273 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000118
2016-09-14 16:43:44,993 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000076_0' has completed task_201609141558_0004_m_000076 successfully.
2016-09-14 16:43:44,994 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000125_0' to tip task_201609141558_0004_m_000125, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:34641'
2016-09-14 16:43:44,994 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000125
2016-09-14 16:43:51,295 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000099_0' has completed task_201609141558_0004_m_000099 successfully.
2016-09-14 16:43:51,295 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000119_0' to tip task_201609141558_0004_m_000119, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:43:51,295 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000119
2016-09-14 16:44:48,395 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000111_0' has completed task_201609141558_0004_m_000111 successfully.
2016-09-14 16:44:48,395 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000116_0' to tip task_201609141558_0004_m_000116, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:44:48,395 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000116
2016-09-14 16:44:55,409 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000110_0' has completed task_201609141558_0004_m_000110 successfully.
2016-09-14 16:44:55,409 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000113_0' has completed task_201609141558_0004_m_000113 successfully.
2016-09-14 16:44:55,410 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000120_0' to tip task_201609141558_0004_m_000120, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:44:55,410 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000120
2016-09-14 16:44:55,410 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000122_0' to tip task_201609141558_0004_m_000122, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:44:55,410 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000122
2016-09-14 16:45:00,714 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000112_0' has completed task_201609141558_0004_m_000112 successfully.
2016-09-14 16:45:00,714 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000123_0' to tip task_201609141558_0004_m_000123, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:45:00,714 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000123
2016-09-14 16:45:05,694 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000084_0' has completed task_201609141558_0004_m_000084 successfully.
2016-09-14 16:45:05,695 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000092_0' has completed task_201609141558_0004_m_000092 successfully.
2016-09-14 16:45:05,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000124_0' to tip task_201609141558_0004_m_000124, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:45:05,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000124
2016-09-14 16:45:05,695 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000126_0' to tip task_201609141558_0004_m_000126, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:45:05,695 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000126
2016-09-14 16:45:17,285 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000091_0' has completed task_201609141558_0004_m_000091 successfully.
2016-09-14 16:45:17,286 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000094_0' has completed task_201609141558_0004_m_000094 successfully.
2016-09-14 16:45:17,286 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000127_0' to tip task_201609141558_0004_m_000127, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:45:17,286 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000127
2016-09-14 16:45:17,286 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000129_0' to tip task_201609141558_0004_m_000129, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:45:17,286 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000129
2016-09-14 16:45:18,732 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000114_0' has completed task_201609141558_0004_m_000114 successfully.
2016-09-14 16:45:18,732 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000128_0' to tip task_201609141558_0004_m_000128, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:45:18,732 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000128
2016-09-14 16:45:20,289 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000087_0' has completed task_201609141558_0004_m_000087 successfully.
2016-09-14 16:45:20,290 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000130_0' to tip task_201609141558_0004_m_000130, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:45:20,290 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000130
2016-09-14 16:45:44,772 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000109_0' has completed task_201609141558_0004_m_000109 successfully.
2016-09-14 16:45:44,773 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000115_0' has completed task_201609141558_0004_m_000115 successfully.
2016-09-14 16:45:44,775 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000118_0' has completed task_201609141558_0004_m_000118 successfully.
2016-09-14 16:45:44,776 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000133_0' to tip task_201609141558_0004_m_000133, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:45:44,776 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000133
2016-09-14 16:45:44,776 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000134_0' to tip task_201609141558_0004_m_000134, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:45:44,776 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000134
2016-09-14 16:45:44,776 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000135_0' to tip task_201609141558_0004_m_000135, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:45:44,776 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000135
2016-09-14 16:45:49,900 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000117_0' has completed task_201609141558_0004_m_000117 successfully.
2016-09-14 16:45:49,900 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000136_0' to tip task_201609141558_0004_m_000136, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:45:49,900 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000136
2016-09-14 16:45:51,403 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000102_0' has completed task_201609141558_0004_m_000102 successfully.
2016-09-14 16:45:51,404 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000131_0' to tip task_201609141558_0004_m_000131, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:45:51,404 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000131
2016-09-14 16:45:54,937 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000119_0' has completed task_201609141558_0004_m_000119 successfully.
2016-09-14 16:45:54,937 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000137_0' to tip task_201609141558_0004_m_000137, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:45:54,937 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000137
2016-09-14 16:46:01,875 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000103_0' has completed task_201609141558_0004_m_000103 successfully.
2016-09-14 16:46:01,875 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000105_0' has completed task_201609141558_0004_m_000105 successfully.
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000107_0' has completed task_201609141558_0004_m_000107 successfully.
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000108_0' has completed task_201609141558_0004_m_000108 successfully.
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000132_0' to tip task_201609141558_0004_m_000132, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000132
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000138_0' to tip task_201609141558_0004_m_000138, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000138
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000139_0' to tip task_201609141558_0004_m_000139, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000139
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000140_0' to tip task_201609141558_0004_m_000140, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:46:01,876 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000140
2016-09-14 16:46:15,633 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000122_0' has completed task_201609141558_0004_m_000122 successfully.
2016-09-14 16:46:15,634 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000142_0' to tip task_201609141558_0004_m_000142, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:46:15,634 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000142
2016-09-14 16:46:21,638 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000120_0' has completed task_201609141558_0004_m_000120 successfully.
2016-09-14 16:46:21,638 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000123_0' has completed task_201609141558_0004_m_000123 successfully.
2016-09-14 16:46:21,639 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000143_0' to tip task_201609141558_0004_m_000143, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:46:21,639 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000143
2016-09-14 16:46:21,639 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000144_0' to tip task_201609141558_0004_m_000144, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:46:21,639 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000144
2016-09-14 16:46:34,577 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000116_0' has completed task_201609141558_0004_m_000116 successfully.
2016-09-14 16:46:34,578 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000146_0' to tip task_201609141558_0004_m_000146, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:46:34,578 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000146
2016-09-14 16:47:07,595 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000128_0' has completed task_201609141558_0004_m_000128 successfully.
2016-09-14 16:47:07,596 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000147_0' to tip task_201609141558_0004_m_000147, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:47:07,596 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000147
2016-09-14 16:47:37,774 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000143_0' has completed task_201609141558_0004_m_000143 successfully.
2016-09-14 16:47:37,775 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000148_0' to tip task_201609141558_0004_m_000148, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:47:37,775 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000148
2016-09-14 16:47:42,545 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000136_0' has completed task_201609141558_0004_m_000136 successfully.
2016-09-14 16:47:42,546 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000149_0' to tip task_201609141558_0004_m_000149, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:47:42,546 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000149
2016-09-14 16:47:46,785 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000142_0' has completed task_201609141558_0004_m_000142 successfully.
2016-09-14 16:47:46,785 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000144_0' has completed task_201609141558_0004_m_000144 successfully.
2016-09-14 16:47:46,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000141_0' to tip task_201609141558_0004_m_000141, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:47:46,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0004_m_000141
2016-09-14 16:47:46,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000145_0' to tip task_201609141558_0004_m_000145, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:47:46,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0004_m_000145
2016-09-14 16:47:47,722 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000135_0' has completed task_201609141558_0004_m_000135 successfully.
2016-09-14 16:47:47,722 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000139 for speculative execution
2016-09-14 16:47:47,723 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000139_1' to tip task_201609141558_0004_m_000139, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:47:47,723 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000139
2016-09-14 16:47:48,432 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609141558_0004_m_000141_0 is 1647 ms debug.
2016-09-14 16:47:50,726 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000133_0' has completed task_201609141558_0004_m_000133 successfully.
2016-09-14 16:47:50,726 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000134_0' has completed task_201609141558_0004_m_000134 successfully.
2016-09-14 16:47:50,727 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000137_0' has completed task_201609141558_0004_m_000137 successfully.
2016-09-14 16:47:50,727 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000131 for speculative execution
2016-09-14 16:47:50,727 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000131_1' to tip task_201609141558_0004_m_000131, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:47:50,727 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0004_m_000131
2016-09-14 16:47:53,241 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000146_0' has completed task_201609141558_0004_m_000146 successfully.
2016-09-14 16:47:54,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000132 for speculative execution
2016-09-14 16:47:54,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000132_1' to tip task_201609141558_0004_m_000132, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:47:54,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0004_m_000132
2016-09-14 16:48:14,417 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000147_0' has completed task_201609141558_0004_m_000147 successfully.
2016-09-14 16:48:14,417 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000140 for speculative execution
2016-09-14 16:48:14,417 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000140_1' to tip task_201609141558_0004_m_000140, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:48:14,417 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000140
2016-09-14 16:48:35,660 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000148_0' has completed task_201609141558_0004_m_000148 successfully.
2016-09-14 16:48:35,661 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000126 for speculative execution
2016-09-14 16:48:35,661 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000126_1' to tip task_201609141558_0004_m_000126, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:48:35,661 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000126
2016-09-14 16:48:51,132 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000131_1' has completed task_201609141558_0004_m_000131 successfully.
2016-09-14 16:48:51,133 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000138 for speculative execution
2016-09-14 16:48:51,133 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000138_1' to tip task_201609141558_0004_m_000138, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:48:51,133 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000138
2016-09-14 16:49:03,142 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000149_0' has completed task_201609141558_0004_m_000149 successfully.
2016-09-14 16:49:03,142 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000124 for speculative execution
2016-09-14 16:49:03,143 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000124_1' to tip task_201609141558_0004_m_000124, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:49:03,143 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0004_m_000124
2016-09-14 16:49:06,686 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000140_1' has completed task_201609141558_0004_m_000140 successfully.
2016-09-14 16:49:09,803 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000131_0'
2016-09-14 16:49:09,803 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000131_0' to tip task_201609141558_0004_m_000131, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:49:20,940 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000140_0'
2016-09-14 16:49:20,940 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000140_0' to tip task_201609141558_0004_m_000140, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:49:25,912 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000139_1' has completed task_201609141558_0004_m_000139 successfully.
2016-09-14 16:49:36,337 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000139_0'
2016-09-14 16:49:36,337 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000139_0' to tip task_201609141558_0004_m_000139, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:43656'
2016-09-14 16:49:39,811 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000126_1' has completed task_201609141558_0004_m_000126 successfully.
2016-09-14 16:49:39,812 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000127 for speculative execution
2016-09-14 16:49:39,812 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000127_1' to tip task_201609141558_0004_m_000127, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:40811'
2016-09-14 16:49:39,812 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000127
2016-09-14 16:49:47,935 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000126_0'
2016-09-14 16:49:47,935 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000126_0' to tip task_201609141558_0004_m_000126, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:49:58,537 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000132_0' has completed task_201609141558_0004_m_000132 successfully.
2016-09-14 16:49:58,538 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000138_0' has completed task_201609141558_0004_m_000138 successfully.
2016-09-14 16:50:06,109 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000132_1'
2016-09-14 16:50:06,109 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000132_1' to tip task_201609141558_0004_m_000132, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:50:06,109 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000138_1'
2016-09-14 16:50:09,110 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000129 for speculative execution
2016-09-14 16:50:09,111 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000129_1' to tip task_201609141558_0004_m_000129, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:50:09,111 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609141558_0004_m_000129
2016-09-14 16:50:09,111 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000132_1'
2016-09-14 16:50:12,113 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609141558_0004_m_000130 for speculative execution
2016-09-14 16:50:12,113 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609141558_0004_m_000130_1' to tip task_201609141558_0004_m_000130, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:50:12,113 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609141558_0004_m_000130
2016-09-14 16:50:33,786 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000100_0' has completed task_201609141558_0004_m_000100 successfully.
2016-09-14 16:50:33,786 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000101_0' has completed task_201609141558_0004_m_000101 successfully.
2016-09-14 16:50:33,786 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000104_0' has completed task_201609141558_0004_m_000104 successfully.
2016-09-14 16:50:33,787 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000121_0' has completed task_201609141558_0004_m_000121 successfully.
2016-09-14 16:50:33,787 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000125_0' has completed task_201609141558_0004_m_000125 successfully.
2016-09-14 16:50:50,318 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000127_1' has completed task_201609141558_0004_m_000127 successfully.
2016-09-14 16:50:53,339 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000145_0' has completed task_201609141558_0004_m_000145 successfully.
2016-09-14 16:50:57,945 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000127_0'
2016-09-14 16:50:57,945 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000127_0' to tip task_201609141558_0004_m_000127, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:51:16,200 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000130_1' has completed task_201609141558_0004_m_000130 successfully.
2016-09-14 16:51:21,245 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000141_0' has completed task_201609141558_0004_m_000141 successfully.
2016-09-14 16:51:21,816 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000131_0'
2016-09-14 16:51:21,816 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000139_0'
2016-09-14 16:51:21,816 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000140_0'
2016-09-14 16:51:22,255 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000130_0'
2016-09-14 16:51:22,255 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000130_0' to tip task_201609141558_0004_m_000130, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 16:52:01,278 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000129_0' has completed task_201609141558_0004_m_000129 successfully.
2016-09-14 16:52:06,448 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000129_1'
2016-09-14 16:52:06,448 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000129_1' to tip task_201609141558_0004_m_000129, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:52:09,449 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000129_1'
2016-09-14 16:52:19,292 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000124_0' has completed task_201609141558_0004_m_000124 successfully.
2016-09-14 16:52:26,462 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000124_1'
2016-09-14 16:52:26,462 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609141558_0004_m_000124_1' to tip task_201609141558_0004_m_000124, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 16:52:29,465 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000124_1'
2016-09-14 16:53:05,452 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000126_0'
2016-09-14 16:53:05,452 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000127_0'
2016-09-14 16:53:05,452 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000130_0'
2016-09-14 17:01:15,788 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609141558_0004_r_000004 for speculative execution
2016-09-14 17:01:15,789 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609141558_0004_r_000004_1' to tip task_201609141558_0004_r_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 17:01:18,791 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_r_000003_0' has completed task_201609141558_0004_r_000003 successfully.
2016-09-14 17:02:17,337 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_r_000000_0' has completed task_201609141558_0004_r_000000 successfully.
2016-09-14 17:02:48,951 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_r_000002_0' has completed task_201609141558_0004_r_000002 successfully.
2016-09-14 17:02:51,886 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_r_000001_0' has completed task_201609141558_0004_r_000001 successfully.
2016-09-14 17:06:14,932 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_r_000004_0' has completed task_201609141558_0004_r_000004 successfully.
2016-09-14 17:06:14,932 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609141558_0004_m_000150_0' to tip task_201609141558_0004_m_000150, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 17:06:20,937 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609141558_0004_m_000150_0' has completed task_201609141558_0004_m_000150 successfully.
2016-09-14 17:06:20,938 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609141558_0004 has completed successfully.
2016-09-14 17:06:20,938 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609141558_0004,submitTime=1473850965199,launchTime=1473850965318,finishTime=1473852980938,numMaps=150,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=24511,reduceSlotsSeconds=8783,clusterMapCapacity=25,clusterReduceCapacity=25
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0004_hduser to file:/usr/local/hadoop/logs/history/done/job_201609141558_0004_hduser
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000001_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000002_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000012_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000013_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000014_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000055_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000056_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000057_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000058_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000059_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000084_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000087_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000091_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000092_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000094_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000124_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000129_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000150_0'
2016-09-14 17:06:20,965 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_r_000004_0'
2016-09-14 17:06:20,987 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609141558_0004_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609141558_0004_conf.xml
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609141558_0004_conf.xml
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000000_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000003_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000004_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000005_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000006_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000007_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000008_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000009_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000010_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000011_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000015_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000016_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000017_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000018_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000019_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000020_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000021_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000022_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000023_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000024_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000025_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000026_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000027_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000028_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000029_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000030_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000031_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000032_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000033_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000034_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000035_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000036_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000037_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000038_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000039_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000040_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000041_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000042_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000043_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000044_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000045_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000046_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000047_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000048_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000049_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000050_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000051_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000052_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000053_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000054_0'
2016-09-14 17:06:20,992 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000060_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000061_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000062_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000063_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000064_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000065_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000066_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000067_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000068_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000069_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000070_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000071_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000072_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000073_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000074_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000075_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000076_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000077_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000078_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000079_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000080_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000081_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000082_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000083_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000085_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000086_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000088_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000089_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000090_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000093_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000095_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000096_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000097_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000098_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000099_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000100_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000101_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000102_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000103_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000104_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000105_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000106_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000107_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000108_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000109_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000110_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000111_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000112_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000113_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000114_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000115_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000116_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000117_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000118_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000119_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000120_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000121_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000122_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000123_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000125_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000126_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000127_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000128_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000130_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000131_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000132_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000133_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000134_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000135_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000136_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000137_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000138_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000139_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000140_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000141_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000142_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000143_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000144_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000145_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000146_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000147_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000148_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000149_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_r_000000_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_r_000001_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_r_000002_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_r_000003_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_r_000004_1'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609141558_0004_m_000151_0'
2016-09-14 17:06:20,993 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609141558_0004' of user 'hduser'
2016-09-14 18:01:08,432 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609141558_0001.info]
2016-09-14 18:01:08,448 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609141558_0002.info]
2016-09-14 18:01:08,456 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609141558_0003.info]
2016-09-14 19:01:08,466 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609141558_0004.info]
2016-09-14 22:41:08,449 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave3:127.0.0.1/127.0.0.1:34946'
2016-09-14 22:51:08,450 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34635'
2016-09-14 23:36:34,947 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 23:36:40,261 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 23:36:40,326 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 23:36:40,329 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 23:36:40,329 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 23:36:40,330 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 23:36:40,330 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 23:36:40,330 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 23:36:40,330 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 23:36:40,336 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 23:36:40,346 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 23:36:40,350 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:36:40,353 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 23:36:40,354 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:36:40,355 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 23:36:40,374 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 23:36:40,397 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 23:36:40,399 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 23:36:40,407 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 23:36:40,408 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 23:36:40,408 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 23:36:40,408 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 23:36:40,533 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 23:36:40,534 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 23:36:40,534 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:36:40,534 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:36:40,535 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 23:36:40,535 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 23:36:40,558 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 23:36:40,620 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:36:40,622 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 343 needs additional 211 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:36:50,624 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:36:50,626 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:00,628 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:37:00,633 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:06,085 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 23:37:10,797 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 23:37:10,863 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 23:37:10,865 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 23:37:10,866 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 23:37:10,867 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 23:37:10,867 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 23:37:10,867 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 23:37:10,867 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 23:37:10,873 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 23:37:10,885 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 23:37:10,888 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:10,891 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 23:37:10,893 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:10,893 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 23:37:10,913 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 23:37:10,936 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 23:37:10,938 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 23:37:10,946 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 23:37:10,946 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 23:37:10,946 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 23:37:10,947 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 23:37:11,070 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 23:37:11,071 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 23:37:11,071 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:11,071 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:11,072 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 23:37:11,072 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 23:37:11,097 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 23:37:11,157 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:37:11,159 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:21,164 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:37:21,166 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:31,169 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:37:31,170 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:41,174 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:37:41,177 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:37:51,180 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:37:51,181 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:38:01,187 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:38:01,194 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:38:11,197 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:38:11,199 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:38:21,204 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:38:21,206 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:38:31,208 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:38:31,209 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:38:41,215 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:38:41,218 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:38:51,221 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:38:51,222 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:39:01,227 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:39:01,230 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:39:11,232 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:39:11,233 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:39:21,237 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:39:21,240 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:39:31,242 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:39:31,243 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:39:41,246 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:39:41,247 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:39:51,252 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:39:51,254 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:40:01,259 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:40:01,261 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:40:11,268 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:40:11,270 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:40:21,273 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:40:21,286 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:40:31,288 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:40:31,289 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:40:41,291 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:40:41,292 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:40:51,294 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:40:51,295 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:41:01,299 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:41:01,302 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:41:11,303 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:41:11,305 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:41:21,307 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:41:21,308 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:41:31,309 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:41:31,310 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:41:41,312 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:41:41,314 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:41:51,317 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:41:51,319 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:01,321 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:42:01,324 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:11,326 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:42:11,330 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:15,985 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-14 23:42:20,882 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-14 23:42:20,947 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-14 23:42:20,950 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-14 23:42:20,950 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 23:42:20,951 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-14 23:42:20,951 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-14 23:42:20,951 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-14 23:42:20,952 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 23:42:20,957 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-14 23:42:20,967 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-14 23:42:20,970 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:20,973 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 23:42:20,974 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:20,975 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-14 23:42:20,994 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-14 23:42:21,017 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-14 23:42:21,018 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-14 23:42:21,026 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-14 23:42:21,027 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-14 23:42:21,027 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-14 23:42:21,027 INFO org.mortbay.log: jetty-6.1.14
2016-09-14 23:42:21,146 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-14 23:42:21,147 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-14 23:42:21,147 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:21,148 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:21,148 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-14 23:42:21,148 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-14 23:42:21,172 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-14 23:42:21,231 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:42:21,232 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:31,235 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:42:31,236 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:41,239 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:42:41,241 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:42:51,246 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:42:51,248 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:43:01,250 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:43:01,251 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:43:11,257 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:43:11,259 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:43:21,265 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:43:21,267 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:43:31,273 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:43:31,282 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:43:41,286 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:43:41,288 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:43:51,294 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:43:51,297 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:44:01,299 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:44:01,300 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:44:11,303 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:44:11,304 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:44:21,305 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:44:21,307 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 495 needs additional 59 blocks to reach the threshold 0.9990 of total blocks 555. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-14 23:44:31,311 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-14 23:44:31,401 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-14 23:44:31,402 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-14 23:44:31,404 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-14 23:44:31,407 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-14 23:44:31,551 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-14 23:44:31,559 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-14 23:44:31,559 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-14 23:44:31,559 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-14 23:44:31,559 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-14 23:44:31,559 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-14 23:44:31,560 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-14 23:44:31,560 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-14 23:44:31,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-14 23:44:31,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-14 23:44:31,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-14 23:44:31,571 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-14 23:44:31,571 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-14 23:44:31,572 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-14 23:44:31,572 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-14 23:44:31,574 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-14 23:44:31,579 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-14 23:44:31,579 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-14 23:44:31,705 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-14 23:44:31,706 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:127.0.0.1/127.0.0.1:41080 to host slave3
2016-09-14 23:44:31,732 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-14 23:44:31,732 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:44640 to host slave5
2016-09-14 23:44:31,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-14 23:44:31,736 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:44958 to host slave1
2016-09-14 23:44:31,753 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-14 23:44:31,753 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:42249 to host slave4
2016-09-14 23:44:31,795 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-14 23:44:31,796 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:45726 to host slave2
2016-09-14 23:45:03,429 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-14 23:45:03,488 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609142342_0001 added successfully for user 'hduser' to queue 'default'
2016-09-14 23:45:03,488 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609142342_0001
2016-09-14 23:45:03,488 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609142342_0001
2016-09-14 23:45:03,520 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609142342_0001_hduser
2016-09-14 23:45:03,601 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609142342_0001_conf.xml
2016-09-14 23:45:03,646 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609142342_0001/jobToken
2016-09-14 23:45:03,655 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609142342_0001 = 10000000000. Number of splits = 40
2016-09-14 23:45:03,656 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000000 has split on node:/default-rack/slave3
2016-09-14 23:45:03,656 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000001 has split on node:/default-rack/slave3
2016-09-14 23:45:03,656 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000002 has split on node:/default-rack/slave5
2016-09-14 23:45:03,656 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000003 has split on node:/default-rack/slave3
2016-09-14 23:45:03,656 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000004 has split on node:/default-rack/slave3
2016-09-14 23:45:03,656 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000005 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000006 has split on node:/default-rack/slave3
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000007 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000008 has split on node:/default-rack/slave3
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000009 has split on node:/default-rack/slave3
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000010 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000011 has split on node:/default-rack/slave3
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000012 has split on node:/default-rack/slave3
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000013 has split on node:/default-rack/slave3
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000014 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000015 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000016 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000017 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000018 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000019 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000020 has split on node:/default-rack/slave5
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000021 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000022 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000023 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000024 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000025 has split on node:/default-rack/slave2
2016-09-14 23:45:03,657 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000026 has split on node:/default-rack/slave2
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000027 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000028 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000029 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000030 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000031 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000032 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000033 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000034 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000035 has split on node:/default-rack/slave5
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000036 has split on node:/default-rack/slave5
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000037 has split on node:/default-rack/slave2
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000038 has split on node:/default-rack/slave1
2016-09-14 23:45:03,658 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609142342_0001_m_000039 has split on node:/default-rack/slave1
2016-09-14 23:45:03,659 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609142342_0001 initialized successfully with 40 map tasks and 5 reduce tasks.
2016-09-14 23:45:04,759 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609142342_0001_m_000041_0' to tip task_201609142342_0001_m_000041, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,811 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000041_0' has completed task_201609142342_0001_m_000041 successfully.
2016-09-14 23:45:07,818 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000000_0' to tip task_201609142342_0001_m_000000, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000000
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000001_0' to tip task_201609142342_0001_m_000001, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000001
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000003_0' to tip task_201609142342_0001_m_000003, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000003
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000004_0' to tip task_201609142342_0001_m_000004, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,820 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000004
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000006_0' to tip task_201609142342_0001_m_000006, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000006
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000008_0' to tip task_201609142342_0001_m_000008, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000008
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000009_0' to tip task_201609142342_0001_m_000009, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000009
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000011_0' to tip task_201609142342_0001_m_000011, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:07,821 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000011
2016-09-14 23:45:07,839 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000007_0' to tip task_201609142342_0001_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,839 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000007
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000018_0' to tip task_201609142342_0001_m_000018, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000018
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000019_0' to tip task_201609142342_0001_m_000019, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000019
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000021_0' to tip task_201609142342_0001_m_000021, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000021
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000022_0' to tip task_201609142342_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,840 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000022
2016-09-14 23:45:07,841 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000023_0' to tip task_201609142342_0001_m_000023, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,841 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000023
2016-09-14 23:45:07,841 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000024_0' to tip task_201609142342_0001_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,841 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000024
2016-09-14 23:45:07,841 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000025_0' to tip task_201609142342_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:07,841 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000025
2016-09-14 23:45:10,782 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000027_0' to tip task_201609142342_0001_m_000027, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,782 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000027
2016-09-14 23:45:10,782 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000028_0' to tip task_201609142342_0001_m_000028, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,782 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000028
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000029_0' to tip task_201609142342_0001_m_000029, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000029
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000030_0' to tip task_201609142342_0001_m_000030, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000030
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000031_0' to tip task_201609142342_0001_m_000031, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000031
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000032_0' to tip task_201609142342_0001_m_000032, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,783 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000032
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000033_0' to tip task_201609142342_0001_m_000033, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000033
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000034_0' to tip task_201609142342_0001_m_000034, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000034
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000002_0' to tip task_201609142342_0001_m_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000002
2016-09-14 23:45:10,784 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000005_0' to tip task_201609142342_0001_m_000005, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000005
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000010_0' to tip task_201609142342_0001_m_000010, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000010
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000014_0' to tip task_201609142342_0001_m_000014, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000014
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000015_0' to tip task_201609142342_0001_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000015
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000016_0' to tip task_201609142342_0001_m_000016, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,785 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000016
2016-09-14 23:45:10,786 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000017_0' to tip task_201609142342_0001_m_000017, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,786 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000017
2016-09-14 23:45:10,786 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000020_0' to tip task_201609142342_0001_m_000020, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:10,786 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609142342_0001_m_000020
2016-09-14 23:45:10,808 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000012_0' to tip task_201609142342_0001_m_000012, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,808 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000012
2016-09-14 23:45:10,808 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000013_0' to tip task_201609142342_0001_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,808 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000013
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000026_0' to tip task_201609142342_0001_m_000026, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000026
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000035_0' to tip task_201609142342_0001_m_000035, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000035
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000036_0' to tip task_201609142342_0001_m_000036, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000036
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000037_0' to tip task_201609142342_0001_m_000037, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000037
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000038_0' to tip task_201609142342_0001_m_000038, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,809 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000038
2016-09-14 23:45:10,810 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609142342_0001_m_000039_0' to tip task_201609142342_0001_m_000039, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:10,810 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609142342_0001_m_000039
2016-09-14 23:45:44,147 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000038_0' has completed task_201609142342_0001_m_000038 successfully.
2016-09-14 23:45:44,149 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000039_0' has completed task_201609142342_0001_m_000039 successfully.
2016-09-14 23:45:44,152 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609142342_0001_r_000000_0' to tip task_201609142342_0001_r_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:42249'
2016-09-14 23:45:44,901 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609142342_0001_r_000001_0' to tip task_201609142342_0001_r_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:44958'
2016-09-14 23:45:46,918 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609142342_0001_r_000002_0' to tip task_201609142342_0001_r_000002, for tracker 'tracker_slave3:127.0.0.1/127.0.0.1:41080'
2016-09-14 23:45:47,101 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609142342_0001_r_000003_0' to tip task_201609142342_0001_r_000003, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:44640'
2016-09-14 23:45:47,152 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609142342_0001_r_000004_0' to tip task_201609142342_0001_r_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:45:52,709 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000019_0' has completed task_201609142342_0001_m_000019 successfully.
2016-09-14 23:45:59,801 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000026_0' has completed task_201609142342_0001_m_000026 successfully.
2016-09-14 23:46:13,121 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000000_0' has completed task_201609142342_0001_m_000000 successfully.
2016-09-14 23:46:13,123 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000001_0' has completed task_201609142342_0001_m_000001 successfully.
2016-09-14 23:46:13,123 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000004_0' has completed task_201609142342_0001_m_000004 successfully.
2016-09-14 23:46:13,124 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000009_0' has completed task_201609142342_0001_m_000009 successfully.
2016-09-14 23:46:13,125 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000011_0' has completed task_201609142342_0001_m_000011 successfully.
2016-09-14 23:46:22,735 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000022_0' has completed task_201609142342_0001_m_000022 successfully.
2016-09-14 23:46:26,827 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000037_0' has completed task_201609142342_0001_m_000037 successfully.
2016-09-14 23:46:29,870 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000035_0' has completed task_201609142342_0001_m_000035 successfully.
2016-09-14 23:46:32,888 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000036_0' has completed task_201609142342_0001_m_000036 successfully.
2016-09-14 23:46:34,744 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000023_0' has completed task_201609142342_0001_m_000023 successfully.
2016-09-14 23:46:37,751 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000007_0' has completed task_201609142342_0001_m_000007 successfully.
2016-09-14 23:46:40,755 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000025_0' has completed task_201609142342_0001_m_000025 successfully.
2016-09-14 23:46:55,768 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000021_0' has completed task_201609142342_0001_m_000021 successfully.
2016-09-14 23:47:01,776 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000018_0' has completed task_201609142342_0001_m_000018 successfully.
2016-09-14 23:47:01,777 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000024_0' has completed task_201609142342_0001_m_000024 successfully.
2016-09-14 23:47:28,190 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000003_0' has completed task_201609142342_0001_m_000003 successfully.
2016-09-14 23:47:38,410 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000006_0' has completed task_201609142342_0001_m_000006 successfully.
2016-09-14 23:47:38,411 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000008_0' has completed task_201609142342_0001_m_000008 successfully.
2016-09-14 23:47:50,970 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000012_0' has completed task_201609142342_0001_m_000012 successfully.
2016-09-14 23:47:53,975 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000013_0' has completed task_201609142342_0001_m_000013 successfully.
2016-09-14 23:49:41,692 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000014_0' has completed task_201609142342_0001_m_000014 successfully.
2016-09-14 23:49:44,700 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000002_0' has completed task_201609142342_0001_m_000002 successfully.
2016-09-14 23:49:44,702 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000005_0' has completed task_201609142342_0001_m_000005 successfully.
2016-09-14 23:49:44,703 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000016_0' has completed task_201609142342_0001_m_000016 successfully.
2016-09-14 23:49:44,704 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000017_0' has completed task_201609142342_0001_m_000017 successfully.
2016-09-14 23:49:44,706 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000020_0' has completed task_201609142342_0001_m_000020 successfully.
2016-09-14 23:49:47,718 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000010_0' has completed task_201609142342_0001_m_000010 successfully.
2016-09-14 23:49:47,721 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000015_0' has completed task_201609142342_0001_m_000015 successfully.
2016-09-14 23:50:27,937 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000028_0' has completed task_201609142342_0001_m_000028 successfully.
2016-09-14 23:50:27,939 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000030_0' has completed task_201609142342_0001_m_000030 successfully.
2016-09-14 23:50:27,940 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000031_0' has completed task_201609142342_0001_m_000031 successfully.
2016-09-14 23:50:27,943 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000032_0' has completed task_201609142342_0001_m_000032 successfully.
2016-09-14 23:50:27,944 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000033_0' has completed task_201609142342_0001_m_000033 successfully.
2016-09-14 23:50:30,949 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000027_0' has completed task_201609142342_0001_m_000027 successfully.
2016-09-14 23:50:30,952 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000029_0' has completed task_201609142342_0001_m_000029 successfully.
2016-09-14 23:50:30,954 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000034_0' has completed task_201609142342_0001_m_000034 successfully.
2016-09-14 23:51:25,992 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_r_000004_0' has completed task_201609142342_0001_r_000004 successfully.
2016-09-14 23:52:44,041 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609142342_0001_r_000001 for speculative execution
2016-09-14 23:52:44,041 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609142342_0001_r_000001_1' to tip task_201609142342_0001_r_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:53:25,755 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_r_000000_0' has completed task_201609142342_0001_r_000000 successfully.
2016-09-14 23:53:35,491 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_r_000002_0' has completed task_201609142342_0001_r_000002 successfully.
2016-09-14 23:53:37,160 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_r_000003_0' has completed task_201609142342_0001_r_000003 successfully.
2016-09-14 23:53:59,095 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_r_000001_1' has completed task_201609142342_0001_r_000001 successfully.
2016-09-14 23:53:59,097 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609142342_0001_m_000040_0' to tip task_201609142342_0001_m_000040, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:45726'
2016-09-14 23:54:02,100 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609142342_0001_m_000040_0' has completed task_201609142342_0001_m_000040 successfully.
2016-09-14 23:54:02,101 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609142342_0001 has completed successfully.
2016-09-14 23:54:02,102 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609142342_0001,submitTime=1473876903380,launchTime=1473876903658,finishTime=1473877442101,numMaps=40,numSlotsPerMap=1,numReduces=5,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=6835,reduceSlotsSeconds=1798,clusterMapCapacity=50,clusterReduceCapacity=50
2016-09-14 23:54:02,152 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609142342_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609142342_0001_hduser
2016-09-14 23:54:02,154 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000007_0'
2016-09-14 23:54:02,154 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000018_0'
2016-09-14 23:54:02,154 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000019_0'
2016-09-14 23:54:02,154 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000021_0'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000022_0'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000023_0'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000024_0'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000025_0'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000040_0'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_r_000001_1'
2016-09-14 23:54:02,155 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_r_000004_0'
2016-09-14 23:54:02,157 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609142342_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609142342_0001_conf.xml
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609142342_0001_conf.xml
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000000_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000001_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000002_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000003_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000004_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000005_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000006_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000008_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000009_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000010_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000011_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000012_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000013_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000014_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000015_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000016_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000017_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000020_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000026_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000027_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000028_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000029_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000030_0'
2016-09-14 23:54:02,162 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000031_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000032_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000033_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000034_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000035_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000036_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000037_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000038_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000039_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_r_000000_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_r_000001_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_r_000002_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_r_000003_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609142342_0001_m_000041_0'
2016-09-14 23:54:02,163 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609142342_0001' of user 'hduser'
2016-09-14 23:57:27,015 INFO org.apache.hadoop.mapred.JSPUtil: Loading Job History file job_201609142342_0001.   Cache size is 0
2016-09-14 23:57:40,795 INFO org.apache.hadoop.conf.Configuration: found resource webapps/static/jobconf.xsl at file:/usr/local/hadoop-0.21.0/webapps/static/jobconf.xsl
