2016-09-08 18:09:22,042 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609062321_0003 added successfully for user 'hduser' to queue 'default'
2016-09-08 18:09:22,042 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609062321_0003
2016-09-08 18:09:22,043 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609062321_0003
2016-09-08 18:09:22,045 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609062321_0003_hduser
2016-09-08 18:09:22,053 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609062321_0003_conf.xml
2016-09-08 18:09:22,116 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609062321_0003 = 10000000000. Number of splits = 38
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000000 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000001 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000002 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000003 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000004 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000005 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000006 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000007 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000008 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000009 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000010 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000011 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000012 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000013 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000014 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000015 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000015 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000015 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000016 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000016 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000016 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000017 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000017 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000017 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000018 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000018 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000018 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000019 has split on node:/default-rack/slave5
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000019 has split on node:/default-rack/slave2
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000019 has split on node:/default-rack/slave1
2016-09-08 18:09:22,119 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000020 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000020 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000020 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000021 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000021 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000021 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000022 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000022 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000022 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000023 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000023 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000023 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000024 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000024 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000024 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000025 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000025 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000025 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000026 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000026 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000026 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000027 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000027 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000027 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000028 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000028 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000028 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000029 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000029 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000029 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000030 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000030 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000030 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000031 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000031 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000031 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000032 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000032 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000032 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000033 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000033 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000033 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000034 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000034 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000034 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000035 has split on node:/default-rack/slave2
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000035 has split on node:/default-rack/slave5
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000035 has split on node:/default-rack/slave1
2016-09-08 18:09:22,120 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000036 has split on node:/default-rack/slave1
2016-09-08 18:09:22,121 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000036 has split on node:/default-rack/slave5
2016-09-08 18:09:22,121 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000036 has split on node:/default-rack/slave2
2016-09-08 18:09:22,121 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000037 has split on node:/default-rack/slave5
2016-09-08 18:09:22,121 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000037 has split on node:/default-rack/slave2
2016-09-08 18:09:22,121 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609062321_0003_m_000037 has split on node:/default-rack/slave1
2016-09-08 18:09:22,121 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609062321_0003 initialized successfully with 38 map tasks and 1 reduce tasks.
2016-09-08 18:09:22,829 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609062321_0003_m_000039_0' to tip task_201609062321_0003_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:46785'
2016-09-08 18:09:25,832 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000039_0' has completed task_201609062321_0003_m_000039 successfully.
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000000_0' to tip task_201609062321_0003_m_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:46785'
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000000
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000001_0' to tip task_201609062321_0003_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:46785'
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000001
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000002_0' to tip task_201609062321_0003_m_000002, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:46785'
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000002
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000003_0' to tip task_201609062321_0003_m_000003, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:46785'
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000003
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000004_0' to tip task_201609062321_0003_m_000004, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:46785'
2016-09-08 18:09:25,834 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000004
2016-09-08 18:09:26,887 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000010_0' to tip task_201609062321_0003_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:09:26,888 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000010
2016-09-08 18:09:26,888 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000011_0' to tip task_201609062321_0003_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:09:26,888 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000011
2016-09-08 18:09:26,888 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000012_0' to tip task_201609062321_0003_m_000012, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:09:26,889 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000012
2016-09-08 18:09:26,889 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000013_0' to tip task_201609062321_0003_m_000013, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:09:26,889 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000013
2016-09-08 18:09:26,889 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000014_0' to tip task_201609062321_0003_m_000014, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:09:26,889 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000014
2016-09-08 18:09:27,675 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000005_0' to tip task_201609062321_0003_m_000005, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:09:27,675 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000005
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000006_0' to tip task_201609062321_0003_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000006
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000007_0' to tip task_201609062321_0003_m_000007, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000007
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000008_0' to tip task_201609062321_0003_m_000008, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000008
2016-09-08 18:09:27,676 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000009_0' to tip task_201609062321_0003_m_000009, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:09:27,677 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000009
2016-09-08 18:09:27,730 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000015_0' to tip task_201609062321_0003_m_000015, for tracker 'tracker_slave3:localhost/127.0.0.1:35535'
2016-09-08 18:09:27,730 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609062321_0003_m_000015
2016-09-08 18:09:27,730 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000016_0' to tip task_201609062321_0003_m_000016, for tracker 'tracker_slave3:localhost/127.0.0.1:35535'
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609062321_0003_m_000016
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000017_0' to tip task_201609062321_0003_m_000017, for tracker 'tracker_slave3:localhost/127.0.0.1:35535'
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609062321_0003_m_000017
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000018_0' to tip task_201609062321_0003_m_000018, for tracker 'tracker_slave3:localhost/127.0.0.1:35535'
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609062321_0003_m_000018
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000019_0' to tip task_201609062321_0003_m_000019, for tracker 'tracker_slave3:localhost/127.0.0.1:35535'
2016-09-08 18:09:27,731 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609062321_0003_m_000019
2016-09-08 18:10:19,280 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000016_0' has completed task_201609062321_0003_m_000016 successfully.
2016-09-08 18:10:19,281 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000020_0' to tip task_201609062321_0003_m_000020, for tracker 'tracker_slave3:localhost/127.0.0.1:35535'
2016-09-08 18:10:19,281 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609062321_0003_m_000020
2016-09-08 18:10:46,099 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000014_0' has completed task_201609062321_0003_m_000014 successfully.
2016-09-08 18:10:46,100 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000021_0' to tip task_201609062321_0003_m_000021, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:10:46,100 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000021
2016-09-08 18:10:46,101 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609062321_0003_r_000000_0' to tip task_201609062321_0003_r_000000, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:11:01,857 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000008_0' has completed task_201609062321_0003_m_000008 successfully.
2016-09-08 18:11:01,860 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000022_0' to tip task_201609062321_0003_m_000022, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:11:01,860 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000022
2016-09-08 18:11:04,126 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000011_0' has completed task_201609062321_0003_m_000011 successfully.
2016-09-08 18:11:04,127 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000023_0' to tip task_201609062321_0003_m_000023, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:11:04,127 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000023
2016-09-08 18:11:04,874 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000007_0' has completed task_201609062321_0003_m_000007 successfully.
2016-09-08 18:11:04,876 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000024_0' to tip task_201609062321_0003_m_000024, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:46122'
2016-09-08 18:11:04,876 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000024
2016-09-08 18:11:07,219 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000010_0' has completed task_201609062321_0003_m_000010 successfully.
2016-09-08 18:11:07,220 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000012_0' has completed task_201609062321_0003_m_000012 successfully.
2016-09-08 18:11:07,220 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000013_0' has completed task_201609062321_0003_m_000013 successfully.
2016-09-08 18:11:07,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000025_0' to tip task_201609062321_0003_m_000025, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:11:07,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000025
2016-09-08 18:11:07,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000026_0' to tip task_201609062321_0003_m_000026, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:11:07,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000026
2016-09-08 18:11:07,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000027_0' to tip task_201609062321_0003_m_000027, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:11:07,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000027
2016-09-08 18:12:16,284 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609062321_0003_m_000000_0 is 170450 ms debug.
2016-09-08 18:13:44,129 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000026_0' has completed task_201609062321_0003_m_000026 successfully.
2016-09-08 18:13:44,131 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000027_0' has completed task_201609062321_0003_m_000027 successfully.
2016-09-08 18:13:44,133 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000028_0' to tip task_201609062321_0003_m_000028, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:13:44,133 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000028
2016-09-08 18:13:44,133 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000029_0' to tip task_201609062321_0003_m_000029, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:13:44,134 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000029
2016-09-08 18:13:51,424 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000021_0' has completed task_201609062321_0003_m_000021 successfully.
2016-09-08 18:13:51,425 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000023_0' has completed task_201609062321_0003_m_000023 successfully.
2016-09-08 18:13:51,426 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_m_000025_0' has completed task_201609062321_0003_m_000025 successfully.
2016-09-08 18:13:51,427 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000030_0' to tip task_201609062321_0003_m_000030, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:13:51,428 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000030
2016-09-08 18:13:51,428 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000031_0' to tip task_201609062321_0003_m_000031, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:13:51,428 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000031
2016-09-08 18:13:51,428 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609062321_0003_m_000032_0' to tip task_201609062321_0003_m_000032, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:13:51,428 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609062321_0003_m_000032
2016-09-08 18:14:55,672 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609062321_0003
2016-09-08 18:14:55,672 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609062321_0003'
2016-09-08 18:14:56,762 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609062321_0003_r_000001_0' to tip task_201609062321_0003_r_000001, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39765'
2016-09-08 18:15:13,434 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000028_0'
2016-09-08 18:15:13,434 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000029_0'
2016-09-08 18:15:28,639 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609062321_0003_r_000001_0' has completed task_201609062321_0003_r_000001 successfully.
2016-09-08 18:15:28,640 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609062321_0003,submitTime=1473338361951,launchTime=1473338362121,finishTime=1473338728640,numMaps=38,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=KILLED,mapSlotSeconds=1932,reduceSlotsSeconds=24,clusterMapCapacity=20,clusterReduceCapacity=8
2016-09-08 18:15:29,015 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 10.129.40.105:50010
2016-09-08 18:15:29,015 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_4060472747029118026_7024
2016-09-08 18:15:29,016 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.105:50010
2016-09-08 18:15:29,017 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2016-09-08 18:15:29,017 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_4133849375939199524_7024
2016-09-08 18:15:29,017 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.103:50010
2016-09-08 18:15:29,020 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 10.129.40.102:50010
2016-09-08 18:15:29,020 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-6632035772819917711_7024
2016-09-08 18:15:29,020 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.102:50010
2016-09-08 18:15:29,576 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609062321_0003_hduser to file:/usr/local/hadoop/logs/history/done/job_201609062321_0003_hduser
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000010_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000011_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000012_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000013_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000014_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000021_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000023_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000025_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000026_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000027_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000030_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000031_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000032_0'
2016-09-08 18:15:29,577 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_r_000001_0'
2016-09-08 18:15:29,585 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609062321_0003_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609062321_0003_conf.xml
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609062321_0003_conf.xml
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000000_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000001_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000002_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000003_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000004_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000005_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000006_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000007_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000008_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000009_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000015_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000016_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000017_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000018_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000019_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000020_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000022_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000024_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_r_000000_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609062321_0003_m_000039_0'
2016-09-08 18:15:29,588 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609062321_0003' of user 'hduser'
2016-09-08 18:15:36,284 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609062321_0003_m_000000_0 is 370450 ms debug.
2016-09-08 18:18:56,284 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609062321_0003_m_000000_0 is 570450 ms debug.
2016-09-08 18:21:53,873 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 18:21:59,036 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 18:21:59,104 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 18:21:59,107 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 18:21:59,107 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 18:21:59,108 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 18:21:59,108 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 18:21:59,108 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 18:21:59,108 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 18:21:59,125 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 18:21:59,135 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 18:21:59,138 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:21:59,142 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 18:21:59,143 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:21:59,143 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 18:21:59,163 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 18:21:59,187 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 18:21:59,189 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 18:21:59,197 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 18:21:59,198 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 18:21:59,198 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 18:21:59,198 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 18:21:59,318 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 18:21:59,319 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 18:21:59,319 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:21:59,319 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:21:59,320 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 18:21:59,320 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 18:21:59,343 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 18:21:59,410 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:21:59,411 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 832 needs additional 290 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:22:09,616 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:22:09,618 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:22:19,623 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:22:19,626 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:22:29,628 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:22:29,629 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:22:39,631 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:22:39,632 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:22:49,634 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:22:49,635 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:22:59,640 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:22:59,643 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:23:09,646 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:23:09,647 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:23:19,649 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:23:19,650 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:23:29,652 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:23:29,653 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:23:39,656 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:23:39,658 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:23:49,661 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:23:49,663 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:23:59,666 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:23:59,668 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:09,670 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:24:09,670 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:19,672 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:24:19,676 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:24,488 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 18:24:29,321 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 18:24:29,386 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 18:24:29,388 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 18:24:29,389 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 18:24:29,390 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 18:24:29,390 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 18:24:29,390 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 18:24:29,390 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 18:24:29,396 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 18:24:29,405 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 18:24:29,408 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:29,411 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 18:24:29,413 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:29,414 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 18:24:29,435 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 18:24:29,457 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 18:24:29,459 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 18:24:29,467 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 18:24:29,467 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 18:24:29,467 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 18:24:29,467 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 18:24:29,591 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 18:24:29,592 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 18:24:29,592 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:29,593 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:29,593 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 18:24:29,593 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 18:24:29,619 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 18:24:29,682 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:24:29,683 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:39,688 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:24:39,691 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:49,695 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:24:49,699 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 18:24:59,702 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 18:24:59,789 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 18:24:59,789 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 18:24:59,802 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 18:24:59,804 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 18:24:59,927 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 18:24:59,934 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 18:24:59,934 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 18:24:59,934 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 18:24:59,934 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 18:24:59,936 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 18:24:59,938 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 18:24:59,941 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 18:24:59,941 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 18:24:59,941 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 18:24:59,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 18:24:59,954 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 18:24:59,958 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 18:24:59,961 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 18:24:59,961 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 18:24:59,961 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 18:24:59,961 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 18:24:59,964 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 18:25:00,054 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 18:25:00,055 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:35410 to host slave2
2016-09-08 18:25:00,068 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 18:25:00,069 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:39139 to host slave1
2016-09-08 18:25:00,075 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 18:25:00,075 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:33174 to host slave3
2016-09-08 18:25:00,104 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 18:25:00,104 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:34232 to host slave5
2016-09-08 18:26:25,553 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-08 18:26:25,627 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609081824_0001 added successfully for user 'hduser' to queue 'default'
2016-09-08 18:26:25,628 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609081824_0001
2016-09-08 18:26:25,628 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609081824_0001
2016-09-08 18:26:25,660 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609081824_0001_hduser
2016-09-08 18:26:25,740 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609081824_0001_conf.xml
2016-09-08 18:26:25,797 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken
2016-09-08 18:26:25,840 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609081824_0001 = 10000000000. Number of splits = 38
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000000 has split on node:/default-rack/slave5
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000001 has split on node:/default-rack/slave5
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000002 has split on node:/default-rack/slave5
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000003 has split on node:/default-rack/slave5
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000004 has split on node:/default-rack/slave5
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000005 has split on node:/default-rack/slave2
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000006 has split on node:/default-rack/slave2
2016-09-08 18:26:25,841 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000007 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000008 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000009 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000010 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000011 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000012 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000013 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000014 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000015 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000015 has split on node:/default-rack/slave5
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000015 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000016 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000016 has split on node:/default-rack/slave5
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000016 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000017 has split on node:/default-rack/slave5
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000017 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000017 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000018 has split on node:/default-rack/slave1
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000018 has split on node:/default-rack/slave5
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000018 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000019 has split on node:/default-rack/slave5
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000019 has split on node:/default-rack/slave2
2016-09-08 18:26:25,842 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000019 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000020 has split on node:/default-rack/slave2
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000020 has split on node:/default-rack/slave5
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000020 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000021 has split on node:/default-rack/slave5
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000021 has split on node:/default-rack/slave2
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000021 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000022 has split on node:/default-rack/slave2
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000022 has split on node:/default-rack/slave5
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000022 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000023 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000023 has split on node:/default-rack/slave5
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000023 has split on node:/default-rack/slave2
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000024 has split on node:/default-rack/slave5
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000024 has split on node:/default-rack/slave2
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000024 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000025 has split on node:/default-rack/slave2
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000025 has split on node:/default-rack/slave5
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000025 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000026 has split on node:/default-rack/slave1
2016-09-08 18:26:25,843 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000026 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000026 has split on node:/default-rack/slave2
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000027 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000027 has split on node:/default-rack/slave2
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000027 has split on node:/default-rack/slave1
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000028 has split on node:/default-rack/slave1
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000028 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000028 has split on node:/default-rack/slave2
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000029 has split on node:/default-rack/slave2
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000029 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000029 has split on node:/default-rack/slave1
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000030 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000030 has split on node:/default-rack/slave2
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000030 has split on node:/default-rack/slave1
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000031 has split on node:/default-rack/slave1
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000031 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000031 has split on node:/default-rack/slave2
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000032 has split on node:/default-rack/slave1
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000032 has split on node:/default-rack/slave5
2016-09-08 18:26:25,844 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000032 has split on node:/default-rack/slave2
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000033 has split on node:/default-rack/slave5
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000033 has split on node:/default-rack/slave2
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000033 has split on node:/default-rack/slave1
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000034 has split on node:/default-rack/slave1
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000034 has split on node:/default-rack/slave5
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000034 has split on node:/default-rack/slave2
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000035 has split on node:/default-rack/slave5
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000035 has split on node:/default-rack/slave2
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000035 has split on node:/default-rack/slave1
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000036 has split on node:/default-rack/slave1
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000036 has split on node:/default-rack/slave5
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000036 has split on node:/default-rack/slave2
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000037 has split on node:/default-rack/slave5
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000037 has split on node:/default-rack/slave2
2016-09-08 18:26:25,845 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609081824_0001_m_000037 has split on node:/default-rack/slave1
2016-09-08 18:26:25,846 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609081824_0001 initialized successfully with 38 map tasks and 1 reduce tasks.
2016-09-08 18:26:27,183 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609081824_0001_m_000039_0' to tip task_201609081824_0001_m_000039, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:26:30,224 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000039_0' has completed task_201609081824_0001_m_000039 successfully.
2016-09-08 18:26:30,241 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000005_0' to tip task_201609081824_0001_m_000005, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:26:30,245 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000005
2016-09-08 18:26:30,245 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000006_0' to tip task_201609081824_0001_m_000006, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:26:30,246 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000006
2016-09-08 18:26:30,246 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000007_0' to tip task_201609081824_0001_m_000007, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:26:30,246 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000007
2016-09-08 18:26:30,246 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000008_0' to tip task_201609081824_0001_m_000008, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:26:30,247 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000008
2016-09-08 18:26:30,247 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000009_0' to tip task_201609081824_0001_m_000009, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:26:30,247 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000009
2016-09-08 18:26:33,193 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000000_0' to tip task_201609081824_0001_m_000000, for tracker 'tracker_slave3:localhost/127.0.0.1:33174'
2016-09-08 18:26:33,194 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609081824_0001_m_000000
2016-09-08 18:26:33,194 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000001_0' to tip task_201609081824_0001_m_000001, for tracker 'tracker_slave3:localhost/127.0.0.1:33174'
2016-09-08 18:26:33,194 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609081824_0001_m_000001
2016-09-08 18:26:33,194 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000002_0' to tip task_201609081824_0001_m_000002, for tracker 'tracker_slave3:localhost/127.0.0.1:33174'
2016-09-08 18:26:33,195 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609081824_0001_m_000002
2016-09-08 18:26:33,195 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000003_0' to tip task_201609081824_0001_m_000003, for tracker 'tracker_slave3:localhost/127.0.0.1:33174'
2016-09-08 18:26:33,195 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609081824_0001_m_000003
2016-09-08 18:26:33,195 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000004_0' to tip task_201609081824_0001_m_000004, for tracker 'tracker_slave3:localhost/127.0.0.1:33174'
2016-09-08 18:26:33,195 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609081824_0001_m_000004
2016-09-08 18:26:33,196 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000010_0' to tip task_201609081824_0001_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:26:33,196 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000010
2016-09-08 18:26:33,196 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000011_0' to tip task_201609081824_0001_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:26:33,196 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000011
2016-09-08 18:26:33,196 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000012_0' to tip task_201609081824_0001_m_000012, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:26:33,197 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000012
2016-09-08 18:26:33,197 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000013_0' to tip task_201609081824_0001_m_000013, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:26:33,197 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000013
2016-09-08 18:26:33,197 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000014_0' to tip task_201609081824_0001_m_000014, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:26:33,197 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000014
2016-09-08 18:26:33,216 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000015_0' to tip task_201609081824_0001_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34232'
2016-09-08 18:26:33,216 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000015
2016-09-08 18:26:33,216 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000016_0' to tip task_201609081824_0001_m_000016, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34232'
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000016
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000017_0' to tip task_201609081824_0001_m_000017, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34232'
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000017
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000018_0' to tip task_201609081824_0001_m_000018, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34232'
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000018
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000019_0' to tip task_201609081824_0001_m_000019, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34232'
2016-09-08 18:26:33,217 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000019
2016-09-08 18:27:24,520 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000005_0' has completed task_201609081824_0001_m_000005 successfully.
2016-09-08 18:27:24,527 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000008_0' has completed task_201609081824_0001_m_000008 successfully.
2016-09-08 18:27:24,531 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000020_0' to tip task_201609081824_0001_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:27:24,532 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000020
2016-09-08 18:27:24,532 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000021_0' to tip task_201609081824_0001_m_000021, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:27:24,532 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000021
2016-09-08 18:27:24,539 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609081824_0001_r_000000_0' to tip task_201609081824_0001_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:27:30,550 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000009_0' has completed task_201609081824_0001_m_000009 successfully.
2016-09-08 18:27:30,552 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000022_0' to tip task_201609081824_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:27:30,552 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000022
2016-09-08 18:27:36,672 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000017_0' has completed task_201609081824_0001_m_000017 successfully.
2016-09-08 18:27:36,674 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000023_0' to tip task_201609081824_0001_m_000023, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:34232'
2016-09-08 18:27:36,674 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000023
2016-09-08 18:27:44,722 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000010_0' has completed task_201609081824_0001_m_000010 successfully.
2016-09-08 18:27:44,725 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000012_0' has completed task_201609081824_0001_m_000012 successfully.
2016-09-08 18:27:44,727 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000024_0' to tip task_201609081824_0001_m_000024, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:27:44,727 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000024
2016-09-08 18:27:44,728 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000025_0' to tip task_201609081824_0001_m_000025, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:27:44,728 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000025
2016-09-08 18:27:44,901 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000006_0' has completed task_201609081824_0001_m_000006 successfully.
2016-09-08 18:27:44,903 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000007_0' has completed task_201609081824_0001_m_000007 successfully.
2016-09-08 18:27:44,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000026_0' to tip task_201609081824_0001_m_000026, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:27:44,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000026
2016-09-08 18:27:44,904 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000027_0' to tip task_201609081824_0001_m_000027, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:27:44,904 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000027
2016-09-08 18:27:59,755 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000014_0' has completed task_201609081824_0001_m_000014 successfully.
2016-09-08 18:27:59,758 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000028_0' to tip task_201609081824_0001_m_000028, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:27:59,759 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000028
2016-09-08 18:28:04,868 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000011_0' has completed task_201609081824_0001_m_000011 successfully.
2016-09-08 18:28:04,871 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000029_0' to tip task_201609081824_0001_m_000029, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:28:04,871 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000029
2016-09-08 18:28:10,130 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000013_0' has completed task_201609081824_0001_m_000013 successfully.
2016-09-08 18:28:10,131 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000030_0' to tip task_201609081824_0001_m_000030, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:28:10,132 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000030
2016-09-08 18:28:42,417 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000020_0' has completed task_201609081824_0001_m_000020 successfully.
2016-09-08 18:28:42,418 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000031_0' to tip task_201609081824_0001_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:28:42,418 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000031
2016-09-08 18:28:51,426 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000027_0' has completed task_201609081824_0001_m_000027 successfully.
2016-09-08 18:28:51,427 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000032_0' to tip task_201609081824_0001_m_000032, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:28:51,427 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000032
2016-09-08 18:28:56,459 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000021_0' has completed task_201609081824_0001_m_000021 successfully.
2016-09-08 18:28:56,461 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000033_0' to tip task_201609081824_0001_m_000033, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:28:56,461 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000033
2016-09-08 18:29:01,512 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000022_0' has completed task_201609081824_0001_m_000022 successfully.
2016-09-08 18:29:01,515 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000034_0' to tip task_201609081824_0001_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:29:01,515 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000034
2016-09-08 18:29:08,024 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000026_0' has completed task_201609081824_0001_m_000026 successfully.
2016-09-08 18:29:08,026 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000035_0' to tip task_201609081824_0001_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:29:08,026 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000035
2016-09-08 18:29:20,863 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000025_0' has completed task_201609081824_0001_m_000025 successfully.
2016-09-08 18:29:20,864 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000036_0' to tip task_201609081824_0001_m_000036, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:29:20,864 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000036
2016-09-08 18:29:25,802 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000024_0' has completed task_201609081824_0001_m_000024 successfully.
2016-09-08 18:29:25,803 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081824_0001_m_000037_0' to tip task_201609081824_0001_m_000037, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:39139'
2016-09-08 18:29:25,803 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609081824_0001_m_000037
2016-09-08 18:29:45,153 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000029_0' has completed task_201609081824_0001_m_000029 successfully.
2016-09-08 18:29:45,178 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609081824_0001
2016-09-08 18:29:45,178 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609081824_0001'
2016-09-08 18:29:47,836 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609081824_0001_r_000001_0' to tip task_201609081824_0001_r_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:35410'
2016-09-08 18:29:49,744 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000028_0' has completed task_201609081824_0001_m_000028 successfully.
2016-09-08 18:29:49,745 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_m_000030_0' has completed task_201609081824_0001_m_000030 successfully.
2016-09-08 18:29:55,312 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000036_0'
2016-09-08 18:30:00,626 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000031_0'
2016-09-08 18:30:00,626 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000032_0'
2016-09-08 18:30:03,286 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000037_0'
2016-09-08 18:30:10,705 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081824_0001_r_000001_0' has completed task_201609081824_0001_r_000001 successfully.
2016-09-08 18:30:10,707 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609081824_0001,submitTime=1473339385523,launchTime=1473339385845,finishTime=1473339610706,numMaps=38,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=KILLED,mapSlotSeconds=2018,reduceSlotsSeconds=17,clusterMapCapacity=20,clusterReduceCapacity=8
2016-09-08 18:30:11,294 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 10.129.40.103:50010
2016-09-08 18:30:11,294 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-424913560466712531_7033
2016-09-08 18:30:11,295 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.103:50010
2016-09-08 18:30:11,621 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609081824_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609081824_0001_hduser
2016-09-08 18:30:11,622 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000005_0'
2016-09-08 18:30:11,622 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000006_0'
2016-09-08 18:30:11,622 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000007_0'
2016-09-08 18:30:11,622 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000008_0'
2016-09-08 18:30:11,622 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000009_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000020_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000021_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000022_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000026_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000027_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000033_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000034_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000039_0'
2016-09-08 18:30:11,623 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_r_000001_0'
2016-09-08 18:30:11,633 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609081824_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609081824_0001_conf.xml
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609081824_0001_conf.xml
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000000_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000001_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000002_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000003_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000004_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000010_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000011_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000012_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000013_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000014_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000015_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000016_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000017_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000018_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000019_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000023_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000024_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000025_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000028_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000029_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000030_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_m_000035_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081824_0001_r_000000_0'
2016-09-08 18:30:11,658 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609081824_0001' of user 'hduser'
2016-09-08 18:33:25,846 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 19:08:13,810 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:08:13,923 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:08:13,926 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 19:08:13,927 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:08:13,927 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 19:08:13,927 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:08:13,927 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 19:08:13,928 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:08:13,968 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 19:08:13,978 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:08:13,981 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:13,984 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:08:13,985 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:13,986 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:08:14,005 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:08:14,027 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:08:14,030 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 19:08:14,074 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 19:08:14,075 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 19:08:14,075 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 19:08:14,075 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:08:14,205 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 19:08:14,206 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 19:08:14,206 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:14,207 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:14,207 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 19:08:14,207 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 19:08:14,250 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 19:08:14,350 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:08:14,352 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 914 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:24,357 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:08:24,361 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:34,367 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:08:34,369 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:44,374 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:08:44,378 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:08:54,384 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:08:54,538 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 19:08:54,539 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 19:08:54,540 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 19:08:54,542 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 19:08:54,690 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 19:08:54,697 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 19:08:54,698 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 19:08:54,698 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:08:54,698 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 19:08:54,700 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:08:54,701 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 19:08:54,701 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 19:08:54,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 19:08:54,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 19:08:54,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 19:08:54,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 19:08:54,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 19:08:54,708 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 19:08:54,708 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 19:08:54,708 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 19:08:54,712 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 19:08:54,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 19:08:54,812 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 19:08:54,813 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:35327 to host slave3
2016-09-08 19:08:54,839 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 19:08:54,839 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:44550 to host slave2
2016-09-08 19:08:54,840 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 19:08:54,840 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:45309 to host slave1
2016-09-08 19:08:54,870 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 19:08:54,870 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:43560 to host slave5
2016-09-08 19:16:33,680 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 19:16:38,402 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:16:38,466 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:16:38,469 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 19:16:38,469 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:16:38,470 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 19:16:38,470 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:16:38,470 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 19:16:38,471 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:16:38,476 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 19:16:38,486 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:16:38,489 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:16:38,492 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:16:38,493 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:16:38,494 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:16:38,513 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:16:38,535 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:16:38,537 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 19:16:38,545 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 19:16:38,546 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 19:16:38,546 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 19:16:38,546 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:16:38,665 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 19:16:38,665 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 19:16:38,666 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:16:38,666 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:16:38,666 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 19:16:38,666 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 19:16:38,690 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 19:16:38,756 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:16:38,757 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:16:48,760 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:16:48,762 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:16:58,767 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:16:58,770 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:17:08,776 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:17:08,883 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 19:17:08,885 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 19:17:08,887 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 19:17:08,891 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 19:17:09,039 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 19:17:09,046 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 19:17:09,046 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 19:17:09,046 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:17:09,046 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 19:17:09,047 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:17:09,047 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 19:17:09,055 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 19:17:09,055 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 19:17:09,055 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609062321_0003.info]
2016-09-08 19:17:09,060 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 19:17:09,066 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 19:17:09,066 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 19:17:09,066 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 19:17:09,070 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 19:17:09,070 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 19:17:09,072 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 19:17:09,072 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 19:17:09,072 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 19:17:09,159 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 19:17:09,160 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:35163 to host slave3
2016-09-08 19:17:09,161 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 19:17:09,161 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:34288 to host slave1
2016-09-08 19:17:09,168 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 19:17:09,168 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:35321 to host slave5
2016-09-08 19:17:09,173 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 19:17:09,174 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:46487 to host slave2
2016-09-08 19:23:49,507 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 19:23:54,480 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:23:54,544 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:23:54,547 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 19:23:54,548 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:23:54,549 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 19:23:54,549 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:23:54,549 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 19:23:54,549 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:23:54,555 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 19:23:54,565 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:23:54,568 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:23:54,571 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:23:54,572 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:23:54,573 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:23:54,592 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:23:54,615 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:23:54,617 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 19:23:54,625 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 19:23:54,626 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 19:23:54,626 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 19:23:54,626 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:23:54,745 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 19:23:54,746 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 19:23:54,746 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:23:54,747 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:23:54,747 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 19:23:54,747 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 19:23:54,772 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 19:23:54,832 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:23:54,833 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 27 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:24:04,838 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:24:04,842 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 17 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:24:14,847 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:24:14,857 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 7 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:24:24,863 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:24:24,960 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 19:24:24,961 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 19:24:24,962 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 19:24:24,966 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 19:24:25,086 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 19:24:25,093 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 19:24:25,093 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 19:24:25,093 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:24:25,093 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 19:24:25,094 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:24:25,095 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 19:24:25,096 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 19:24:25,096 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 19:24:25,102 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 19:24:25,102 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 19:24:25,102 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 19:24:25,104 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 19:24:25,108 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 19:24:25,116 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 19:24:25,116 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 19:24:25,116 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 19:24:25,116 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 19:24:25,170 WARN org.apache.hadoop.mapred.JobTracker: Report from tracker_slave4:127.0.0.1/127.0.0.1:43660: Shutting down. Incompatible buildVersion.
JobTracker's: 0.21.0 from 985326 by tomwhite source checksum a1aeb15b4854808d152989ba76f90fac
TaskTracker's: 0.21.0 from Unknown by jayant source checksum c3a40654b45e0d42d4890992c6642d4e
2016-09-08 19:24:25,199 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 19:24:25,199 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:41921 to host slave1
2016-09-08 19:24:25,200 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 19:24:25,201 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:45139 to host slave2
2016-09-08 19:24:25,201 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 19:24:25,201 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:36756 to host slave3
2016-09-08 19:24:25,207 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 19:24:25,207 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:44587 to host slave5
2016-09-08 19:43:53,610 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 19:43:58,324 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:43:58,388 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:43:58,391 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 19:43:58,391 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:43:58,392 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 19:43:58,392 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 19:43:58,392 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 19:43:58,393 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:43:58,398 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 19:43:58,408 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:43:58,411 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:43:58,414 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:43:58,416 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:43:58,416 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 19:43:58,436 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:43:58,459 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:43:58,460 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 19:43:58,468 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 19:43:58,469 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 19:43:58,469 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 19:43:58,469 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:43:58,588 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 19:43:58,588 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 19:43:58,588 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:43:58,589 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:43:58,589 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 19:43:58,589 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 19:43:58,613 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 19:43:58,671 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:43:58,674 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:44:08,677 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:44:08,678 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:44:18,680 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:44:18,681 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 19:44:28,683 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 19:44:28,791 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 19:44:28,791 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 19:44:28,792 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 19:44:28,800 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 19:44:28,912 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 19:44:28,921 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 19:44:28,921 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 19:44:28,921 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:44:28,921 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 19:44:28,937 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:44:28,938 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609081824_0001.info]
2016-09-08 19:44:28,938 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 19:44:28,938 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 19:44:28,939 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 19:44:28,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 19:44:28,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 19:44:28,947 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 19:44:29,041 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 19:44:29,042 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:38632 to host slave1
2016-09-08 19:44:29,043 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-08 19:44:29,044 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:35506 to host slave4
2016-09-08 19:44:29,047 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 19:44:29,048 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:33198 to host slave5
2016-09-08 19:44:29,048 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 19:44:29,048 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:39387 to host slave2
2016-09-08 19:44:29,053 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 19:44:29,054 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:45581 to host slave3
2016-09-08 20:11:49,422 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-08 20:11:49,464 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609081943_0001 added successfully for user 'hduser' to queue 'default'
2016-09-08 20:11:49,465 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609081943_0001
2016-09-08 20:11:49,465 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609081943_0001
2016-09-08 20:11:49,499 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609081943_0001_hduser
2016-09-08 20:11:49,623 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609081943_0001_conf.xml
2016-09-08 20:11:49,680 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken
2016-09-08 20:11:49,691 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609081943_0001 = 0. Number of splits = 2
2016-09-08 20:11:49,691 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609081943_0001 initialized successfully with 2 map tasks and 0 reduce tasks.
2016-09-08 20:11:51,040 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609081943_0001_m_000003_0' to tip task_201609081943_0001_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:38632'
2016-09-08 20:11:54,239 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081943_0001_m_000003_0' has completed task_201609081943_0001_m_000003 successfully.
2016-09-08 20:11:54,270 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609081943_0001_m_000000
2016-09-08 20:11:54,271 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081943_0001_m_000000_0' to tip task_201609081943_0001_m_000000, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:38632'
2016-09-08 20:11:54,278 INFO org.apache.hadoop.mapred.JobInProgress: Choosing a non-local task task_201609081943_0001_m_000001
2016-09-08 20:11:54,278 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081943_0001_m_000001_0' to tip task_201609081943_0001_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39387'
2016-09-08 20:12:54,720 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609081943_0001_m_000001 for speculative execution
2016-09-08 20:12:54,721 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081943_0001_m_000001_1' to tip task_201609081943_0001_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:35506'
2016-09-08 20:13:06,928 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609081943_0001_m_000000 for speculative execution
2016-09-08 20:13:06,928 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609081943_0001_m_000000_1' to tip task_201609081943_0001_m_000000, for tracker 'tracker_slave3:localhost/127.0.0.1:45581'
2016-09-08 20:24:03,147 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081943_0001_m_000000_1' has completed task_201609081943_0001_m_000000 successfully.
2016-09-08 20:24:07,850 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000000_0'
2016-09-08 20:24:07,851 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609081943_0001_m_000000_0' to tip task_201609081943_0001_m_000000, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:38632'
2016-09-08 20:24:10,857 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000000_0'
2016-09-08 20:25:32,826 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081943_0001_m_000001_1' has completed task_201609081943_0001_m_000001 successfully.
2016-09-08 20:25:32,829 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609081943_0001_m_000002_0' to tip task_201609081943_0001_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:35506'
2016-09-08 20:25:40,388 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000001_0'
2016-09-08 20:25:40,388 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609081943_0001_m_000001_0' to tip task_201609081943_0001_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39387'
2016-09-08 20:25:41,866 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609081943_0001_m_000002_0' has completed task_201609081943_0001_m_000002 successfully.
2016-09-08 20:25:41,868 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609081943_0001 has completed successfully.
2016-09-08 20:25:41,868 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609081943_0001,submitTime=1473345709384,launchTime=1473345709691,finishTime=1473346541868,numMaps=2,numSlotsPerMap=1,numReduces=0,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=1417,reduceSlotsSeconds=0,clusterMapCapacity=22,clusterReduceCapacity=10
2016-09-08 20:25:41,886 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2016-09-08 20:25:41,886 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-2924385686455397670_7050
2016-09-08 20:25:41,886 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.103:50010
2016-09-08 20:25:41,909 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609081943_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609081943_0001_hduser
2016-09-08 20:25:41,913 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000001_1'
2016-09-08 20:25:41,913 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000002_0'
2016-09-08 20:25:41,937 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609081943_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609081943_0001_conf.xml
2016-09-08 20:25:41,947 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609081943_0001_conf.xml
2016-09-08 20:25:41,947 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000000_1'
2016-09-08 20:25:41,947 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000001_0'
2016-09-08 20:25:41,947 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609081943_0001_m_000003_0'
2016-09-08 20:25:41,947 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609081943_0001' of user 'hduser'
2016-09-08 20:31:13,715 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 20:31:18,579 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:31:18,642 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:31:18,645 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 20:31:18,646 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:31:18,646 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 20:31:18,646 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:31:18,647 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 20:31:18,647 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:31:18,653 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 20:31:18,663 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:31:18,666 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:18,669 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:31:18,670 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:18,670 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:31:18,689 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:31:18,712 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:31:18,714 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 20:31:18,722 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 20:31:18,722 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 20:31:18,722 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 20:31:18,722 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:31:18,838 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 20:31:18,839 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 20:31:18,839 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:18,839 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:18,840 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 20:31:18,840 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 20:31:18,864 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 20:31:18,924 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:31:18,925 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:28,930 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:31:28,932 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:36,894 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 20:31:41,678 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:31:41,741 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:31:41,744 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 20:31:41,745 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:31:41,745 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 20:31:41,746 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:31:41,746 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 20:31:41,746 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:31:41,751 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 20:31:41,761 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:31:41,764 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:41,767 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:31:41,769 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:41,769 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:31:41,788 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:31:41,811 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:31:41,813 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 20:31:41,821 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 20:31:41,821 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 20:31:41,821 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 20:31:41,821 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:31:41,938 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 20:31:41,939 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 20:31:41,939 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:41,940 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:41,940 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 20:31:41,940 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 20:31:41,963 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 20:31:42,023 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:31:42,024 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:31:52,029 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:31:52,031 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:32:02,033 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:32:02,035 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:32:12,039 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:32:12,041 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:32:22,047 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:32:22,050 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:32:32,053 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:32:32,054 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:32:42,059 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:32:42,062 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:32:52,069 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:32:52,072 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:33:02,074 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:33:02,075 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:33:12,077 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:33:12,078 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:33:22,080 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:33:22,081 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:33:32,084 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:33:32,088 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:33:42,090 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:33:42,091 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:33:52,094 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:33:52,096 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:34:02,099 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:34:02,100 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:34:12,103 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:34:12,111 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:34:22,114 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:34:22,115 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:34:32,120 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:34:32,125 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:34:42,128 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:34:42,130 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:34:52,133 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:34:52,135 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:35:02,137 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:35:02,138 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:35:12,142 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:35:12,145 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:35:22,149 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:35:22,152 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:35:32,156 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:35:32,158 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:35:42,162 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:35:42,165 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:35:52,169 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:35:52,172 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:36:02,174 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:36:02,175 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:36:12,177 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:36:12,180 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:36:22,184 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:36:22,187 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:36:32,190 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:36:32,192 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:36:42,195 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:36:42,197 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:36:52,201 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:36:52,203 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:02,207 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:37:02,210 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:12,214 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:37:12,217 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:22,220 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:37:22,222 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:32,223 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:37:32,224 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:42,227 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:37:42,229 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:51,055 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 20:37:55,799 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:37:55,863 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:37:55,865 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 20:37:55,866 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:37:55,866 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 20:37:55,867 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:37:55,867 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 20:37:55,867 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:37:55,872 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 20:37:55,882 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:37:55,885 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:55,888 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:37:55,890 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:55,890 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:37:55,910 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:37:55,933 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:37:55,935 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 20:37:55,943 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 20:37:55,943 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 20:37:55,943 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 20:37:55,943 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:37:56,062 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 20:37:56,063 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 20:37:56,063 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:56,063 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:37:56,063 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 20:37:56,063 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 20:37:56,087 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 20:37:56,146 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:37:56,148 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:38:06,154 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:38:06,157 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:38:16,164 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:38:16,167 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:38:26,170 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:38:26,247 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 20:38:26,248 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 20:38:26,253 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 20:38:26,255 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 20:38:26,377 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 20:38:26,385 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 20:38:26,385 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 20:38:26,385 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:38:26,385 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 20:38:26,392 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 20:38:26,392 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 20:38:26,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 20:38:26,400 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 20:38:26,400 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 20:38:26,400 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 20:38:26,401 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 20:38:26,401 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 20:38:26,401 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 20:38:26,402 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 20:38:26,402 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 20:38:26,402 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 20:38:26,402 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 20:38:26,507 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 20:38:26,508 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:35644 to host slave1
2016-09-08 20:38:26,514 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 20:38:26,515 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:34037 to host slave2
2016-09-08 20:38:26,515 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 20:38:26,515 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:34771 to host slave3
2016-09-08 20:38:26,517 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-08 20:38:26,517 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:43639 to host slave4
2016-09-08 20:38:26,540 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 20:38:26,540 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:33709 to host slave5
2016-09-08 20:39:16,599 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at master/10.129.40.100
************************************************************/
2016-09-08 20:39:21,348 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/../hdfs/conf:/usr/local/hadoop/bin/../hdfs/hadoop-hdfs-*.jar:/usr/local/hadoop/bin/../hdfs/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:39:21,414 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:39:21,416 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hduser and supergroup as supergroup
2016-09-08 20:39:21,417 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:39:21,418 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-09-08 20:39:21,418 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-09-08 20:39:21,418 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2016-09-08 20:39:21,418 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:39:21,424 INFO org.apache.hadoop.mapred.QueueManager: AllQueues : {default=default}; LeafQueues : {default=default}
2016-09-08 20:39:21,434 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:39:21,437 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:21,440 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:39:21,442 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1450)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:21,442 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=JobTracker, port=8021
2016-09-08 20:39:21,462 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:39:21,485 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:39:21,487 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: History log directory is file:////usr/local/hadoop/bin/../logs/history
2016-09-08 20:39:21,495 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2016-09-08 20:39:21,495 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2016-09-08 20:39:21,495 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2016-09-08 20:39:21,495 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:39:21,615 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2016-09-08 20:39:21,616 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-09-08 20:39:21,616 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:21,616 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context mapred
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.mapred.JobTrackerMetricsInst.<init>(JobTrackerMetricsInst.java:73)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1488)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:21,617 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 8021
2016-09-08 20:39:21,617 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2016-09-08 20:39:21,642 WARN org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-08 20:39:21,705 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:39:21,706 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:31,710 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:39:31,712 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:41,718 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:39:41,721 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://master:8020/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)

	at org.apache.hadoop.ipc.Client.call(Client.java:905)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at com.sun.proxy.$Proxy5.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:810)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:296)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1563)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:258)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:250)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:245)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4164)
2016-09-08 20:39:51,725 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2016-09-08 20:39:51,873 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Inited the done directory to file:/usr/local/hadoop/logs/history/done
2016-09-08 20:39:51,873 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Job History Cleaner Thread started. MaxAge is 604800000 ms(7.0 days), Cleanup Frequency is 86400000 ms (1.0 days)
2016-09-08 20:39:51,874 WARN org.apache.hadoop.conf.Configuration: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2016-09-08 20:39:51,884 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store activated/configured with retain-time : 3600000 , job-info-dir : /jobtracker/jobsInfo
2016-09-08 20:39:51,985 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2016-09-08 20:39:51,993 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2016-09-08 20:39:51,993 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2016-09-08 20:39:51,993 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:39:51,993 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2016-09-08 20:39:51,994 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 20:39:51,994 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8021: starting
2016-09-08 20:39:51,995 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8021: starting
2016-09-08 20:39:52,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8021: starting
2016-09-08 20:39:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8021: starting
2016-09-08 20:39:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8021: starting
2016-09-08 20:39:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021: starting
2016-09-08 20:39:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8021: starting
2016-09-08 20:39:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8021: starting
2016-09-08 20:39:52,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8021: starting
2016-09-08 20:39:52,016 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8021: starting
2016-09-08 20:39:52,012 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8021: starting
2016-09-08 20:39:52,012 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2016-09-08 20:39:52,104 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave1
2016-09-08 20:39:52,105 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave1:127.0.0.1/127.0.0.1:41151 to host slave1
2016-09-08 20:39:52,111 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave5
2016-09-08 20:39:52,111 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave5:127.0.0.1/127.0.0.1:43445 to host slave5
2016-09-08 20:39:52,112 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave4
2016-09-08 20:39:52,112 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave4:127.0.0.1/127.0.0.1:44758 to host slave4
2016-09-08 20:39:52,113 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave3
2016-09-08 20:39:52,113 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave3:localhost/127.0.0.1:35677 to host slave3
2016-09-08 20:39:52,115 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/slave2
2016-09-08 20:39:52,115 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_slave2:127.0.0.1/127.0.0.1:39842 to host slave2
2016-09-08 20:41:13,325 WARN org.apache.hadoop.conf.Configuration: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2016-09-08 20:41:13,406 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609082039_0001 added successfully for user 'hduser' to queue 'default'
2016-09-08 20:41:13,407 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609082039_0001
2016-09-08 20:41:13,407 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609082039_0001
2016-09-08 20:41:13,437 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609082039_0001_hduser
2016-09-08 20:41:13,512 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609082039_0001_conf.xml
2016-09-08 20:41:13,555 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken
2016-09-08 20:41:13,565 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609082039_0001 = 10000000000. Number of splits = 38
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000000 has split on node:/default-rack/slave5
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000001 has split on node:/default-rack/slave2
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000002 has split on node:/default-rack/slave5
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000003 has split on node:/default-rack/slave1
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000004 has split on node:/default-rack/slave1
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000005 has split on node:/default-rack/slave3
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000006 has split on node:/default-rack/slave5
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000007 has split on node:/default-rack/slave3
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000008 has split on node:/default-rack/slave3
2016-09-08 20:41:13,566 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000009 has split on node:/default-rack/slave1
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000010 has split on node:/default-rack/slave3
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000011 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000012 has split on node:/default-rack/slave3
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000013 has split on node:/default-rack/slave5
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000014 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000015 has split on node:/default-rack/slave5
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000016 has split on node:/default-rack/slave2
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000017 has split on node:/default-rack/slave1
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000018 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000019 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000020 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000021 has split on node:/default-rack/slave2
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000022 has split on node:/default-rack/slave2
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000023 has split on node:/default-rack/slave2
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000024 has split on node:/default-rack/slave3
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000024 has split on node:/default-rack/slave2
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000024 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000025 has split on node:/default-rack/slave4
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000025 has split on node:/default-rack/slave2
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000025 has split on node:/default-rack/slave3
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000026 has split on node:/default-rack/slave1
2016-09-08 20:41:13,567 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000026 has split on node:/default-rack/slave2
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000026 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000027 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000027 has split on node:/default-rack/slave5
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000027 has split on node:/default-rack/slave3
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000028 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000028 has split on node:/default-rack/slave3
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000028 has split on node:/default-rack/slave1
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000029 has split on node:/default-rack/slave5
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000029 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000029 has split on node:/default-rack/slave1
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000030 has split on node:/default-rack/slave1
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000030 has split on node:/default-rack/slave2
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000030 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000031 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000031 has split on node:/default-rack/slave2
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000031 has split on node:/default-rack/slave1
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000032 has split on node:/default-rack/slave4
2016-09-08 20:41:13,568 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000032 has split on node:/default-rack/slave3
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000032 has split on node:/default-rack/slave1
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000033 has split on node:/default-rack/slave5
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000033 has split on node:/default-rack/slave4
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000033 has split on node:/default-rack/slave1
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000034 has split on node:/default-rack/slave4
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000034 has split on node:/default-rack/slave2
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000034 has split on node:/default-rack/slave1
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000035 has split on node:/default-rack/slave2
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000035 has split on node:/default-rack/slave4
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000035 has split on node:/default-rack/slave1
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000036 has split on node:/default-rack/slave1
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000037 has split on node:/default-rack/slave5
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000037 has split on node:/default-rack/slave4
2016-09-08 20:41:13,569 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0001_m_000037 has split on node:/default-rack/slave1
2016-09-08 20:41:13,570 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609082039_0001 initialized successfully with 38 map tasks and 1 reduce tasks.
2016-09-08 20:41:16,217 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609082039_0001_m_000039_0' to tip task_201609082039_0001_m_000039, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:19,251 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000039_0' has completed task_201609082039_0001_m_000039 successfully.
2016-09-08 20:41:19,272 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000003_0' to tip task_201609082039_0001_m_000003, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:19,273 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000003
2016-09-08 20:41:19,273 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000004_0' to tip task_201609082039_0001_m_000004, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:19,274 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000004
2016-09-08 20:41:19,274 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000009_0' to tip task_201609082039_0001_m_000009, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:19,274 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000009
2016-09-08 20:41:19,274 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000017_0' to tip task_201609082039_0001_m_000017, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:19,275 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000017
2016-09-08 20:41:19,275 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000026_0' to tip task_201609082039_0001_m_000026, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:19,275 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000026
2016-09-08 20:41:22,229 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000005_0' to tip task_201609082039_0001_m_000005, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000005
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000007_0' to tip task_201609082039_0001_m_000007, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000007
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000008_0' to tip task_201609082039_0001_m_000008, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000008
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000010_0' to tip task_201609082039_0001_m_000010, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000010
2016-09-08 20:41:22,230 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000012_0' to tip task_201609082039_0001_m_000012, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:22,231 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000012
2016-09-08 20:41:22,231 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000000_0' to tip task_201609082039_0001_m_000000, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:41:22,231 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000000
2016-09-08 20:41:22,231 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000002_0' to tip task_201609082039_0001_m_000002, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:41:22,231 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000002
2016-09-08 20:41:22,231 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000006_0' to tip task_201609082039_0001_m_000006, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000006
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000013_0' to tip task_201609082039_0001_m_000013, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000013
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000015_0' to tip task_201609082039_0001_m_000015, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000015
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000001_0' to tip task_201609082039_0001_m_000001, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000001
2016-09-08 20:41:22,232 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000016_0' to tip task_201609082039_0001_m_000016, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000016
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000021_0' to tip task_201609082039_0001_m_000021, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000021
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000022_0' to tip task_201609082039_0001_m_000022, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000022
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000023_0' to tip task_201609082039_0001_m_000023, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:22,233 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000023
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000011_0' to tip task_201609082039_0001_m_000011, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000011
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000014_0' to tip task_201609082039_0001_m_000014, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000014
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000018_0' to tip task_201609082039_0001_m_000018, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000018
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000019_0' to tip task_201609082039_0001_m_000019, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000019
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000020_0' to tip task_201609082039_0001_m_000020, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:41:22,235 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000020
2016-09-08 20:41:43,886 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000021_0' has completed task_201609082039_0001_m_000021 successfully.
2016-09-08 20:41:43,888 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000022_0' has completed task_201609082039_0001_m_000022 successfully.
2016-09-08 20:41:43,889 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000023_0' has completed task_201609082039_0001_m_000023 successfully.
2016-09-08 20:41:43,890 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000024_0' to tip task_201609082039_0001_m_000024, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:43,890 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000024
2016-09-08 20:41:43,890 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000025_0' to tip task_201609082039_0001_m_000025, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:43,890 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000025
2016-09-08 20:41:43,890 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000030_0' to tip task_201609082039_0001_m_000030, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:43,890 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000030
2016-09-08 20:41:43,892 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609082039_0001_r_000000_0' to tip task_201609082039_0001_r_000000, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:49,317 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000015_0' has completed task_201609082039_0001_m_000015 successfully.
2016-09-08 20:41:49,318 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000027_0' to tip task_201609082039_0001_m_000027, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:41:49,318 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000027
2016-09-08 20:41:50,758 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000016_0' has completed task_201609082039_0001_m_000016 successfully.
2016-09-08 20:41:50,765 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000031_0' to tip task_201609082039_0001_m_000031, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:50,765 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000031
2016-09-08 20:41:53,648 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000017_0' has completed task_201609082039_0001_m_000017 successfully.
2016-09-08 20:41:53,650 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000028_0' to tip task_201609082039_0001_m_000028, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:41:53,650 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000028
2016-09-08 20:41:55,027 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000010_0' has completed task_201609082039_0001_m_000010 successfully.
2016-09-08 20:41:55,028 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000012_0' has completed task_201609082039_0001_m_000012 successfully.
2016-09-08 20:41:55,029 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000032_0' to tip task_201609082039_0001_m_000032, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:55,030 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000032
2016-09-08 20:41:55,030 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000029_0' to tip task_201609082039_0001_m_000029, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:41:55,030 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0001_m_000029
2016-09-08 20:41:58,854 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000001_0' has completed task_201609082039_0001_m_000001 successfully.
2016-09-08 20:41:58,869 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000034_0' to tip task_201609082039_0001_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:41:58,870 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000034
2016-09-08 20:42:13,548 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000002_0' has completed task_201609082039_0001_m_000002 successfully.
2016-09-08 20:42:13,550 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000033_0' to tip task_201609082039_0001_m_000033, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:42:13,550 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000033
2016-09-08 20:42:14,365 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000024_0' has completed task_201609082039_0001_m_000024 successfully.
2016-09-08 20:42:14,367 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000035_0' to tip task_201609082039_0001_m_000035, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:42:14,367 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000035
2016-09-08 20:42:20,735 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000014_0' has completed task_201609082039_0001_m_000014 successfully.
2016-09-08 20:42:20,737 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000037_0' to tip task_201609082039_0001_m_000037, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:42:20,737 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000037
2016-09-08 20:42:26,702 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000004_0' has completed task_201609082039_0001_m_000004 successfully.
2016-09-08 20:42:26,704 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000036_0' to tip task_201609082039_0001_m_000036, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:42:26,704 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000036
2016-09-08 20:42:27,021 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000000_0' has completed task_201609082039_0001_m_000000 successfully.
2016-09-08 20:42:27,022 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000013_0' has completed task_201609082039_0001_m_000013 successfully.
2016-09-08 20:42:31,610 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000020_0' has completed task_201609082039_0001_m_000020 successfully.
2016-09-08 20:42:32,682 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000009_0' has completed task_201609082039_0001_m_000009 successfully.
2016-09-08 20:42:34,788 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000011_0' has completed task_201609082039_0001_m_000011 successfully.
2016-09-08 20:42:34,789 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000018_0' has completed task_201609082039_0001_m_000018 successfully.
2016-09-08 20:42:34,790 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000019_0' has completed task_201609082039_0001_m_000019 successfully.
2016-09-08 20:42:36,071 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000006_0' has completed task_201609082039_0001_m_000006 successfully.
2016-09-08 20:42:38,697 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000003_0' has completed task_201609082039_0001_m_000003 successfully.
2016-09-08 20:42:44,285 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000005_0' has completed task_201609082039_0001_m_000005 successfully.
2016-09-08 20:42:44,286 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000007_0' has completed task_201609082039_0001_m_000007 successfully.
2016-09-08 20:42:44,287 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000008_0' has completed task_201609082039_0001_m_000008 successfully.
2016-09-08 20:42:44,288 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609082039_0001_m_000030 for speculative execution
2016-09-08 20:42:44,288 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000030_1' to tip task_201609082039_0001_m_000030, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:42:44,288 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0001_m_000030
2016-09-08 20:42:44,288 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609082039_0001_r_000000 for speculative execution
2016-09-08 20:42:44,288 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609082039_0001_r_000000_1' to tip task_201609082039_0001_r_000000, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:42:44,728 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000026_0' has completed task_201609082039_0001_m_000026 successfully.
2016-09-08 20:42:46,922 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000037_0' has completed task_201609082039_0001_m_000037 successfully.
2016-09-08 20:42:48,160 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000027_0' has completed task_201609082039_0001_m_000027 successfully.
2016-09-08 20:42:55,957 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609082039_0001_m_000029 for speculative execution
2016-09-08 20:42:55,957 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000029_1' to tip task_201609082039_0001_m_000029, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:42:55,957 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000029
2016-09-08 20:42:57,433 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000028_0' has completed task_201609082039_0001_m_000028 successfully.
2016-09-08 20:42:59,448 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000025_0' has completed task_201609082039_0001_m_000025 successfully.
2016-09-08 20:42:59,450 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000031_0' has completed task_201609082039_0001_m_000031 successfully.
2016-09-08 20:43:00,217 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000033_0' has completed task_201609082039_0001_m_000033 successfully.
2016-09-08 20:43:02,015 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609082039_0001_m_000034 for speculative execution
2016-09-08 20:43:02,015 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000034_1' to tip task_201609082039_0001_m_000034, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 20:43:02,015 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000034
2016-09-08 20:43:03,232 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609082039_0001_m_000032 for speculative execution
2016-09-08 20:43:03,233 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000032_1' to tip task_201609082039_0001_m_000032, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:43:03,233 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0001_m_000032
2016-09-08 20:43:03,454 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000036_0' has completed task_201609082039_0001_m_000036 successfully.
2016-09-08 20:43:11,516 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000029_1' has completed task_201609082039_0001_m_000029 successfully.
2016-09-08 20:43:15,485 INFO org.apache.hadoop.mapred.JobInProgress: Choosing map task task_201609082039_0001_m_000035 for speculative execution
2016-09-08 20:43:15,486 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0001_m_000035_1' to tip task_201609082039_0001_m_000035, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:43:15,486 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0001_m_000035
2016-09-08 20:43:20,566 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000034_1' has completed task_201609082039_0001_m_000034 successfully.
2016-09-08 20:43:21,067 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000029_0'
2016-09-08 20:43:21,067 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609082039_0001_m_000029_0' to tip task_201609082039_0001_m_000029, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:43:25,225 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000029_0'
2016-09-08 20:43:25,696 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000034_0'
2016-09-08 20:43:25,696 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609082039_0001_m_000034_0' to tip task_201609082039_0001_m_000034, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 20:43:28,237 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000032_0' has completed task_201609082039_0001_m_000032 successfully.
2016-09-08 20:43:28,703 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000030_0' has completed task_201609082039_0001_m_000030 successfully.
2016-09-08 20:43:28,704 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000035_0' has completed task_201609082039_0001_m_000035 successfully.
2016-09-08 20:43:28,705 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000034_0'
2016-09-08 20:43:35,457 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000032_1'
2016-09-08 20:43:35,457 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609082039_0001_m_000032_1' to tip task_201609082039_0001_m_000032, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 20:43:35,539 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000035_1'
2016-09-08 20:43:35,539 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609082039_0001_m_000035_1' to tip task_201609082039_0001_m_000035, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 20:43:36,288 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000030_1'
2016-09-08 20:43:36,288 INFO org.apache.hadoop.mapred.JobTracker: Adding task (TASK_CLEANUP) 'attempt_201609082039_0001_m_000030_1' to tip task_201609082039_0001_m_000030, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 20:43:38,488 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000032_1'
2016-09-08 20:43:38,547 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000035_1'
2016-09-08 20:43:39,309 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000030_1'
2016-09-08 21:01:40,403 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_r_000000_0' has completed task_201609082039_0001_r_000000 successfully.
2016-09-08 21:01:40,405 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609082039_0001_m_000038_0' to tip task_201609082039_0001_m_000038, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:01:46,412 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0001_m_000038_0' has completed task_201609082039_0001_m_000038 successfully.
2016-09-08 21:01:46,413 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609082039_0001 has completed successfully.
2016-09-08 21:01:46,414 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609082039_0001,submitTime=1473347473288,launchTime=1473347473569,finishTime=1473348706413,numMaps=38,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=SUCCEEDED,mapSlotSeconds=2032,reduceSlotsSeconds=1193,clusterMapCapacity=25,clusterReduceCapacity=10
2016-09-08 21:01:47,394 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609082039_0001_hduser to file:/usr/local/hadoop/logs/history/done/job_201609082039_0001_hduser
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000001_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000016_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000021_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000022_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000023_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000024_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000025_0'
2016-09-08 21:01:47,398 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000030_0'
2016-09-08 21:01:47,399 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000031_0'
2016-09-08 21:01:47,399 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000035_0'
2016-09-08 21:01:47,399 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000038_0'
2016-09-08 21:01:47,399 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_r_000000_0'
2016-09-08 21:01:47,431 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609082039_0001_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609082039_0001_conf.xml
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609082039_0001_conf.xml
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000000_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000002_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000003_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000004_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000005_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000006_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000007_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000008_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000009_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000010_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000011_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000012_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000013_0'
2016-09-08 21:01:47,446 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000014_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000015_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000017_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000018_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000019_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000020_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000026_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000027_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000028_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000029_1'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000032_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000033_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000034_1'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000036_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000037_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_r_000000_1'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0001_m_000039_0'
2016-09-08 21:01:47,447 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609082039_0001' of user 'hduser'
2016-09-08 21:09:24,422 INFO org.apache.hadoop.mapred.JobTracker: Job job_201609082039_0002 added successfully for user 'hduser' to queue 'default'
2016-09-08 21:09:24,422 INFO org.apache.hadoop.mapred.JobTracker: Initializing job_201609082039_0002
2016-09-08 21:09:24,422 INFO org.apache.hadoop.mapred.JobInProgress: Initializing job_201609082039_0002
2016-09-08 21:09:24,426 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: SetupWriter, creating file file:/usr/local/hadoop/logs/history/job_201609082039_0002_hduser
2016-09-08 21:09:24,433 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: LogDirConfPath is file:/usr/local/hadoop/logs/history/job_201609082039_0002_conf.xml
2016-09-08 21:09:24,522 INFO org.apache.hadoop.mapred.JobInProgress: jobToken generated and stored with users keys in /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: Input size for job job_201609082039_0002 = 4408944001. Number of splits = 20
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000000 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000000 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000000 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000001 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000001 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000001 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000002 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000002 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000002 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000003 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000003 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000003 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000004 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000004 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000004 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000005 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000005 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000005 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000006 has split on node:/default-rack/slave1
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000006 has split on node:/default-rack/slave2
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000006 has split on node:/default-rack/slave5
2016-09-08 21:09:24,526 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000007 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000007 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000007 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000008 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000008 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000008 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000009 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000009 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000009 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000010 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000010 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000010 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000011 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000011 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000011 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000012 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000012 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000012 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000013 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000013 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000013 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000014 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000014 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000014 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000015 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000015 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000015 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000016 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000016 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000016 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000017 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000017 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000017 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000018 has split on node:/default-rack/slave1
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000018 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000018 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000019 has split on node:/default-rack/slave2
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000019 has split on node:/default-rack/slave5
2016-09-08 21:09:24,527 INFO org.apache.hadoop.mapred.JobInProgress: tip:task_201609082039_0002_m_000019 has split on node:/default-rack/slave1
2016-09-08 21:09:24,528 INFO org.apache.hadoop.mapred.JobInProgress: Job job_201609082039_0002 initialized successfully with 20 map tasks and 1 reduce tasks.
2016-09-08 21:09:24,727 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_SETUP) 'attempt_201609082039_0002_m_000021_0' to tip task_201609082039_0002_m_000021, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:09:27,733 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000021_0' has completed task_201609082039_0002_m_000021 successfully.
2016-09-08 21:09:27,735 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000000_0' to tip task_201609082039_0002_m_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:09:27,735 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000000
2016-09-08 21:09:27,735 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000001_0' to tip task_201609082039_0002_m_000001, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:09:27,735 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000001
2016-09-08 21:09:27,735 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000002_0' to tip task_201609082039_0002_m_000002, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:09:27,735 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000002
2016-09-08 21:09:27,736 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000003_0' to tip task_201609082039_0002_m_000003, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:09:27,736 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000003
2016-09-08 21:09:28,167 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000004_0' to tip task_201609082039_0002_m_000004, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000004
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000005_0' to tip task_201609082039_0002_m_000005, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000005
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000006_0' to tip task_201609082039_0002_m_000006, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000006
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000007_0' to tip task_201609082039_0002_m_000007, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:09:28,168 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000007
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000008_0' to tip task_201609082039_0002_m_000008, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000008
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000009_0' to tip task_201609082039_0002_m_000009, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000009
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000010_0' to tip task_201609082039_0002_m_000010, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000010
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000011_0' to tip task_201609082039_0002_m_000011, for tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 21:09:28,221 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000011
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000012_0' to tip task_201609082039_0002_m_000012, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000012
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000013_0' to tip task_201609082039_0002_m_000013, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000013
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000014_0' to tip task_201609082039_0002_m_000014, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000014
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000015_0' to tip task_201609082039_0002_m_000015, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:09:29,692 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000015
2016-09-08 21:09:30,321 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000016_0' to tip task_201609082039_0002_m_000016, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 21:09:30,321 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000016
2016-09-08 21:09:30,321 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000017_0' to tip task_201609082039_0002_m_000017, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 21:09:30,321 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000017
2016-09-08 21:09:30,321 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000018_0' to tip task_201609082039_0002_m_000018, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 21:09:30,321 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000018
2016-09-08 21:09:30,322 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000019_0' to tip task_201609082039_0002_m_000019, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 21:09:30,322 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000019
2016-09-08 21:09:42,335 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000016_0' has completed task_201609082039_0002_m_000016 successfully.
2016-09-08 21:09:42,336 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000017_0' has completed task_201609082039_0002_m_000017 successfully.
2016-09-08 21:09:42,337 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000018_0' has completed task_201609082039_0002_m_000018 successfully.
2016-09-08 21:09:42,337 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000019_0' has completed task_201609082039_0002_m_000019 successfully.
2016-09-08 21:09:42,339 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609082039_0002_r_000000_0' to tip task_201609082039_0002_r_000000, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 21:10:32,809 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000012_0' has completed task_201609082039_0002_m_000012 successfully.
2016-09-08 21:10:32,809 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000013_0' has completed task_201609082039_0002_m_000013 successfully.
2016-09-08 21:10:32,810 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000015_0' has completed task_201609082039_0002_m_000015 successfully.
2016-09-08 21:10:33,794 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000002_0' has completed task_201609082039_0002_m_000002 successfully.
2016-09-08 21:10:35,825 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000014_0' has completed task_201609082039_0002_m_000014 successfully.
2016-09-08 21:10:39,803 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000000_0' has completed task_201609082039_0002_m_000000 successfully.
2016-09-08 21:10:39,805 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000001_0' has completed task_201609082039_0002_m_000001 successfully.
2016-09-08 21:10:42,813 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000003_0' has completed task_201609082039_0002_m_000003 successfully.
2016-09-08 21:10:42,814 INFO org.apache.hadoop.mapred.JobInProgress: Choosing reduce task task_201609082039_0002_r_000000 for speculative execution
2016-09-08 21:10:42,814 INFO org.apache.hadoop.mapred.JobTracker: Adding task (REDUCE) 'attempt_201609082039_0002_r_000000_1' to tip task_201609082039_0002_r_000000, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:11:07,235 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000005_0' has completed task_201609082039_0002_m_000005 successfully.
2016-09-08 21:11:07,236 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000007_0' has completed task_201609082039_0002_m_000007 successfully.
2016-09-08 21:11:10,238 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000006_0' has completed task_201609082039_0002_m_000006 successfully.
2016-09-08 21:11:16,245 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000004_0' has completed task_201609082039_0002_m_000004 successfully.
2016-09-08 21:17:13,475 INFO org.apache.hadoop.mapred.JobTracker: Killing job job_201609082039_0002
2016-09-08 21:17:13,475 INFO org.apache.hadoop.mapred.JobInProgress: Killing job 'job_201609082039_0002'
2016-09-08 21:17:15,118 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609082039_0002_m_000020_0' to tip task_201609082039_0002_m_000020, for tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:17:20,738 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_r_000000_0'
2016-09-08 21:17:21,239 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_r_000000_1'
2016-09-08 21:19:51,996 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609082039_0002_m_000020_0 is 156878 ms debug.
2016-09-08 21:23:11,996 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave1:127.0.0.1/127.0.0.1:41151'
2016-09-08 21:23:11,996 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000008_0 on tracker_slave1:127.0.0.1/127.0.0.1:41151: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:41151
2016-09-08 21:23:11,996 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000009_0 on tracker_slave1:127.0.0.1/127.0.0.1:41151: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:41151
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000010_0 on tracker_slave1:127.0.0.1/127.0.0.1:41151: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:41151
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000011_0 on tracker_slave1:127.0.0.1/127.0.0.1:41151: Lost task tracker: tracker_slave1:127.0.0.1/127.0.0.1:41151
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000008_0'
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000009_0'
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000010_0'
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000011_0'
2016-09-08 21:23:11,997 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609082039_0002_m_000020_0 is 356878 ms debug.
2016-09-08 21:26:31,997 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609082039_0002_m_000020_0 is 556879 ms debug.
2016-09-08 21:29:51,997 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave2:127.0.0.1/127.0.0.1:39842'
2016-09-08 21:29:51,997 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000012_0 on tracker_slave2:127.0.0.1/127.0.0.1:39842: Lost task tracker: tracker_slave2:127.0.0.1/127.0.0.1:39842
2016-09-08 21:29:51,998 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000013_0 on tracker_slave2:127.0.0.1/127.0.0.1:39842: Lost task tracker: tracker_slave2:127.0.0.1/127.0.0.1:39842
2016-09-08 21:29:51,998 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000014_0 on tracker_slave2:127.0.0.1/127.0.0.1:39842: Lost task tracker: tracker_slave2:127.0.0.1/127.0.0.1:39842
2016-09-08 21:29:51,998 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000015_0 on tracker_slave2:127.0.0.1/127.0.0.1:39842: Lost task tracker: tracker_slave2:127.0.0.1/127.0.0.1:39842
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000020_0 on tracker_slave2:127.0.0.1/127.0.0.1:39842: Lost task tracker: tracker_slave2:127.0.0.1/127.0.0.1:39842
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000012_0'
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000013_0'
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000014_0'
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000015_0'
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000020_0'
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: attempt_201609082039_0002_m_000020_0 is 756879 ms debug.
2016-09-08 21:29:51,999 INFO org.apache.hadoop.mapred.JobTracker: Launching task attempt_201609082039_0002_m_000020_0 timed out.
2016-09-08 21:29:52,559 INFO org.apache.hadoop.mapred.JobTracker: Adding task (JOB_CLEANUP) 'attempt_201609082039_0002_m_000020_1' to tip task_201609082039_0002_m_000020, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:29:52,753 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000015_1' to tip task_201609082039_0002_m_000015, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:29:52,753 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000015
2016-09-08 21:29:52,753 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000014_1' to tip task_201609082039_0002_m_000014, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:29:52,753 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000014
2016-09-08 21:29:52,753 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000013_1' to tip task_201609082039_0002_m_000013, for tracker 'tracker_slave3:localhost/127.0.0.1:35677'
2016-09-08 21:29:52,753 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000013
2016-09-08 21:29:54,349 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000012_1' to tip task_201609082039_0002_m_000012, for tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 21:29:54,349 INFO org.apache.hadoop.mapred.JobInProgress: Choosing data-local task task_201609082039_0002_m_000012
2016-09-08 21:29:58,759 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000015_1 on tracker_slave3:localhost/127.0.0.1:35677: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
2016-09-08 21:29:58,759 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000014_1 on tracker_slave3:localhost/127.0.0.1:35677: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
2016-09-08 21:29:58,759 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000013_1 on tracker_slave3:localhost/127.0.0.1:35677: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
2016-09-08 21:30:07,764 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000013_1'
2016-09-08 21:30:07,765 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000014_1'
2016-09-08 21:30:07,765 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000015_1'
2016-09-08 21:30:08,185 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000013_2' to tip task_201609082039_0002_m_000013, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:30:08,185 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000013
2016-09-08 21:30:08,186 INFO org.apache.hadoop.mapred.JobTracker: Adding task (MAP) 'attempt_201609082039_0002_m_000014_2' to tip task_201609082039_0002_m_000014, for tracker 'tracker_slave4:127.0.0.1/127.0.0.1:44758'
2016-09-08 21:30:08,186 INFO org.apache.hadoop.mapred.JobInProgress: Choosing rack-local task task_201609082039_0002_m_000014
2016-09-08 21:30:14,192 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201609082039_0002_m_000020_1' has completed task_201609082039_0002_m_000020 successfully.
2016-09-08 21:30:14,193 INFO org.apache.hadoop.mapred.JobInProgress$JobSummary: jobId=job_201609082039_0002,submitTime=1473349164364,launchTime=1473349164527,finishTime=1473350414193,numMaps=20,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=hduser,queue=default,status=KILLED,mapSlotSeconds=4273,reduceSlotsSeconds=856,clusterMapCapacity=15,clusterReduceCapacity=6
2016-09-08 21:30:14,218 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 10.129.40.105:50010
2016-09-08 21:30:14,218 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-3645734112949878524_7068
2016-09-08 21:30:14,218 INFO org.apache.hadoop.hdfs.DFSClient: Excluding datanode 10.129.40.105:50010
2016-09-08 21:30:14,395 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609082039_0002_hduser to file:/usr/local/hadoop/logs/history/done/job_201609082039_0002_hduser
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000013_2 on tracker_slave4:127.0.0.1/127.0.0.1:44758: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201609082039_0002_m_000014_2 on tracker_slave4:127.0.0.1/127.0.0.1:44758: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000000_0'
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000001_0'
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000002_0'
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000003_0'
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000020_1'
2016-09-08 21:30:14,396 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000021_0'
2016-09-08 21:30:14,399 INFO org.apache.hadoop.mapreduce.jobhistory.JobHistory: Moving file:/usr/local/hadoop/logs/history/job_201609082039_0002_conf.xml to file:/usr/local/hadoop/logs/history/done/job_201609082039_0002_conf.xml
2016-09-08 21:30:14,406 INFO org.apache.hadoop.mapred.JobInProgress: Deleting localized job conf at /usr/local/hadoop/bin/../logs/job_201609082039_0002_conf.xml
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000004_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000005_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000006_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000007_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000012_1'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000013_2'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000014_2'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000016_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000017_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000018_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Removing task 'attempt_201609082039_0002_m_000019_0'
2016-09-08 21:30:14,407 INFO org.apache.hadoop.mapred.JobTracker: Retired job with id: 'job_201609082039_0002' of user 'hduser'
2016-09-08 21:39:52,008 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609081943_0001.info]
2016-09-08 21:43:12,000 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_slave5:127.0.0.1/127.0.0.1:43445'
2016-09-08 22:39:52,026 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609082039_0001.info]
2016-09-08 22:39:52,085 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Retiring job status from the store [hdfs://master:8020/jobtracker/jobsInfo/job_201609082039_0002.info]
