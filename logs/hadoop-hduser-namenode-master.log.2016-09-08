2016-09-08 00:22:17,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 00:27:25,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 00:27:26,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 01:11:45,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_6469556580943644020 to add as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 01:22:17,032 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 01:27:27,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 01:27:28,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 02:22:17,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 02:27:28,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 02:27:29,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 02:47:37,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_3582789123556368590 to add as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 03:22:17,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 03:27:29,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 03:27:30,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 03:54:00,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_6446045949068725457 to add as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 04:22:17,036 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 04:27:32,715 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 04:27:33,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 05:22:17,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 05:27:36,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 05:27:37,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 06:22:17,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 06:27:37,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 06:27:39,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 07:11:44,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_6469556580943644020 to add as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 07:22:17,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 07:27:39,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 07:27:40,999 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 08:22:17,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 08:27:41,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 08:27:42,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 08:47:38,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_3582789123556368590 to add as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 09:22:17,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 09:27:42,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 09:27:43,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 09:53:59,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_6446045949068725457 to add as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 10:22:17,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 10:27:44,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 10:27:45,259 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 11:22:17,041 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 11:27:45,868 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 11:27:46,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 12:22:17,042 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 12:27:47,207 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 12:27:48,004 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 13:11:45,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_6469556580943644020 to add as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 13:22:17,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 13:27:48,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 13:27:49,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 14:22:17,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 14:27:49,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 14:27:50,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 14:47:36,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_3582789123556368590 to add as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 15:22:17,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 15:27:51,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 15:27:51,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 15:54:01,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_6446045949068725457 to add as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 16:22:17,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 16:27:52,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 16:27:53,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 17:22:17,048 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 17:27:53,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 17:27:54,957 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 18:00:53,346 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 18:01:59,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/terasort-output8-block-512-slave4	dst=null	perm=null
2016-09-08 18:02:08,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/terasort-output8-block-512-slave4	dst=null	perm=null
2016-09-08 18:02:23,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/terasort-output8-block-512-slave4	dst=null	perm=null
2016-09-08 18:02:54,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 112 Total time for transactions(ms): 2Number of transactions batched in Syncs: 3 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 18:02:54,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/user/hduser/terasort-output10-block-256-slave4	dst=null	perm=null
2016-09-08 18:09:20,923 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/user/hduser/terasort-input10-block-256-slave4	dst=null	perm=null
2016-09-08 18:09:20,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:20,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:20,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:20,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:20,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:20,983 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:20,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:20,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:21,004 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:21,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 117 Total time for transactions(ms): 2Number of transactions batched in Syncs: 3 Number of syncs: 1 SyncTimes(ms): 41 
2016-09-08 18:09:21,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:21,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-output10-block-256-slave4/_partition.lst is closed by DFSClient_-1914341341
2016-09-08 18:09:21,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 18:09:21,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 18:09:21,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar. blk_-854779622135298996_7018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:09:21,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-854779622135298996_7018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-854779622135298996_7018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-854779622135298996_7018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar is closed by DFSClient_-1914341341
2016-09-08 18:09:21,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar. New replication is 10
2016-09-08 18:09:21,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=null
2016-09-08 18:09:21,642 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split. New replication is 10
2016-09-08 18:09:21,667 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:21,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split. blk_-4697796671056113312_7019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:09:21,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-4697796671056113312_7019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-4697796671056113312_7019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-4697796671056113312_7019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-4697796671056113312_7019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:09:21,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split is closed by DFSClient_-1914341341
2016-09-08 18:09:21,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.splitmetainfo. blk_-5632428859023514737_7020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 18:09:21,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-5632428859023514737_7020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 18:09:21,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-5632428859023514737_7020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 18:09:21,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-5632428859023514737_7020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 18:09:21,808 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.splitmetainfo is closed by DFSClient_-1914341341
2016-09-08 18:09:21,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:21,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml. blk_4093210132420813530_7021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 18:09:21,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_4093210132420813530_7021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:09:21,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_4093210132420813530_7021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:09:21,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_4093210132420813530_7021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:09:21,946 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml is closed by DFSClient_-1914341341
2016-09-08 18:09:21,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=null
2016-09-08 18:09:22,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 18:09:22,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 18:09:22,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/job-info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:22,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/job-info. blk_-472439537150983649_7022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 18:09:22,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-472439537150983649_7022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 18:09:22,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-472439537150983649_7022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 18:09:22,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-472439537150983649_7022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 18:09:22,038 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/job-info is closed by DFSClient_1249878598
2016-09-08 18:09:22,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:09:22,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken. blk_3342183026528330916_7023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 18:09:22,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3342183026528330916_7023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:09:22,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_3342183026528330916_7023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:09:22,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3342183026528330916_7023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:09:22,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken is closed by DFSClient_1249878598
2016-09-08 18:09:22,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.splitmetainfo	dst=null	perm=null
2016-09-08 18:09:22,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken	dst=null	perm=null
2016-09-08 18:09:22,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=null
2016-09-08 18:09:23,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=null
2016-09-08 18:09:23,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:09:26,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken	dst=null	perm=null
2016-09-08 18:09:27,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=null
2016-09-08 18:09:27,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=null
2016-09-08 18:09:27,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:09:27,687 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken	dst=null	perm=null
2016-09-08 18:09:27,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=null
2016-09-08 18:09:27,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003/jobToken	dst=null	perm=null
2016-09-08 18:09:27,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.xml	dst=null	perm=null
2016-09-08 18:09:27,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=null
2016-09-08 18:09:27,774 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.jar	dst=null	perm=null
2016-09-08 18:09:27,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:09:27,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:09:29,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,127 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:30,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:30,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:30,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:30,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:30,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:30,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,372 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,438 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:30,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:09:31,562 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:31,563 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:31,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:31,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:31,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:09:31,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:31,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:31,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,108 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:32,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:09:45,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-854779622135298996_7018 to datanode(s) 10.129.40.105:50010
2016-09-08 18:09:45,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-854779622135298996_7018 size 252064
2016-09-08 18:10:27,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:11:13,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:11:13,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:11:14,041 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:11:14,069 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:11:14,075 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:11:14,308 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:11:14,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:11:14,381 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:11:14,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:11:14,410 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:11:14,413 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:12:51,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:14:31,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:14:31,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:14:31,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:14:31,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:14:31,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003/job.split	dst=null	perm=null
2016-09-08 18:14:32,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:14:32,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:14:32,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:14:32,844 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:14:32,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:15:23,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.103:50010 10.129.40.101:50010 10.129.40.102:50010 10.129.40.105:50010 
2016-09-08 18:15:23,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.101:50010 10.129.40.103:50010 10.129.40.105:50010 10.129.40.102:50010 
2016-09-08 18:15:23,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 18:15:23,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4093210132420813530_7021 to 10.129.40.105:50010 10.129.40.102:50010 10.129.40.101:50010 
2016-09-08 18:15:23,562 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 147 Total time for transactions(ms): 3Number of transactions batched in Syncs: 3 Number of syncs: 25 SyncTimes(ms): 260 
2016-09-08 18:15:24,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_4093210132420813530_7021 blk_-854779622135298996_7018 blk_-4697796671056113312_7019
2016-09-08 18:15:24,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_4093210132420813530_7021 blk_-854779622135298996_7018 blk_-4697796671056113312_7019 blk_-5632428859023514737_7020
2016-09-08 18:15:25,415 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609062321_0003	dst=null	perm=null
2016-09-08 18:15:27,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-854779622135298996_7018 blk_-4697796671056113312_7019 blk_-5632428859023514737_7020
2016-09-08 18:15:27,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_4093210132420813530_7021 blk_-854779622135298996_7018 blk_-4697796671056113312_7019 blk_-5632428859023514737_7020
2016-09-08 18:15:28,667 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/jobtracker/jobsInfo/job_201609062321_0003.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:15:28,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609062321_0003.info. blk_4060472747029118026_7024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 18:15:29,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609062321_0003.info. blk_4133849375939199524_7024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:15:29,018 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Not able to place enough replicas, still in need of 1
2016-09-08 18:15:29,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609062321_0003.info. blk_-6632035772819917711_7024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:15:29,020 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Not able to place enough replicas, still in need of 2
2016-09-08 18:15:29,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609062321_0003.info. blk_-1080332131809226665_7024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 18:15:29,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* NameSystem.checkFileProgress: block blk_-1080332131809226665_7024{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} has not reached minimal replication 1
2016-09-08 18:15:29,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-1080332131809226665_7024{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 2832
2016-09-08 18:15:29,566 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /jobtracker/jobsInfo/job_201609062321_0003.info is closed by DFSClient_1249878598
2016-09-08 18:15:29,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.103:50010 10.129.40.102:50010 10.129.40.105:50010 
2016-09-08 18:15:29,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.105:50010 10.129.40.102:50010 10.129.40.103:50010 
2016-09-08 18:15:29,584 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609062321_0003	dst=null	perm=null
2016-09-08 18:15:30,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_-472439537150983649_7022 blk_3342183026528330916_7023
2016-09-08 18:15:30,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_-472439537150983649_7022 blk_3342183026528330916_7023
2016-09-08 18:15:31,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/jobtracker/jobsInfo/job_201609062321_0003.info	dst=null	perm=null
2016-09-08 18:15:33,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-472439537150983649_7022 blk_3342183026528330916_7023
2016-09-08 18:15:48,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-1080332131809226665_7024 to datanode(s) 10.129.40.102:50010 10.129.40.105:50010
2016-09-08 18:21:36,375 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 18:21:54,868 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 18:21:54,934 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 18:21:54,940 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 18:21:54,942 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:21:54,946 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:21:54,946 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 18:21:54,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 18:21:54,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 18:21:54,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 18:21:54,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 18:21:54,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 18:21:54,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 18:21:54,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 18:21:54,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 18:21:54,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 18:21:54,994 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:21:54,994 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 18:21:54,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 18:21:55,008 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 378
2016-09-08 18:21:55,026 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 18:21:55,026 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78967 loaded in 0 seconds.
2016-09-08 18:21:55,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 1049092 edits # 43 loaded in 0 seconds.
2016-09-08 18:21:55,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 18:21:55,088 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79090 saved in 0 seconds.
2016-09-08 18:21:55,495 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79090 saved in 0 seconds.
2016-09-08 18:21:55,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 977 msecs
2016-09-08 18:21:55,938 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 18:21:55,949 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 18:21:55,950 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:21:55,950 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 18:21:55,951 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:21:55,951 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 18:21:55,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 18:21:55,954 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1122 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
2016-09-08 18:21:55,985 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 18:21:56,006 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 18:21:56,009 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 18:21:56,010 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 18:21:56,010 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 18:21:56,010 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 18:21:56,124 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 18:21:56,369 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 18:21:56,370 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 18:21:56,371 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 18:21:56,372 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 18:21:56,372 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 18:21:56,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 18:21:56,374 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 18:21:58,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 18:21:58,197 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 18:21:58,226 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-854779622135298996_7018 on 10.129.40.102:50010 size 252064 does not belong to any file.
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.102:50010
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3342183026528330916_7023 on 10.129.40.102:50010 size 101 does not belong to any file.
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.102:50010
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5632428859023514737_7020 on 10.129.40.102:50010 size 937 does not belong to any file.
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.102:50010
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4093210132420813530_7021 on 10.129.40.102:50010 size 32919 does not belong to any file.
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4093210132420813530_7021 to 10.129.40.102:50010
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-472439537150983649_7022 on 10.129.40.102:50010 size 136 does not belong to any file.
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.102:50010
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4697796671056113312_7019 on 10.129.40.102:50010 size 6087 does not belong to any file.
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.102:50010
2016-09-08 18:21:58,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 18:21:58,684 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 18:21:58,684 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-854779622135298996_7018 on 10.129.40.103:50010 size 252064 does not belong to any file.
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.103:50010
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3342183026528330916_7023 on 10.129.40.103:50010 size 101 does not belong to any file.
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.103:50010
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-472439537150983649_7022 on 10.129.40.103:50010 size 136 does not belong to any file.
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.103:50010
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5632428859023514737_7020 on 10.129.40.103:50010 size 937 does not belong to any file.
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.103:50010
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4697796671056113312_7019 on 10.129.40.103:50010 size 6087 does not belong to any file.
2016-09-08 18:21:58,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.103:50010
2016-09-08 18:21:59,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:21:59,411 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 832 needs additional 290 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 832 needs additional 290 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:21:59,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 18:21:59,625 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 18:21:59,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3342183026528330916_7023 on 10.129.40.105:50010 size 101 does not belong to any file.
2016-09-08 18:21:59,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.105:50010
2016-09-08 18:21:59,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5632428859023514737_7020 on 10.129.40.105:50010 size 937 does not belong to any file.
2016-09-08 18:21:59,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.105:50010
2016-09-08 18:21:59,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4093210132420813530_7021 on 10.129.40.105:50010 size 32919 does not belong to any file.
2016-09-08 18:21:59,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4093210132420813530_7021 to 10.129.40.105:50010
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-854779622135298996_7018 on 10.129.40.105:50010 size 252064 does not belong to any file.
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.105:50010
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-472439537150983649_7022 on 10.129.40.105:50010 size 136 does not belong to any file.
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.105:50010
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4697796671056113312_7019 on 10.129.40.105:50010 size 6087 does not belong to any file.
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.105:50010
2016-09-08 18:21:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 18:22:09,413 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:22:09,617 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:19,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:22:19,624 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:29,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:22:29,629 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:37,723 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:256)
	at org.apache.hadoop.util.Shell.run(Shell.java:183)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:376)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:462)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:445)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:67)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:51)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:85)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:644)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:51)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4015)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:3998)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1872)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:879)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:37,725 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 18:22:39,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:22:39,631 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:49,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:22:49,635 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:57,426 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:46986: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:22:59,639 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:22:59,642 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:00,070 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:46988: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:01,518 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:46992: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:03,106 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:46996: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:06,300 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:46998: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:08,429 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47000: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:09,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:23:09,646 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:16,563 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47006: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:19,648 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:23:19,649 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:20,644 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47008: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:25,984 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47028: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:28,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 18:23:29,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:23:29,652 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:37,731 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47034: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:39,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:23:39,658 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:44,615 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47040: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:49,058 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47042: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:49,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:23:49,662 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:23:53,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/terasort-input10-block-256	dst=null	perm=null
2016-09-08 18:23:55,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/terasort-input10-block-256/_temporary	dst=null	perm=null
2016-09-08 18:23:55,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/terasort-input10-block-256/_temporary	dst=null	perm=null
2016-09-08 18:23:59,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:23:59,667 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:09,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:09,670 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:19,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:19,673 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46950: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 912 needs additional 210 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:23,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 18:24:25,288 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 18:24:25,357 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 18:24:25,362 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 18:24:25,364 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:24:25,368 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:24:25,369 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 18:24:25,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 18:24:25,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 18:24:25,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 18:24:25,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 18:24:25,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 18:24:25,388 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 18:24:25,388 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 18:24:25,388 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 18:24:25,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 18:24:25,410 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:24:25,410 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 18:24:25,411 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 18:24:25,425 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 379
2016-09-08 18:24:25,443 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 18:24:25,443 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79090 loaded in 0 seconds.
2016-09-08 18:24:25,443 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2016-09-08 18:24:25,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 63 msecs
2016-09-08 18:24:25,445 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 18:24:25,456 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 18:24:25,457 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:24:25,457 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 18:24:25,458 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 18:24:25,458 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 18:24:25,459 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 18:24:25,460 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1122 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
2016-09-08 18:24:25,481 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 18:24:25,510 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 18:24:25,514 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 18:24:25,514 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 18:24:25,514 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 18:24:25,514 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 18:24:25,629 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 18:24:25,631 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 18:24:25,631 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 18:24:25,632 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 18:24:25,632 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 18:24:25,632 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 18:24:25,633 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 18:24:25,633 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 18:24:25,637 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 18:24:25,637 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 18:24:25,637 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 18:24:25,637 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 18:24:25,637 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 18:24:25,641 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 18:24:25,642 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 18:24:27,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 18:24:27,556 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-854779622135298996_7018 on 10.129.40.102:50010 size 252064 does not belong to any file.
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3342183026528330916_7023 on 10.129.40.102:50010 size 101 does not belong to any file.
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5632428859023514737_7020 on 10.129.40.102:50010 size 937 does not belong to any file.
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4093210132420813530_7021 on 10.129.40.102:50010 size 32919 does not belong to any file.
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4093210132420813530_7021 to 10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-472439537150983649_7022 on 10.129.40.102:50010 size 136 does not belong to any file.
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4697796671056113312_7019 on 10.129.40.102:50010 size 6087 does not belong to any file.
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.102:50010
2016-09-08 18:24:27,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 18:24:27,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 18:24:27,698 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 18:24:27,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 18:24:27,705 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-854779622135298996_7018 on 10.129.40.103:50010 size 252064 does not belong to any file.
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.103:50010
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3342183026528330916_7023 on 10.129.40.103:50010 size 101 does not belong to any file.
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.103:50010
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-472439537150983649_7022 on 10.129.40.103:50010 size 136 does not belong to any file.
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.103:50010
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5632428859023514737_7020 on 10.129.40.103:50010 size 937 does not belong to any file.
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.103:50010
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4697796671056113312_7019 on 10.129.40.103:50010 size 6087 does not belong to any file.
2016-09-08 18:24:27,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.103:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3342183026528330916_7023 on 10.129.40.105:50010 size 101 does not belong to any file.
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3342183026528330916_7023 to 10.129.40.105:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5632428859023514737_7020 on 10.129.40.105:50010 size 937 does not belong to any file.
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5632428859023514737_7020 to 10.129.40.105:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4093210132420813530_7021 on 10.129.40.105:50010 size 32919 does not belong to any file.
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4093210132420813530_7021 to 10.129.40.105:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-854779622135298996_7018 on 10.129.40.105:50010 size 252064 does not belong to any file.
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-854779622135298996_7018 to 10.129.40.105:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-472439537150983649_7022 on 10.129.40.105:50010 size 136 does not belong to any file.
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-472439537150983649_7022 to 10.129.40.105:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4697796671056113312_7019 on 10.129.40.105:50010 size 6087 does not belong to any file.
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4697796671056113312_7019 to 10.129.40.105:50010
2016-09-08 18:24:27,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 18:24:28,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 18:24:28,653 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 18:24:28,670 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1122 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 18:24:28,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4060472747029118026_7024 on 10.129.40.101:50010 size 0 does not belong to any file.
2016-09-08 18:24:28,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4060472747029118026_7024 to 10.129.40.101:50010
2016-09-08 18:24:28,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-6632035772819917711_7024 on 10.129.40.101:50010 size 0 does not belong to any file.
2016-09-08 18:24:28,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6632035772819917711_7024 to 10.129.40.101:50010
2016-09-08 18:24:28,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6469556580943644020 added as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 18:24:29,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:29,682 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:47092: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 28 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:39,686 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:39,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:47092: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 18 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:47,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47108: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 11 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 11 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:48,673 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 18:24:49,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:49,697 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:47092: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:50,185 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47110: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:52,117 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47112: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 6 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 6 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:53,604 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47114: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 5 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 5 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:55,106 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/user/hduser/terasort-output10-block-256-slave4, true) from 10.129.40.100:47118: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 3 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hduser/terasort-output10-block-256-slave4. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 3 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1124
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 80
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs.
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 4 datanodes
2016-09-08 18:24:58,677 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 80 blocks
2016-09-08 18:24:59,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:59,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2058962499453093486_6996 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 18:24:59,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 18:24:59,777 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 18:24:59,785 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 18:24:59,827 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:24:59,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 18:24:59,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_141046710396074459_7025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:24:59,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_141046710396074459_7025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:24:59,917 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_141046710396074459_7025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:24:59,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_141046710396074459_7025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:24:59,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_-383799463
2016-09-08 18:24:59,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 18:25:01,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-1080332131809226665_7024 to datanode(s) 10.129.40.103:50010 10.129.40.102:50010
2016-09-08 18:25:01,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_4060472747029118026_7024 blk_-6632035772819917711_7024
2016-09-08 18:25:01,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_2058962499453093486_6996 blk_4093210132420813530_7021 blk_-472439537150983649_7022 blk_3342183026528330916_7023 blk_-854779622135298996_7018 blk_-5632428859023514737_7020 blk_-4697796671056113312_7019
2016-09-08 18:25:01,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1080332131809226665_7024 size 2832
2016-09-08 18:25:01,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1080332131809226665_7024 size 2832
2016-09-08 18:25:04,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_2058962499453093486_6996 blk_4093210132420813530_7021 blk_-472439537150983649_7022 blk_-854779622135298996_7018 blk_3342183026528330916_7023 blk_-5632428859023514737_7020 blk_-4697796671056113312_7019
2016-09-08 18:25:04,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_2058962499453093486_6996 blk_-472439537150983649_7022 blk_-854779622135298996_7018 blk_3342183026528330916_7023 blk_-5632428859023514737_7020 blk_-4697796671056113312_7019
2016-09-08 18:25:07,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/user/hduser/terasort-output10-block-256-slave4	dst=null	perm=null
2016-09-08 18:26:23,874 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/user/hduser/terasort-input10-block-256-slave4	dst=null	perm=null
2016-09-08 18:26:23,876 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:23,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:23,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,940 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 11 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 105 
2016-09-08 18:26:23,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:23,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:23,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:23,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:23,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:23,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,971 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:23,983 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:24,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-output10-block-256-slave4/_partition.lst is closed by DFSClient_296828130
2016-09-08 18:26:24,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 18:26:24,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 18:26:24,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:24,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar. blk_8720215310300598522_7027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 18:26:24,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8720215310300598522_7027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:24,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_8720215310300598522_7027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:24,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_8720215310300598522_7027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:24,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar is closed by DFSClient_296828130
2016-09-08 18:26:24,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar. New replication is 10
2016-09-08 18:26:24,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=null
2016-09-08 18:26:24,618 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:24,635 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:24,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:24,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split. New replication is 10
2016-09-08 18:26:24,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:24,656 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Not able to place enough replicas, still in need of 1
2016-09-08 18:26:24,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split. blk_1141280134524718175_7028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 18:26:24,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1141280134524718175_7028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:24,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_1141280134524718175_7028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:24,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_1141280134524718175_7028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:24,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split is closed by DFSClient_296828130
2016-09-08 18:26:24,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:24,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:24,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.splitmetainfo. blk_3063723066141312321_7029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 18:26:24,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_3063723066141312321_7029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:26:24,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3063723066141312321_7029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:26:24,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3063723066141312321_7029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:26:24,713 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.splitmetainfo is closed by DFSClient_296828130
2016-09-08 18:26:25,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:25,394 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:25,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml. blk_-419300231387879448_7030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 18:26:25,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-419300231387879448_7030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:26:25,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-419300231387879448_7030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:26:25,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-419300231387879448_7030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 18:26:25,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml is closed by DFSClient_296828130
2016-09-08 18:26:25,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=null
2016-09-08 18:26:25,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 18:26:25,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 18:26:25,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/job-info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:25,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/job-info. blk_-1758247494430403513_7031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:26:25,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1758247494430403513_7031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:26:25,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-1758247494430403513_7031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:26:25,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-1758247494430403513_7031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:26:25,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/job-info is closed by DFSClient_-383799463
2016-09-08 18:26:25,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:26:25,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken. blk_1008699130398466483_7032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 18:26:25,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1008699130398466483_7032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:25,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1008699130398466483_7032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:25,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_1008699130398466483_7032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 18:26:25,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken is closed by DFSClient_-383799463
2016-09-08 18:26:25,799 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.splitmetainfo	dst=null	perm=null
2016-09-08 18:26:27,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken	dst=null	perm=null
2016-09-08 18:26:27,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=null
2016-09-08 18:26:27,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=null
2016-09-08 18:26:27,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:26:31,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_1141280134524718175_7028 to datanode(s) 10.129.40.102:50010
2016-09-08 18:26:31,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8720215310300598522_7027 to datanode(s) 10.129.40.102:50010
2016-09-08 18:26:31,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1141280134524718175_7028 size 6087
2016-09-08 18:26:33,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken	dst=null	perm=null
2016-09-08 18:26:33,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken	dst=null	perm=null
2016-09-08 18:26:33,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=null
2016-09-08 18:26:33,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=null
2016-09-08 18:26:33,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001/jobToken	dst=null	perm=null
2016-09-08 18:26:33,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=null
2016-09-08 18:26:33,333 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=null
2016-09-08 18:26:33,350 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.xml	dst=null	perm=null
2016-09-08 18:26:33,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:26:33,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.jar	dst=null	perm=null
2016-09-08 18:26:33,393 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:26:33,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-output10-block-256-slave4/_partition.lst	dst=null	perm=null
2016-09-08 18:26:33,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_8720215310300598522_7027 size 252064
2016-09-08 18:26:33,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:33,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:33,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:34,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:34,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:34,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:34,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:34,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:34,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:34,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,559 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,691 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,706 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,803 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,838 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:26:35,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,907 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:35,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:35,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:36,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:26:36,203 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:36,410 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:36,415 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:36,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:36,441 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:36,443 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:26:36,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:27:25,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:27:36,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:27:36,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:27:36,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:36,463 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:36,518 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:36,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:37,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:27:37,868 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:37,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:50,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:27:50,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:27:50,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:27:50,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:28:03,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:28:03,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:28:04,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:28:04,426 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:28:10,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:28:10,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:28:11,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:28:11,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:28:11,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:28:11,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:29:02,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:29:03,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:29:03,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:29:03,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:29:04,999 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:05,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:05,005 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:05,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:29:05,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:05,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00001	dst=null	perm=null
2016-09-08 18:29:13,727 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:29:13,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:13,821 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:28,518 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 18:29:29,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 18:29:55,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001/job.split	dst=null	perm=null
2016-09-08 18:29:55,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:29:55,697 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256-slave4/part-m-00000	dst=null	perm=null
2016-09-08 18:30:05,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8720215310300598522_7027 to 10.129.40.105:50010 10.129.40.101:50010 10.129.40.103:50010 10.129.40.102:50010 
2016-09-08 18:30:05,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1141280134524718175_7028 to 10.129.40.105:50010 10.129.40.101:50010 10.129.40.103:50010 10.129.40.102:50010 
2016-09-08 18:30:05,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3063723066141312321_7029 to 10.129.40.105:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 18:30:05,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-419300231387879448_7030 to 10.129.40.105:50010 10.129.40.102:50010 10.129.40.101:50010 
2016-09-08 18:30:05,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 41 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 18:30:05,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081824_0001	dst=null	perm=null
2016-09-08 18:30:07,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_8720215310300598522_7027 blk_3063723066141312321_7029 blk_1141280134524718175_7028
2016-09-08 18:30:07,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_8720215310300598522_7027 blk_1141280134524718175_7028 blk_-419300231387879448_7030
2016-09-08 18:30:10,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_8720215310300598522_7027 blk_3063723066141312321_7029 blk_1141280134524718175_7028 blk_-419300231387879448_7030
2016-09-08 18:30:10,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_8720215310300598522_7027 blk_3063723066141312321_7029 blk_1141280134524718175_7028 blk_-419300231387879448_7030
2016-09-08 18:30:10,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/jobtracker/jobsInfo/job_201609081824_0001.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 18:30:10,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609081824_0001.info. blk_-424913560466712531_7033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 18:30:11,295 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Not able to place enough replicas, still in need of 1
2016-09-08 18:30:11,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609081824_0001.info. blk_7835029572861036828_7033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 18:30:11,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7835029572861036828_7033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:30:11,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7835029572861036828_7033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 18:30:11,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /jobtracker/jobsInfo/job_201609081824_0001.info is closed by DFSClient_-383799463
2016-09-08 18:30:11,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1758247494430403513_7031 to 10.129.40.101:50010 10.129.40.105:50010 10.129.40.102:50010 
2016-09-08 18:30:11,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1008699130398466483_7032 to 10.129.40.101:50010 10.129.40.102:50010 10.129.40.103:50010 
2016-09-08 18:30:11,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081824_0001	dst=null	perm=null
2016-09-08 18:30:13,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-1758247494430403513_7031 blk_1008699130398466483_7032
2016-09-08 18:30:13,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_-1758247494430403513_7031
2016-09-08 18:30:13,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/jobtracker/jobsInfo/job_201609081824_0001.info	dst=null	perm=null
2016-09-08 18:30:16,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_-1758247494430403513_7031 blk_1008699130398466483_7032
2016-09-08 18:30:16,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_1008699130398466483_7032
2016-09-08 18:30:16,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/jobtracker/jobsInfo/job_201609081824_0001.info	dst=null	perm=null
2016-09-08 18:30:19,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/jobtracker/jobsInfo/job_201609081824_0001.info	dst=null	perm=null
2016-09-08 18:30:31,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_7835029572861036828_7033 to datanode(s) 10.129.40.103:50010
2016-09-08 18:33:25,811 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 19:08:10,887 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:08:11,185 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:08:11,195 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 19:08:11,221 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:08:11,233 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:08:11,233 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:08:11,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 19:08:11,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 19:08:11,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 19:08:11,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 19:08:11,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 19:08:11,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 19:08:11,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 19:08:11,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 19:08:11,308 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 19:08:11,404 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:08:11,404 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:08:11,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 19:08:11,542 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 387
2016-09-08 19:08:11,561 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 19:08:11,562 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 80413 loaded in 0 seconds.
2016-09-08 19:08:11,591 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 1049092 edits # 6 loaded in 0 seconds.
2016-09-08 19:08:11,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 19:08:11,646 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79213 saved in 0 seconds.
2016-09-08 19:08:12,104 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79213 saved in 0 seconds.
2016-09-08 19:08:12,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1327 msecs
2016-09-08 19:08:12,595 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:08:12,624 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:08:12,625 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:08:12,625 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:08:12,626 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:08:12,626 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:08:12,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 19:08:12,641 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1123 blocks to reach the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically.
2016-09-08 19:08:12,969 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:08:13,023 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:08:13,026 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 19:08:13,027 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 19:08:13,027 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 19:08:13,027 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:08:13,331 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 19:08:13,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 19:08:13,334 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 19:08:13,335 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 19:08:13,335 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 19:08:13,335 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 19:08:13,335 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 19:08:13,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 19:08:13,925 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_8720215310300598522_7027 on 10.129.40.103:50010 size 252064 does not belong to any file.
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8720215310300598522_7027 to 10.129.40.103:50010
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_1141280134524718175_7028 on 10.129.40.103:50010 size 6087 does not belong to any file.
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1141280134524718175_7028 to 10.129.40.103:50010
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_1008699130398466483_7032 on 10.129.40.103:50010 size 101 does not belong to any file.
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1008699130398466483_7032 to 10.129.40.103:50010
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3063723066141312321_7029 on 10.129.40.103:50010 size 937 does not belong to any file.
2016-09-08 19:08:13,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3063723066141312321_7029 to 10.129.40.103:50010
2016-09-08 19:08:14,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 19:08:14,092 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_1141280134524718175_7028 on 10.129.40.105:50010 size 6087 does not belong to any file.
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1141280134524718175_7028 to 10.129.40.105:50010
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-419300231387879448_7030 on 10.129.40.105:50010 size 32919 does not belong to any file.
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-419300231387879448_7030 to 10.129.40.105:50010
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_8720215310300598522_7027 on 10.129.40.105:50010 size 252064 does not belong to any file.
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8720215310300598522_7027 to 10.129.40.105:50010
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3063723066141312321_7029 on 10.129.40.105:50010 size 937 does not belong to any file.
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3063723066141312321_7029 to 10.129.40.105:50010
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-1758247494430403513_7031 on 10.129.40.105:50010 size 136 does not belong to any file.
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1758247494430403513_7031 to 10.129.40.105:50010
2016-09-08 19:08:14,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 19:08:14,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 19:08:14,324 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 19:08:14,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:08:14,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-424913560466712531_7033 on 10.129.40.102:50010 size 0 does not belong to any file.
2016-09-08 19:08:14,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-424913560466712531_7033 to 10.129.40.102:50010
2016-09-08 19:08:14,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 19:08:14,351 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44348: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 914 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 914 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:08:14,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 19:08:14,597 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 19:08:14,613 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1123 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 19:08:14,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-424913560466712531_7033 on 10.129.40.101:50010 size 0 does not belong to any file.
2016-09-08 19:08:14,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-424913560466712531_7033 to 10.129.40.101:50010
2016-09-08 19:08:14,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6469556580943644020 added as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 19:08:24,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:08:24,359 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44348: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 20 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:08:34,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:08:34,368 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44348: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 10 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:08:34,616 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 19:08:44,373 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:08:44,376 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44348: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 0 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1125
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 80
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs.
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 4 datanodes
2016-09-08 19:08:44,619 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 80 blocks
2016-09-08 19:08:45,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_8720215310300598522_7027 blk_3063723066141312321_7029 blk_-1758247494430403513_7031 blk_1141280134524718175_7028 blk_-419300231387879448_7030
2016-09-08 19:08:45,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_-424913560466712531_7033
2016-09-08 19:08:48,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-424913560466712531_7033
2016-09-08 19:08:48,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_8720215310300598522_7027 blk_3063723066141312321_7029 blk_1008699130398466483_7032 blk_1141280134524718175_7028
2016-09-08 19:08:54,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:08:54,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_141046710396074459_7025 to 10.129.40.103:50010 10.129.40.105:50010 10.129.40.102:50010 
2016-09-08 19:08:54,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:08:54,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 19:08:54,482 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 19:08:54,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 19:08:54,615 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 19:08:54,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_2987627245914093288_7034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 19:08:54,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_141046710396074459_7025
2016-09-08 19:08:54,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_141046710396074459_7025
2016-09-08 19:08:54,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_2987627245914093288_7034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 19:08:54,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2987627245914093288_7034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 19:08:54,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2987627245914093288_7034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 19:08:54,681 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_-197443540
2016-09-08 19:08:54,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 19:08:57,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_141046710396074459_7025
2016-09-08 19:09:12,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_7835029572861036828_7033 to datanode(s) 10.129.40.103:50010
2016-09-08 19:09:14,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7835029572861036828_7033 size 3450
2016-09-08 19:13:13,673 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 19:13:14,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 19:16:32,824 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 19:16:34,487 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:16:34,552 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:16:34,558 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 19:16:34,559 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:16:34,563 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:16:34,564 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:16:34,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 19:16:34,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 19:16:34,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 19:16:34,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 19:16:34,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 19:16:34,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 19:16:34,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 19:16:34,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 19:16:34,584 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 19:16:34,602 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:16:34,602 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:16:34,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 19:16:34,617 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 380
2016-09-08 19:16:34,634 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 19:16:34,634 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79213 loaded in 0 seconds.
2016-09-08 19:16:34,635 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2016-09-08 19:16:34,636 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 60 msecs
2016-09-08 19:16:34,637 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:16:34,648 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:16:34,649 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:16:34,649 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:16:34,649 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:16:34,650 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:16:34,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 19:16:34,652 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1123 blocks to reach the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically.
2016-09-08 19:16:34,673 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:16:34,700 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:16:34,704 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 19:16:34,704 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 19:16:34,704 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 19:16:34,704 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:16:34,816 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 19:16:34,818 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 19:16:34,818 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 19:16:34,819 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 19:16:34,820 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 19:16:34,820 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 19:16:34,820 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 19:16:34,820 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 19:16:36,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 19:16:36,686 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 19:16:36,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 19:16:36,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 19:16:36,765 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 19:16:36,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 19:16:36,770 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 19:16:36,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 19:16:36,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 19:16:36,914 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 19:16:36,935 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1123 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 19:16:36,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6469556580943644020 added as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 19:16:38,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:16:38,757 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44472: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 28 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:16:48,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:16:48,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44472: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 18 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:16:56,939 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 19:16:58,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:16:58,769 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44472: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 8 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1125 has reached the threshold 0.9990 of total blocks 1125. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1125
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 79
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 4 datanodes
2016-09-08 19:17:06,941 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 79 blocks
2016-09-08 19:17:08,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:17:08,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2987627245914093288_7034 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 19:17:08,844 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:17:08,864 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 19:17:08,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 19:17:08,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 19:17:08,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 19:17:08,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_7092443378295069131_7035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 19:17:09,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_7092443378295069131_7035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 19:17:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7092443378295069131_7035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 19:17:09,033 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7092443378295069131_7035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 19:17:09,035 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_-1592333198
2016-09-08 19:17:09,048 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 19:17:09,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1080332131809226665_7024 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 19:17:09,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/jobtracker/jobsInfo/job_201609062321_0003.info	dst=null	perm=null
2016-09-08 19:17:10,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-1080332131809226665_7024 blk_2987627245914093288_7034
2016-09-08 19:17:10,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-1080332131809226665_7024 blk_2987627245914093288_7034
2016-09-08 19:17:13,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_-1080332131809226665_7024 blk_2987627245914093288_7034
2016-09-08 19:21:37,597 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 19:21:38,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 19:23:48,530 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 19:23:50,325 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:23:50,389 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:23:50,395 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 19:23:50,396 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:23:50,400 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:23:50,401 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:23:50,417 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 19:23:50,417 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 19:23:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 19:23:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 19:23:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 19:23:50,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 19:23:50,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 19:23:50,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 19:23:50,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 19:23:50,439 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:23:50,440 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:23:50,441 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 19:23:50,454 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 379
2016-09-08 19:23:50,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 19:23:50,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79090 loaded in 0 seconds.
2016-09-08 19:23:50,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2016-09-08 19:23:50,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 59 msecs
2016-09-08 19:23:50,474 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:23:50,485 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:23:50,486 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:23:50,486 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:23:50,487 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:23:50,487 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:23:50,488 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 19:23:50,489 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1122 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
2016-09-08 19:23:50,626 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:23:50,655 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:23:50,658 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 19:23:50,658 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 19:23:50,658 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 19:23:50,658 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:23:50,769 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 19:23:50,771 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 19:23:50,771 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:23:50,771 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 19:23:50,772 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 19:23:50,774 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 19:23:50,774 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 19:23:50,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 19:23:52,237 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Error report from slave4:50010: Incompatible build versions: namenode BV = 985326; datanode BV = Unknown
2016-09-08 19:23:52,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 19:23:52,480 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 19:23:52,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 19:23:52,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 19:23:52,610 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 19:23:52,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 19:23:52,611 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 19:23:52,632 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 19:23:52,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 19:23:52,653 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 19:23:52,669 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1122 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 19:23:52,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6469556580943644020 added as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 19:23:54,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:23:54,833 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44670: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 27 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 27 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:24:04,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:24:04,840 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44670: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 17 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 17 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:24:12,677 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 19:24:14,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:24:14,849 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:44670: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 7 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 7 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:24:22,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1124
2016-09-08 19:24:22,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 19:24:22,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 79
2016-09-08 19:24:22,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 19:24:22,683 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2016-09-08 19:24:22,683 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 19:24:22,683 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 4 datanodes
2016-09-08 19:24:22,683 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 79 blocks
2016-09-08 19:24:24,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:24:24,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7092443378295069131_7035 to 10.129.40.103:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 19:24:24,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:24:24,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 19:24:24,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 19:24:24,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 19:24:25,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 19:24:25,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_-3310674972921147034_7036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 19:24:25,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-3310674972921147034_7036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 19:24:25,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-3310674972921147034_7036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 19:24:25,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3310674972921147034_7036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 19:24:25,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_1781790744
2016-09-08 19:24:25,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 19:24:26,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_7092443378295069131_7035
2016-09-08 19:24:26,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_7092443378295069131_7035
2016-09-08 19:24:29,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_7092443378295069131_7035
2016-09-08 19:28:53,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 19:28:54,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 19:43:52,764 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 19:43:54,404 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 19:43:54,471 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 19:43:54,477 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 19:43:54,478 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:43:54,482 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:43:54,483 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:43:54,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 19:43:54,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 19:43:54,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 19:43:54,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 19:43:54,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 19:43:54,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 19:43:54,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 19:43:54,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 19:43:54,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 19:43:54,522 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:43:54,523 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 19:43:54,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 19:43:54,537 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 379
2016-09-08 19:43:54,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 19:43:54,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 79090 loaded in 0 seconds.
2016-09-08 19:43:54,555 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2016-09-08 19:43:54,556 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 60 msecs
2016-09-08 19:43:54,557 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 19:43:54,568 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 19:43:54,569 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:43:54,570 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:43:54,570 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 19:43:54,571 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 19:43:54,572 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 19:43:54,573 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1122 blocks to reach the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically.
2016-09-08 19:43:54,614 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 19:43:54,642 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 19:43:54,645 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 19:43:54,646 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 19:43:54,646 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 19:43:54,646 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 19:43:54,756 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 19:43:54,758 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 19:43:54,758 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 19:43:54,759 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 19:43:54,759 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 19:43:54,759 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 19:43:54,759 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 19:43:54,759 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 19:43:54,760 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 19:43:54,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 19:43:54,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 19:43:54,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 19:43:54,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 19:43:54,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 19:43:54,761 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 19:43:56,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 19:43:56,718 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 19:43:56,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 19:43:56,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 19:43:56,754 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 19:43:56,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 19:43:56,781 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 19:43:56,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 19:43:56,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 19:43:56,921 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 19:43:56,942 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1122 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 19:43:56,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6469556580943644020 added as corrupt on 10.129.40.101:50010 by /10.129.40.101
2016-09-08 19:43:57,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.104:50010 storage DS-649323290-10.129.40.104-50010-1473344014446
2016-09-08 19:43:57,016 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.104:50010
2016-09-08 19:43:58,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:43:58,673 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:45084: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 28 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:44:08,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:44:08,677 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:45084: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 18 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:44:16,944 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 19:44:18,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:44:18,681 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:45084: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1124 has reached the threshold 0.9990 of total blocks 1124. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 19:44:26,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1124
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 79
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 5 datanodes
2016-09-08 19:44:26,948 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 79 blocks
2016-09-08 19:44:27,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-9097561235354221905_6290 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-8881363881470423003_6002 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-8853040512501042524_6483 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-8635389947343360234_6281 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-8367831200796608863_5951 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-8357001959628127589_6244 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7997696844924715584_6228 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:27,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7598611821302873381_6476 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:28,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:44:28,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-3310674972921147034_7036 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 19:44:28,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 19:44:28,779 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 19:44:28,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 19:44:28,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 19:44:28,837 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 19:44:28,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_5604019001368321631_7037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 19:44:28,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_5604019001368321631_7037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 19:44:28,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5604019001368321631_7037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 19:44:28,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_5604019001368321631_7037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 19:44:28,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_-497673382
2016-09-08 19:44:28,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 19:44:28,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7835029572861036828_7033 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 19:44:28,945 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/jobtracker/jobsInfo/job_201609081824_0001.info	dst=null	perm=null
2016-09-08 19:44:29,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7997696844924715584_6228 size 5821
2016-09-08 19:44:29,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7598611821302873381_6476 size 177
2016-09-08 19:44:29,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8367831200796608863_5951 size 252064
2016-09-08 19:44:29,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8357001959628127589_6244 size 252064
2016-09-08 19:44:29,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8853040512501042524_6483 size 177
2016-09-08 19:44:29,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8881363881470423003_6002 size 252064
2016-09-08 19:44:29,984 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-9097561235354221905_6290 size 5821
2016-09-08 19:44:30,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8635389947343360234_6281 size 252064
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-7407688967107874754_5945 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-7041130020812565006_6859 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-6243436621843352462_6461 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-6023631287331448880_6373 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-5996134937179890859_5995 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-5251289713081026867_6860 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-4963608668193684323_6356 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-4848730059915213934_6253 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:30,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_7835029572861036828_7033 blk_-3310674972921147034_7036
2016-09-08 19:44:30,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_7835029572861036828_7033 blk_-3310674972921147034_7036
2016-09-08 19:44:32,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6023631287331448880_6373 size 5821
2016-09-08 19:44:32,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6243436621843352462_6461 size 252064
2016-09-08 19:44:32,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5251289713081026867_6860 size 2189
2016-09-08 19:44:32,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5996134937179890859_5995 size 252064
2016-09-08 19:44:32,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4848730059915213934_6253 size 5821
2016-09-08 19:44:32,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4963608668193684323_6356 size 252064
2016-09-08 19:44:32,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7407688967107874754_5945 size 252064
2016-09-08 19:44:32,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7041130020812565006_6859 size 252064
2016-09-08 19:44:33,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-3883779056475645016_6003 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-3824549329037276213_6235 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-3729013296423414375_6424 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-3484606428611463465_6227 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-3468446602291020688_6322 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-3347256216850133923_6446 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-3072301765576673058_6127 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-2753838972754665340_6321 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:33,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_7835029572861036828_7033 blk_-3310674972921147034_7036
2016-09-08 19:44:35,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3468446602291020688_6322 size 5821
2016-09-08 19:44:35,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3347256216850133923_6446 size 177
2016-09-08 19:44:35,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3729013296423414375_6424 size 252064
2016-09-08 19:44:35,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3484606428611463465_6227 size 252064
2016-09-08 19:44:35,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3072301765576673058_6127 size 2263
2016-09-08 19:44:35,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2753838972754665340_6321 size 252064
2016-09-08 19:44:35,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3883779056475645016_6003 size 2263
2016-09-08 19:44:35,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3824549329037276213_6235 size 252064
2016-09-08 19:44:36,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-1353200741452399761_6153 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-1288125119361781099_6089 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-809237844520416912_5946 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-341396596278644703_6090 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_60013184392359448_6313 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_76395164908704071_6742 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_271094087384732306_6135 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:36,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_648655787436488786_6462 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:38,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-341396596278644703_6090 size 2263
2016-09-08 19:44:38,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_648655787436488786_6462 size 177
2016-09-08 19:44:38,786 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-809237844520416912_5946 size 174
2016-09-08 19:44:38,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_271094087384732306_6135 size 2263
2016-09-08 19:44:38,836 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_60013184392359448_6313 size 252064
2016-09-08 19:44:38,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_76395164908704071_6742 size 252064
2016-09-08 19:44:38,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1288125119361781099_6089 size 252064
2016-09-08 19:44:38,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1353200741452399761_6153 size 252064
2016-09-08 19:44:39,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1444884480740410188_6305 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_1621907520522176989_6381 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1818548078702013058_6416 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_1881596984641602353_6306 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_2073204045538803299_6134 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_2100594473583440428_6340 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_2250098932879641111_6468 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:39,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_2261864914278691377_6445 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:41,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2100594473583440428_6340 size 5821
2016-09-08 19:44:41,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1444884480740410188_6305 size 252064
2016-09-08 19:44:41,810 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1818548078702013058_6416 size 252064
2016-09-08 19:44:41,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2261864914278691377_6445 size 252064
2016-09-08 19:44:41,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1881596984641602353_6306 size 5821
2016-09-08 19:44:41,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2250098932879641111_6468 size 252064
2016-09-08 19:44:41,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1621907520522176989_6381 size 5821
2016-09-08 19:44:41,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2073204045538803299_6134 size 252064
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_2859400740115653019_5960 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3328460729405028322_6289 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_3478697329295800387_6372 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_3704037346089368518_6475 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3743191588682154449_6489 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_3970955442791165187_6236 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_4125805381391941904_6245 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_4341216616064218318_6440 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:44,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2859400740115653019_5960 size 174
2016-09-08 19:44:44,799 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3478697329295800387_6372 size 252064
2016-09-08 19:44:44,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4125805381391941904_6245 size 5821
2016-09-08 19:44:44,811 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4341216616064218318_6440 size 6087
2016-09-08 19:44:44,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3328460729405028322_6289 size 252064
2016-09-08 19:44:44,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3743191588682154449_6489 size 252064
2016-09-08 19:44:44,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3970955442791165187_6236 size 5821
2016-09-08 19:44:44,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3704037346089368518_6475 size 252064
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_4939356907239172894_6409 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_4948119379460479273_6454 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_5315638885327285947_6314 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_5315891646608458033_6357 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_5439833312850407934_6433 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_5528743357897760760_6252 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_5882851345851902129_6126 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:45,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_6280989057441654927_5959 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:47,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5439833312850407934_6433 size 6087
2016-09-08 19:44:47,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5315891646608458033_6357 size 5821
2016-09-08 19:44:47,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5528743357897760760_6252 size 252064
2016-09-08 19:44:47,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6280989057441654927_5959 size 252064
2016-09-08 19:44:47,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5315638885327285947_6314 size 5821
2016-09-08 19:44:47,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5882851345851902129_6126 size 252064
2016-09-08 19:44:47,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4939356907239172894_6409 size 6087
2016-09-08 19:44:47,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4948119379460479273_6454 size 252064
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_7050250981320368658_6882 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7461260106836410168_6469 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_7656856767336545188_6298 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7769590168585592997_6883 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_7961384300838747185_6154 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8133251181700593284_6364 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8459696083325972834_5952 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:48,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_8855446708620756060_6482 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:50,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7961384300838747185_6154 size 2263
2016-09-08 19:44:50,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8855446708620756060_6482 size 252064
2016-09-08 19:44:50,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8459696083325972834_5952 size 174
2016-09-08 19:44:50,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8133251181700593284_6364 size 252064
2016-09-08 19:44:50,827 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7461260106836410168_6469 size 177
2016-09-08 19:44:50,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7769590168585592997_6883 size 2189
2016-09-08 19:44:50,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7656856767336545188_6298 size 5821
2016-09-08 19:44:50,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7050250981320368658_6882 size 252064
2016-09-08 19:44:51,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7531231873818743767_6339 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:51,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-7426451902933435557_5996 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:53,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7426451902933435557_5996 size 2263
2016-09-08 19:44:53,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7531231873818743767_6339 size 252064
2016-09-08 19:44:54,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-4831509776643701597_6425 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:54,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-4386889299840198939_6408 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:56,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4386889299840198939_6408 size 252064
2016-09-08 19:44:56,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4831509776643701597_6425 size 6087
2016-09-08 19:44:57,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-2233214403132856734_6401 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:57,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1861527583357003902_6417 to datanode(s) 10.129.40.104:50010
2016-09-08 19:44:59,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1861527583357003902_6417 size 6087
2016-09-08 19:44:59,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2233214403132856734_6401 size 6087
2016-09-08 19:45:00,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_1002240884644888727_6432 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:00,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_1304101234548046845_6282 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:02,951 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1304101234548046845_6282 size 5821
2016-09-08 19:45:02,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1002240884644888727_6432 size 252064
2016-09-08 19:45:03,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_2303545871609246931_6365 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:03,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_2420664165395734975_6490 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:05,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2303545871609246931_6365 size 5821
2016-09-08 19:45:05,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2420664165395734975_6490 size 177
2016-09-08 19:45:06,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_4703678329799447027_6380 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:06,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4705349530728297515_6439 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:08,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4705349530728297515_6439 size 252064
2016-09-08 19:45:08,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4703678329799447027_6380 size 252064
2016-09-08 19:45:09,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_6479755792339953529_6297 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:09,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_6539416572888322796_6455 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:11,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6479755792339953529_6297 size 252064
2016-09-08 19:45:11,836 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6539416572888322796_6455 size 177
2016-09-08 19:45:12,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_9115373919972199236_6400 to datanode(s) 10.129.40.104:50010
2016-09-08 19:45:14,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_9115373919972199236_6400 size 252064
2016-09-08 19:48:57,524 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 19:48:58,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 20:09:24,640 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:256)
	at org.apache.hadoop.util.Shell.run(Shell.java:183)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:376)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:462)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:445)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:67)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:51)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:85)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:644)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:51)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4015)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:3998)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1872)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:879)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:09:24,642 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/	dst=null	perm=null
2016-09-08 20:09:27,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user	dst=null	perm=null
2016-09-08 20:09:28,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 20:11:02,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.103	cmd=listStatus	src=/	dst=null	perm=null
2016-09-08 20:11:03,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.103	cmd=listStatus	src=/user	dst=null	perm=null
2016-09-08 20:11:04,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.103	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2129962630025487025_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7068577366240643902_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8273978501660968255_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2249913677212626283_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6023099268842287765_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2748044179468581342_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7179481969377792504_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-9054267527339705252_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6469556580943644020_6214 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1279310241871777830_6213 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6858777436394193526_6214 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6281029731741859686_6215 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8920626010216439155_6210 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4542139590581227092_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-394307619362869936_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6216899188218369896_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-9204418001477390404_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8483071886759191090_6211 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4019804386398161410_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6597452411844088804_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-716234947049934802_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_5993794840825696383_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_5363980500927141555_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2103927701132621350_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-496109828003111667_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5000613135040271552_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-394817554824382468_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7007256463116289844_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6759674512796134279_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3160273922543799092_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_5931887554275877986_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7627754162761517702_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-3046548857918990565_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-3367300038576472709_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4351053347055434443_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3809921994203155921_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_9061234243965306964_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6639554137002357518_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4449239514817811991_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_8774553128293905645_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5212475441145450267_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4389610006365857655_6211 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-85025763549509526_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1576031082943290210_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4389766038365224677_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6656349926929696597_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4225675376522089180_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7307509065045929581_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1445623918921717660_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2090067630488859067_6212 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:11:44,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 9 Total time for transactions(ms): 1Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 20:11:44,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/user/hduser/terasort-input10-block-256	dst=null	perm=null
2016-09-08 20:11:45,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_2090067630488859067_6212 blk_2129962630025487025_6212 blk_-3046548857918990565_6211 blk_5993794840825696383_6212 blk_-7179481969377792504_6212 blk_2103927701132621350_6212 blk_4225675376522089180_6212 blk_-6759674512796134279_6212 blk_1576031082943290210_6212 blk_-6023099268842287765_6212 blk_6656349926929696597_6212 blk_-8920626010216439155_6210 blk_3160273922543799092_6212 blk_-9054267527339705252_6212 blk_-4389766038365224677_6212 blk_-7068577366240643902_6212 blk_2748044179468581342_6212 blk_-6281029731741859686_6215 blk_7007256463116289844_6212 blk_-4449239514817811991_6211 blk_-3367300038576472709_6211 blk_6469556580943644020_6214 blk_-394307619362869936_6211 blk_3809921994203155921_6211 blk_-7307509065045929581_6212 blk_-5000613135040271552_6212 blk_8273978501660968255_6212 blk_-7627754162761517702_6211 blk_9061234243965306964_6211 blk_-1279310241871777830_6213 blk_-2249913677212626283_6212 blk_5931887554275877986_6212 blk_-4019804386398161410_6211 blk_-6858777436394193526_6214 blk_6216899188218369896_6211 blk_-4351053347055434443_6211 blk_-9204418001477390404_6211 blk_-85025763549509526_6212 blk_-716234947049934802_6211 blk_-394817554824382468_6212 blk_-496109828003111667_6212 blk_-6639554137002357518_6211 blk_-4542139590581227092_6211 blk_6597452411844088804_6211 blk_-5212475441145450267_6211 blk_5363980500927141555_6212 blk_-4389610006365857655_6211 blk_1445623918921717660_6212 blk_8774553128293905645_6211
2016-09-08 20:11:45,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_2090067630488859067_6212 blk_2129962630025487025_6212 blk_8483071886759191090_6211 blk_-3046548857918990565_6211 blk_5993794840825696383_6212 blk_-7179481969377792504_6212 blk_2103927701132621350_6212 blk_4225675376522089180_6212 blk_-6759674512796134279_6212 blk_1576031082943290210_6212 blk_-6023099268842287765_6212 blk_6656349926929696597_6212 blk_-8920626010216439155_6210 blk_3160273922543799092_6212 blk_-9054267527339705252_6212 blk_-4389766038365224677_6212 blk_-7068577366240643902_6212 blk_2748044179468581342_6212 blk_-6281029731741859686_6215 blk_7007256463116289844_6212 blk_-4449239514817811991_6211 blk_-3367300038576472709_6211 blk_6469556580943644020_6214 blk_-394307619362869936_6211 blk_3809921994203155921_6211 blk_-7307509065045929581_6212 blk_-5000613135040271552_6212 blk_8273978501660968255_6212 blk_-7627754162761517702_6211 blk_9061234243965306964_6211 blk_-1279310241871777830_6213 blk_-2249913677212626283_6212 blk_5931887554275877986_6212 blk_-4019804386398161410_6211 blk_-6858777436394193526_6214 blk_6216899188218369896_6211 blk_-4351053347055434443_6211 blk_-9204418001477390404_6211 blk_-85025763549509526_6212 blk_-716234947049934802_6211 blk_-394817554824382468_6212 blk_-496109828003111667_6212 blk_-6639554137002357518_6211 blk_-4542139590581227092_6211 blk_6597452411844088804_6211 blk_-5212475441145450267_6211 blk_5363980500927141555_6212 blk_-4389610006365857655_6211 blk_1445623918921717660_6212 blk_8774553128293905645_6211
2016-09-08 20:11:48,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_8483071886759191090_6211 blk_6469556580943644020_6214
2016-09-08 20:11:48,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_2090067630488859067_6212 blk_2129962630025487025_6212 blk_8483071886759191090_6211 blk_-3046548857918990565_6211 blk_5993794840825696383_6212 blk_-7179481969377792504_6212 blk_2103927701132621350_6212 blk_4225675376522089180_6212 blk_-6759674512796134279_6212 blk_1576031082943290210_6212 blk_-6023099268842287765_6212 blk_6656349926929696597_6212 blk_-8920626010216439155_6210 blk_3160273922543799092_6212 blk_-9054267527339705252_6212 blk_-4389766038365224677_6212 blk_-7068577366240643902_6212 blk_2748044179468581342_6212 blk_-6281029731741859686_6215 blk_7007256463116289844_6212 blk_-4449239514817811991_6211 blk_-3367300038576472709_6211 blk_6469556580943644020_6214 blk_-394307619362869936_6211 blk_3809921994203155921_6211 blk_-7307509065045929581_6212 blk_-5000613135040271552_6212 blk_8273978501660968255_6212 blk_-7627754162761517702_6211 blk_9061234243965306964_6211 blk_-1279310241871777830_6213 blk_-2249913677212626283_6212 blk_5931887554275877986_6212 blk_-4019804386398161410_6211 blk_-6858777436394193526_6214 blk_6216899188218369896_6211 blk_-4351053347055434443_6211 blk_-9204418001477390404_6211 blk_-85025763549509526_6212 blk_-716234947049934802_6211 blk_-394817554824382468_6212 blk_-496109828003111667_6212 blk_-6639554137002357518_6211 blk_-4542139590581227092_6211 blk_6597452411844088804_6211 blk_-5212475441145450267_6211 blk_5363980500927141555_6212 blk_-4389610006365857655_6211 blk_1445623918921717660_6212 blk_8774553128293905645_6211
2016-09-08 20:11:48,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:11:48,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 20:11:48,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:48,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar. blk_-8640492215143176732_7038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:11:48,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8640492215143176732_7038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:11:48,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-8640492215143176732_7038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:11:48,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-8640492215143176732_7038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:11:48,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar is closed by DFSClient_-728283151
2016-09-08 20:11:48,981 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar. New replication is 10
2016-09-08 20:11:48,988 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=null
2016-09-08 20:11:48,997 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split. New replication is 10
2016-09-08 20:11:49,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=null
2016-09-08 20:11:49,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split. blk_4982031477067310394_7039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:11:49,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_4982031477067310394_7039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:11:49,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_4982031477067310394_7039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:11:49,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4982031477067310394_7039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:11:49,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4982031477067310394_7039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:11:49,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_4982031477067310394_7039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:11:49,121 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split is closed by DFSClient_-728283151
2016-09-08 20:11:49,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,155 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.splitmetainfo. blk_-5873986092320996970_7040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:11:49,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-5873986092320996970_7040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:11:49,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-5873986092320996970_7040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:11:49,173 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5873986092320996970_7040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:11:49,174 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.splitmetainfo is closed by DFSClient_-728283151
2016-09-08 20:11:49,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml. blk_-2966897432883187622_7041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:11:49,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2966897432883187622_7041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:11:49,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-2966897432883187622_7041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:11:49,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-2966897432883187622_7041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:11:49,372 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml is closed by DFSClient_-728283151
2016-09-08 20:11:49,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=null
2016-09-08 20:11:49,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:11:49,438 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 20:11:49,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/job-info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,448 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/job-info. blk_-7364540058221320483_7042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:11:49,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-7364540058221320483_7042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:11:49,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7364540058221320483_7042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:11:49,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7364540058221320483_7042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:11:49,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/job-info is closed by DFSClient_-497673382
2016-09-08 20:11:49,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:49,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken. blk_-7757860014277293192_7043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:11:49,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-7757860014277293192_7043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:11:49,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-7757860014277293192_7043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:11:49,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7757860014277293192_7043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:11:49,674 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken is closed by DFSClient_-497673382
2016-09-08 20:11:49,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.splitmetainfo	dst=null	perm=null
2016-09-08 20:11:51,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken	dst=null	perm=null
2016-09-08 20:11:51,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=null
2016-09-08 20:11:51,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=null
2016-09-08 20:11:54,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken	dst=null	perm=null
2016-09-08 20:11:54,374 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=null
2016-09-08 20:11:54,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=null
2016-09-08 20:11:54,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=null
2016-09-08 20:11:55,007 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=create	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:55,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-2638873799979083046_7044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:11:55,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=null
2016-09-08 20:11:55,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=create	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:11:55,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_5037708392074113714_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:12:06,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-8640492215143176732_7038 to datanode(s) 10.129.40.105:50010 10.129.40.101:50010
2016-09-08 20:12:09,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-8640492215143176732_7038 size 252064
2016-09-08 20:12:10,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-8640492215143176732_7038 size 252064
2016-09-08 20:12:40,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2638873799979083046_7044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:40,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-2638873799979083046_7044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:40,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-2638873799979083046_7044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:40,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-4344984032049022173_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:12:42,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_5037708392074113714_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:12:42,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_5037708392074113714_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:12:42,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5037708392074113714_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:12:42,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_4892949802124987058_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:12:44,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4344984032049022173_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:44,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-4344984032049022173_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:44,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-4344984032049022173_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:44,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_6010882235441704063_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:12:48,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6010882235441704063_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:12:48,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6010882235441704063_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:12:48,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_6010882235441704063_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:12:48,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-6442747747966765298_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:12:52,416 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6442747747966765298_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:52,417 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-6442747747966765298_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:52,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-6442747747966765298_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:52,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-114566830199377427_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:12:54,791 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken	dst=null	perm=null
2016-09-08 20:12:54,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=null
2016-09-08 20:12:54,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=null
2016-09-08 20:12:57,488 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=null
2016-09-08 20:12:57,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 48 Total time for transactions(ms): 2Number of transactions batched in Syncs: 0 Number of syncs: 25 SyncTimes(ms): 283 
2016-09-08 20:12:57,519 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=create	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:12:57,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_1248496670862471921_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:12:57,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-114566830199377427_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:57,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-114566830199377427_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:57,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-114566830199377427_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:12:57,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-2003987820136452117_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:13:05,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_1248496670862471921_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:13:05,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1248496670862471921_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:13:05,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1248496670862471921_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:13:05,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_1208860333276073979_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:13:06,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001/jobToken	dst=null	perm=null
2016-09-08 20:13:07,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.xml	dst=null	perm=null
2016-09-08 20:13:07,085 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.jar	dst=null	perm=null
2016-09-08 20:13:07,844 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001/job.split	dst=null	perm=null
2016-09-08 20:13:07,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=create	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:13:07,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-4812638991963349004_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:13:09,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4892949802124987058_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:13:09,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_4892949802124987058_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:13:09,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_4892949802124987058_7045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:13:09,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_6044842858111680358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:13:15,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-4812638991963349004_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:13:16,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-4812638991963349004_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:13:16,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-4812638991963349004_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:13:16,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_6574230813210458185_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:13:30,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-2003987820136452117_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:13:30,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2003987820136452117_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:13:30,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-2003987820136452117_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:13:30,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-7797740609333622423_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:13:37,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7797740609333622423_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:13:37,860 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-7797740609333622423_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:13:37,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-7797740609333622423_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:13:37,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-8288419010529555468_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:13:44,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-8288419010529555468_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:13:44,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8288419010529555468_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:13:44,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-8288419010529555468_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:13:44,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-7292616938307414304_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:13:47,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6044842858111680358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:13:47,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_6044842858111680358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:13:47,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6044842858111680358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:13:47,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_-6899691694244829431_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:14:34,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6574230813210458185_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:34,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6574230813210458185_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:34,259 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6574230813210458185_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:34,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_5622311596479082796_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:14:38,065 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5622311596479082796_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:38,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_5622311596479082796_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:38,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_5622311596479082796_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:38,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-2674760384415208657_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:14:42,877 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2674760384415208657_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:42,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-2674760384415208657_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:42,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2674760384415208657_7047 size 268435456
2016-09-08 20:14:42,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-2154913573980251049_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:14:48,129 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-6899691694244829431_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:14:48,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6899691694244829431_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:14:48,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-6899691694244829431_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:14:48,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_-6991640690675716002_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:14:48,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2154913573980251049_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:48,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-2154913573980251049_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:48,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2154913573980251049_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:14:48,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-1553262788602843268_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:15:14,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1208860333276073979_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:15:14,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1208860333276073979_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:15:14,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1208860333276073979_7046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:15:14,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_-6048042576338080279_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:15:28,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6991640690675716002_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:15:28,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-6991640690675716002_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:15:28,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-6991640690675716002_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:15:28,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_-2444506035184283803_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:15:31,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1553262788602843268_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:15:31,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-1553262788602843268_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:15:31,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1553262788602843268_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:15:31,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_113126663445573567_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:15:31,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6048042576338080279_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:15:31,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-6048042576338080279_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:15:31,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6048042576338080279_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:15:31,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_1438702212370444149_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:16:00,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7292616938307414304_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:16:00,936 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-7292616938307414304_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:16:00,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-7292616938307414304_7047 size 268435456
2016-09-08 20:16:00,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_6381903812236893165_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:16:19,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_113126663445573567_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:16:19,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_113126663445573567_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:16:19,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_113126663445573567_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:16:19,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_7495514232846220488_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:16:22,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_6381903812236893165_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:16:22,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6381903812236893165_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:16:22,984 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_6381903812236893165_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:16:22,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_6442040225374702694_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:16:33,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1438702212370444149_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:16:33,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_1438702212370444149_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:16:33,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1438702212370444149_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:16:33,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_7961540047632521112_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:16:44,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2444506035184283803_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:16:44,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2444506035184283803_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:16:44,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-2444506035184283803_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:16:44,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_-8278117438479269626_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:17:31,429 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7961540047632521112_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:17:31,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7961540047632521112_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:17:31,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7961540047632521112_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:17:31,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_-3854331504842359070_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:17:35,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7495514232846220488_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:17:35,568 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7495514232846220488_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:17:35,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7495514232846220488_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:17:35,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_6445579512898956756_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:17:35,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-3854331504842359070_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:17:35,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-3854331504842359070_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:17:35,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3854331504842359070_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:17:35,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_5491945077124829769_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:17:52,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_5491945077124829769_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:17:52,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_5491945077124829769_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:17:52,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5491945077124829769_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:17:52,984 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_-1102053975483799161_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:18:09,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_6445579512898956756_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:18:09,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6445579512898956756_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:18:09,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6445579512898956756_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:18:09,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-8742684997352567239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:18:17,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6442040225374702694_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:18:17,433 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6442040225374702694_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:18:17,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_6442040225374702694_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:18:17,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_3666689710246477899_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:18:17,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8742684997352567239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:18:17,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-8742684997352567239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:18:17,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-8742684997352567239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:18:17,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-6530526502300064177_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:18:30,314 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3666689710246477899_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:18:30,315 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3666689710246477899_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:18:30,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_3666689710246477899_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:18:30,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-3751284351583555900_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:18:39,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-1102053975483799161_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:18:39,354 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1102053975483799161_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:18:39,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1102053975483799161_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:18:39,358 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_3390062265384821239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:18:51,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-8278117438479269626_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:18:52,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-8278117438479269626_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:18:52,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-8278117438479269626_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:18:52,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_-470693820491003566_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:19:32,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6530526502300064177_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:19:32,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-6530526502300064177_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:19:32,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6530526502300064177_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:19:32,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-3489619926212567210_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:19:36,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-3489619926212567210_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:36,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3489619926212567210_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:36,875 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3489619926212567210_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:36,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-459870613114186857_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:19:45,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-3751284351583555900_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:19:45,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-3751284351583555900_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:19:45,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-3751284351583555900_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:19:45,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_2305626593584701546_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:19:50,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_3390062265384821239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:19:50,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_3390062265384821239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:19:50,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3390062265384821239_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:19:50,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_3659802787662662709_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:19:52,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-470693820491003566_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:52,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-470693820491003566_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:52,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-470693820491003566_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:52,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_1255270580590315120_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:19:55,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3659802787662662709_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:19:55,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_3659802787662662709_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:19:55,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3659802787662662709_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:19:55,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_4112255321187627228_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:19:59,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_4112255321187627228_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:59,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4112255321187627228_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:59,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4112255321187627228_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:19:59,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_3515743108109246341_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:20:05,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3515743108109246341_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:20:05,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3515743108109246341_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:20:05,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3515743108109246341_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:20:05,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_6382231837260840579_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:20:48,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-459870613114186857_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:20:48,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-459870613114186857_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:20:48,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-459870613114186857_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:20:48,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_8508570477610248848_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:20:52,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_8508570477610248848_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:20:52,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_8508570477610248848_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:20:52,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8508570477610248848_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:20:52,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-5466012713730117132_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:21:12,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_2305626593584701546_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:21:12,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2305626593584701546_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:21:12,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_2305626593584701546_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:21:12,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-878555477976763042_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:21:18,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6382231837260840579_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:21:18,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_6382231837260840579_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:21:18,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6382231837260840579_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:21:18,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_2556939611260963982_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:21:34,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1255270580590315120_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:21:34,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1255270580590315120_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:21:34,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1255270580590315120_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:21:34,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_3739220010831100174_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:21:53,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2556939611260963982_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:21:54,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2556939611260963982_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:21:54,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2556939611260963982_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:21:54,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_3166075942414836038_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:21:59,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-5466012713730117132_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:21:59,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5466012713730117132_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:21:59,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-5466012713730117132_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:21:59,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-4646741607299753810_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:22:02,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-878555477976763042_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:22:02,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-878555477976763042_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:22:02,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-878555477976763042_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:22:02,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-1639802626197115410_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:22:28,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3739220010831100174_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:22:28,446 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3739220010831100174_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:22:28,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_3739220010831100174_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:22:28,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_-8047889551929022938_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:22:39,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-4646741607299753810_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:22:39,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-4646741607299753810_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:22:39,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-4646741607299753810_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:22:39,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-3991331141686508358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:22:44,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-1639802626197115410_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:22:44,890 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1639802626197115410_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:22:44,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-1639802626197115410_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:22:44,892 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_-8854278313981030060_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:22:46,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_3166075942414836038_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:22:46,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3166075942414836038_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:22:46,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3166075942414836038_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:22:46,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_3885462861563251198_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:23:39,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-8854278313981030060_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:39,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-8854278313981030060_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:39,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-8854278313981030060_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:39,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_7689745997062661496_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:23:47,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-3991331141686508358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:47,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-3991331141686508358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:47,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3991331141686508358_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:47,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_-440645940591556036_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:23:51,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7689745997062661496_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:23:51,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_7689745997062661496_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:23:51,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7689745997062661496_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:23:51,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000. blk_7862038250385078482_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:23:53,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-440645940591556036_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:53,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-440645940591556036_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:53,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-440645940591556036_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:23:53,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000. blk_990131373146336350_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:23:57,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_990131373146336350_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:23:57,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_990131373146336350_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:23:57,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_990131373146336350_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:23:57,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000 is closed by DFSClient_attempt_201609081943_0001_m_000000_1
2016-09-08 20:23:57,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 52 Total time for transactions(ms): 2Number of transactions batched in Syncs: 0 Number of syncs: 27 SyncTimes(ms): 309 
2016-09-08 20:24:00,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=listStatus	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1	dst=null	perm=null
2016-09-08 20:24:00,957 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=mkdirs	src=/user/hduser/terasort-input10-block-256	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:24:00,981 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=rename	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1/part-m-00000	dst=/user/hduser/terasort-input10-block-256/part-m-00000	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:24:00,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=delete	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_1	dst=null	perm=null
2016-09-08 20:24:01,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-8047889551929022938_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:24:01,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-8047889551929022938_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:24:01,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-8047889551929022938_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:24:01,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_9140190382960931465_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:24:01,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_3885462861563251198_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:24:01,858 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3885462861563251198_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:24:01,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3885462861563251198_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:24:01,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_3395126369060701247_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:24:02,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_7862038250385078482_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:24:02,192 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7862038250385078482_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:24:02,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7862038250385078482_7047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:24:02,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0/part-m-00000 is closed by DFSClient_attempt_201609081943_0001_m_000000_0
2016-09-08 20:24:06,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(block=blk_9140190382960931465_7047, newGenerationStamp=7048, newLength=12615168, newNodes=[10.129.40.102:50010, 10.129.40.105:50010], clientName=DFSClient_attempt_201609081943_0001_m_000001_0)
2016-09-08 20:24:06,323 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_9140190382960931465_7047) successfully to blk_9140190382960931465_7048
2016-09-08 20:24:06,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(block=blk_3395126369060701247_7047, newGenerationStamp=7049, newLength=12160000, newNodes=[10.129.40.104:50010, 10.129.40.102:50010], clientName=DFSClient_attempt_201609081943_0001_m_000001_1)
2016-09-08 20:24:06,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_3395126369060701247_7047) successfully to blk_3395126369060701247_7049
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2638873799979083046_7044 to 10.129.40.101:50010 10.129.40.102:50010 10.129.40.104:50010 
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4344984032049022173_7045 to 10.129.40.101:50010 10.129.40.103:50010 10.129.40.104:50010 
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6010882235441704063_7045 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.103:50010 
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6442747747966765298_7045 to 10.129.40.101:50010 10.129.40.105:50010 10.129.40.104:50010 
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-114566830199377427_7045 to 10.129.40.101:50010 10.129.40.105:50010 10.129.40.104:50010 
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2003987820136452117_7046 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.102:50010 
2016-09-08 20:24:09,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7797740609333622423_7047 to 10.129.40.101:50010 10.129.40.105:50010 10.129.40.104:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8288419010529555468_7047 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.103:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7292616938307414304_7047 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6381903812236893165_7047 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.105:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6442040225374702694_7047 to 10.129.40.101:50010 10.129.40.102:50010 10.129.40.103:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3666689710246477899_7047 to 10.129.40.101:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-3751284351583555900_7047 to 10.129.40.101:50010 10.129.40.102:50010 10.129.40.105:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2305626593584701546_7047 to 10.129.40.101:50010 10.129.40.102:50010 10.129.40.105:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-878555477976763042_7047 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.103:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1639802626197115410_7047 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.105:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8854278313981030060_7047 to 10.129.40.101:50010 10.129.40.102:50010 10.129.40.105:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7689745997062661496_7047 to 10.129.40.101:50010 10.129.40.105:50010 10.129.40.103:50010 
2016-09-08 20:24:09,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7862038250385078482_7047 to 10.129.40.101:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 20:24:09,049 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=delete	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000000_0	dst=null	perm=null
2016-09-08 20:24:09,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-4344984032049022173_7045 blk_-7292616938307414304_7047 blk_-8288419010529555468_7047 blk_3666689710246477899_7047 blk_7689745997062661496_7047 blk_7862038250385078482_7047 blk_6442040225374702694_7047 blk_-878555477976763042_7047 blk_6010882235441704063_7045
2016-09-08 20:24:09,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_-2638873799979083046_7044 blk_2305626593584701546_7047 blk_-7292616938307414304_7047 blk_-2003987820136452117_7046 blk_-3751284351583555900_7047 blk_-8854278313981030060_7047 blk_6442040225374702694_7047
2016-09-08 20:24:12,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_2305626593584701546_7047 blk_-7797740609333622423_7047 blk_-3751284351583555900_7047 blk_-8854278313981030060_7047 blk_3666689710246477899_7047 blk_-1639802626197115410_7047 blk_7689745997062661496_7047 blk_7862038250385078482_7047 blk_-6442747747966765298_7045 blk_-114566830199377427_7045 blk_6381903812236893165_7047
2016-09-08 20:24:12,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-2638873799979083046_7044 blk_-4344984032049022173_7045 blk_-7797740609333622423_7047 blk_-2003987820136452117_7046 blk_-8288419010529555468_7047 blk_-1639802626197115410_7047 blk_-6442747747966765298_7045 blk_-114566830199377427_7045 blk_-878555477976763042_7047 blk_6010882235441704063_7045 blk_6381903812236893165_7047
2016-09-08 20:24:15,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-4344984032049022173_7045 blk_-2003987820136452117_7046 blk_3666689710246477899_7047 blk_-1639802626197115410_7047 blk_-6442747747966765298_7045 blk_6442040225374702694_7047 blk_6010882235441704063_7045 blk_-2638873799979083046_7044 blk_2305626593584701546_7047 blk_-7797740609333622423_7047 blk_-7292616938307414304_7047 blk_-3751284351583555900_7047 blk_-8288419010529555468_7047 blk_-8854278313981030060_7047 blk_7689745997062661496_7047 blk_7862038250385078482_7047 blk_-114566830199377427_7045 blk_-878555477976763042_7047 blk_6381903812236893165_7047
2016-09-08 20:24:29,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_9140190382960931465_7048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 12615168
2016-09-08 20:24:29,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_9140190382960931465_7048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 12615168
2016-09-08 20:24:29,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_5547113216543967951_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:24:29,130 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_3395126369060701247_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 12160000
2016-09-08 20:24:29,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3395126369060701247_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 12160000
2016-09-08 20:24:29,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_-1023921585036736145_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:24:29,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_-75278606890931903_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:25:08,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_5547113216543967951_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:25:08,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5547113216543967951_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:25:08,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5547113216543967951_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:25:08,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001. blk_7996937010234340919_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:25:25,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-75278606890931903_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:25:25,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-75278606890931903_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:25:25,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-75278606890931903_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:25:25,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001. blk_5548417429453604243_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:25:27,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_5548417429453604243_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:25:27,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_5548417429453604243_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:25:27,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5548417429453604243_7049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 20:25:27,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001 is closed by DFSClient_attempt_201609081943_0001_m_000001_1
2016-09-08 20:25:27,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 62 Total time for transactions(ms): 2Number of transactions batched in Syncs: 1 Number of syncs: 34 SyncTimes(ms): 420 
2016-09-08 20:25:30,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=listStatus	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1	dst=null	perm=null
2016-09-08 20:25:30,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=mkdirs	src=/user/hduser/terasort-input10-block-256	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:25:30,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=rename	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1/part-m-00001	dst=/user/hduser/terasort-input10-block-256/part-m-00001	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:25:30,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=delete	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_1	dst=null	perm=null
2016-09-08 20:25:39,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8640492215143176732_7038 to 10.129.40.103:50010 10.129.40.102:50010 10.129.40.104:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:25:39,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4982031477067310394_7039 to 10.129.40.101:50010 10.129.40.104:50010 10.129.40.103:50010 10.129.40.105:50010 10.129.40.102:50010 
2016-09-08 20:25:39,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5873986092320996970_7040 to 10.129.40.104:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 20:25:39,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2966897432883187622_7041 to 10.129.40.102:50010 10.129.40.101:50010 10.129.40.104:50010 
2016-09-08 20:25:39,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609081943_0001	dst=null	perm=null
2016-09-08 20:25:39,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-8640492215143176732_7038 blk_-2966897432883187622_7041 blk_-5873986092320996970_7040 blk_4982031477067310394_7039
2016-09-08 20:25:39,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-8640492215143176732_7038 blk_-2966897432883187622_7041 blk_4982031477067310394_7039
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_5037708392074113714_7045 to 10.129.40.102:50010 10.129.40.101:50010 10.129.40.105:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4892949802124987058_7045 to 10.129.40.102:50010 10.129.40.101:50010 10.129.40.103:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6044842858111680358_7047 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.104:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6899691694244829431_7047 to 10.129.40.102:50010 10.129.40.104:50010 10.129.40.101:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6991640690675716002_7047 to 10.129.40.102:50010 10.129.40.101:50010 10.129.40.104:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2444506035184283803_7047 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.104:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8278117438479269626_7047 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.104:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-470693820491003566_7047 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1255270580590315120_7047 to 10.129.40.102:50010 10.129.40.104:50010 10.129.40.103:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3739220010831100174_7047 to 10.129.40.102:50010 10.129.40.104:50010 10.129.40.103:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8047889551929022938_7047 to 10.129.40.102:50010 10.129.40.105:50010 10.129.40.101:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_9140190382960931465_7048 to 10.129.40.102:50010 10.129.40.105:50010 
2016-09-08 20:25:41,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_5547113216543967951_7049 to 10.129.40.102:50010 10.129.40.104:50010 10.129.40.101:50010 
2016-09-08 20:25:41,158 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=delete	src=/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0	dst=null	perm=null
2016-09-08 20:25:41,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/jobtracker/jobsInfo/job_201609081943_0001.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:25:41,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609081943_0001.info. blk_-2924385686455397670_7050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 20:25:41,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609081943_0001.info. blk_6696779519262551660_7050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 20:25:41,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6696779519262551660_7050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:25:41,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_6696779519262551660_7050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:25:41,902 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6696779519262551660_7050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 20:25:41,902 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /jobtracker/jobsInfo/job_201609081943_0001.info is closed by DFSClient_-497673382
2016-09-08 20:25:41,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7364540058221320483_7042 to 10.129.40.103:50010 10.129.40.104:50010 10.129.40.101:50010 
2016-09-08 20:25:41,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7757860014277293192_7043 to 10.129.40.103:50010 10.129.40.101:50010 10.129.40.105:50010 
2016-09-08 20:25:41,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609081943_0001	dst=null	perm=null
2016-09-08 20:25:42,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/jobtracker/jobsInfo/job_201609081943_0001.info	dst=null	perm=null
2016-09-08 20:25:42,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_3395126369060701247_7049 to datanode(s) 10.129.40.105:50010
2016-09-08 20:25:42,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-8640492215143176732_7038 blk_4892949802124987058_7045 blk_-7364540058221320483_7042 blk_-5873986092320996970_7040 blk_-2444506035184283803_7047 blk_4982031477067310394_7039 blk_3739220010831100174_7047 blk_-8278117438479269626_7047 blk_-7757860014277293192_7043 blk_1255270580590315120_7047
2016-09-08 20:25:42,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-8047889551929022938_7047 blk_-6899691694244829431_7047 blk_4892949802124987058_7045 blk_-7364540058221320483_7042 blk_5037708392074113714_7045 blk_-6991640690675716002_7047 blk_-470693820491003566_7047 blk_5547113216543967951_7049 blk_-7757860014277293192_7043
2016-09-08 20:25:42,852 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/jobtracker/jobsInfo/job_201609081943_0001.info	dst=null	perm=null
2016-09-08 20:25:43,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addBlock: block blk_7996937010234340919_7049 on 10.129.40.104:50010 size 268435456 does not belong to any file.
2016-09-08 20:25:43,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7996937010234340919_7049 to 10.129.40.104:50010
2016-09-08 20:25:43,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addBlock: block blk_7996937010234340919_7049 on 10.129.40.105:50010 size 268435456 does not belong to any file.
2016-09-08 20:25:43,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7996937010234340919_7049 to 10.129.40.105:50010
2016-09-08 20:25:43,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addBlock: block blk_7996937010234340919_7049 on 10.129.40.102:50010 size 268435456 does not belong to any file.
2016-09-08 20:25:43,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7996937010234340919_7049 to 10.129.40.102:50010
2016-09-08 20:25:43,100 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call addBlock(/user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001, DFSClient_attempt_201609081943_0001_m_000001_0, blk_7996937010234340919_7049, null) from 10.129.40.102:59580: error: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001 File does not exist. Holder DFSClient_attempt_201609081943_0001_m_000001_0 does not have any open files.
org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /user/hduser/terasort-input10-block-256/_temporary/_attempt_201609081943_0001_m_000001_0/part-m-00001 File does not exist. Holder DFSClient_attempt_201609081943_0001_m_000001_0 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:1513)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:1504)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1427)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:690)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:25:45,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_-8047889551929022938_7047 blk_-8640492215143176732_7038 blk_6044842858111680358_7047 blk_-5873986092320996970_7040 blk_5037708392074113714_7045 blk_-470693820491003566_7047 blk_4982031477067310394_7039 blk_9140190382960931465_7048 blk_7996937010234340919_7049 blk_-7757860014277293192_7043
2016-09-08 20:25:45,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_4892949802124987058_7045 blk_6044842858111680358_7047 blk_-6991640690675716002_7047 blk_-2444506035184283803_7047 blk_4982031477067310394_7039 blk_7996937010234340919_7049 blk_-8278117438479269626_7047 blk_-8047889551929022938_7047 blk_-6899691694244829431_7047 blk_-8640492215143176732_7038 blk_-2966897432883187622_7041 blk_5037708392074113714_7045 blk_-470693820491003566_7047 blk_5547113216543967951_7049 blk_9140190382960931465_7048 blk_3739220010831100174_7047 blk_1255270580590315120_7047
2016-09-08 20:25:48,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-6899691694244829431_7047 blk_6044842858111680358_7047 blk_-7364540058221320483_7042 blk_-6991640690675716002_7047 blk_-2444506035184283803_7047 blk_5547113216543967951_7049 blk_7996937010234340919_7049 blk_3739220010831100174_7047 blk_-8278117438479269626_7047 blk_1255270580590315120_7047
2016-09-08 20:26:08,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_3395126369060701247_7049 size 268435456
2016-09-08 20:30:32,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/	dst=null	perm=null
2016-09-08 20:30:34,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user	dst=null	perm=null
2016-09-08 20:30:35,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 20:30:39,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-input10-block-256	dst=null	perm=null
2016-09-08 20:30:41,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:30:42,182 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:30:42,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:30:52,771 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-input10-block-256/_temporary	dst=null	perm=null
2016-09-08 20:30:57,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-input10-block-256	dst=null	perm=null
2016-09-08 20:31:11,303 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 20:31:14,536 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:31:14,601 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:31:14,607 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 20:31:14,608 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:14,613 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:14,613 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:31:14,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 20:31:14,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 20:31:14,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 20:31:14,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 20:31:14,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 20:31:14,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 20:31:14,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 20:31:14,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 20:31:14,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 20:31:14,653 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:14,653 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:31:14,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 20:31:14,669 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 378
2016-09-08 20:31:14,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 20:31:14,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78967 loaded in 0 seconds.
2016-09-08 20:31:14,692 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 1049092 edits # 63 loaded in 0 seconds.
2016-09-08 20:31:14,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 20:31:14,738 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 saved in 0 seconds.
2016-09-08 20:31:15,169 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 saved in 0 seconds.
2016-09-08 20:31:15,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 993 msecs
2016-09-08 20:31:15,621 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:31:15,632 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:31:15,633 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:15,634 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:31:15,634 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:15,635 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:31:15,636 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 20:31:15,637 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1110 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
2016-09-08 20:31:15,666 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:31:15,687 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:31:15,690 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 20:31:15,691 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 20:31:15,691 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 20:31:15,691 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:31:15,807 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 20:31:15,808 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 20:31:15,808 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 20:31:15,808 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 20:31:15,809 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 20:31:15,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 20:31:16,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 20:31:16,997 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 20:31:17,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 20:31:17,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 20:31:17,032 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 20:31:17,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 20:31:17,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 20:31:17,255 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8288419010529555468_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8288419010529555468_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_7689745997062661496_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7689745997062661496_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8640492215143176732_7038 on 10.129.40.103:50010 size 252064 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8640492215143176732_7038 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6442040225374702694_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6442040225374702694_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-2444506035184283803_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2444506035184283803_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4982031477067310394_7039 on 10.129.40.103:50010 size 177 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4982031477067310394_7039 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7364540058221320483_7042 on 10.129.40.103:50010 size 136 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7364540058221320483_7042 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_7862038250385078482_7047 on 10.129.40.103:50010 size 168161792 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7862038250385078482_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-878555477976763042_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-878555477976763042_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4344984032049022173_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4344984032049022173_7045 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8278117438479269626_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8278117438479269626_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7757860014277293192_7043 on 10.129.40.103:50010 size 101 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7757860014277293192_7043 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7292616938307414304_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7292616938307414304_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3666689710246477899_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3666689710246477899_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6010882235441704063_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6010882235441704063_7045 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5873986092320996970_7040 on 10.129.40.103:50010 size 16 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5873986092320996970_7040 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3739220010831100174_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3739220010831100174_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4892949802124987058_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4892949802124987058_7045 to 10.129.40.103:50010
2016-09-08 20:31:17,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_1255270580590315120_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:17,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1255270580590315120_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_9140190382960931465_7047 on 10.129.40.103:50010 size 12615168 does not belong to any file.
2016-09-08 20:31:17,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_9140190382960931465_7047 to 10.129.40.103:50010
2016-09-08 20:31:17,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3395126369060701247 added as corrupt on 10.129.40.103:50010 by /10.129.40.103
2016-09-08 20:31:17,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.104:50010 storage DS-649323290-10.129.40.104-50010-1473344014446
2016-09-08 20:31:17,695 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.104:50010
2016-09-08 20:31:17,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-1023921585036736145_7049 on 10.129.40.104:50010 size 0 does not belong to any file.
2016-09-08 20:31:17,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1023921585036736145_7049 to 10.129.40.104:50010
2016-09-08 20:31:18,923 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:31:18,925 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46228: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:31:28,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:31:28,931 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46228: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:31:36,020 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 20:31:37,702 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:31:37,767 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:31:37,773 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 20:31:37,774 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:37,778 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:37,779 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:31:37,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 20:31:37,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 20:31:37,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 20:31:37,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 20:31:37,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 20:31:37,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 20:31:37,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 20:31:37,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 20:31:37,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 20:31:37,819 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:37,819 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:31:37,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 20:31:37,834 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 375
2016-09-08 20:31:37,851 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 20:31:37,851 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 loaded in 0 seconds.
2016-09-08 20:31:37,851 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2016-09-08 20:31:37,852 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 60 msecs
2016-09-08 20:31:37,853 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:31:37,864 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:31:37,865 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:37,865 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:31:37,866 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:31:37,866 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:31:37,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 20:31:37,869 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1110 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
2016-09-08 20:31:37,889 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:31:37,918 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:31:37,921 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 20:31:37,922 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 20:31:37,922 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 20:31:37,922 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:31:38,030 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 20:31:38,032 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 20:31:38,032 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 20:31:38,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 20:31:38,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 20:31:38,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 20:31:38,033 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 20:31:38,035 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 20:31:38,036 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 20:31:39,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.104:50010 storage DS-649323290-10.129.40.104-50010-1473344014446
2016-09-08 20:31:39,940 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.104:50010
2016-09-08 20:31:39,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-1023921585036736145_7049 on 10.129.40.104:50010 size 0 does not belong to any file.
2016-09-08 20:31:39,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1023921585036736145_7049 to 10.129.40.104:50010
2016-09-08 20:31:39,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 20:31:39,991 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 20:31:40,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 20:31:40,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 20:31:40,048 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8288419010529555468_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8288419010529555468_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_7689745997062661496_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7689745997062661496_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8640492215143176732_7038 on 10.129.40.103:50010 size 252064 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8640492215143176732_7038 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6442040225374702694_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6442040225374702694_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-2444506035184283803_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2444506035184283803_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4982031477067310394_7039 on 10.129.40.103:50010 size 177 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4982031477067310394_7039 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7364540058221320483_7042 on 10.129.40.103:50010 size 136 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7364540058221320483_7042 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_7862038250385078482_7047 on 10.129.40.103:50010 size 168161792 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7862038250385078482_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-878555477976763042_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-878555477976763042_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4344984032049022173_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4344984032049022173_7045 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8278117438479269626_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8278117438479269626_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7757860014277293192_7043 on 10.129.40.103:50010 size 101 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7757860014277293192_7043 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7292616938307414304_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7292616938307414304_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3666689710246477899_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3666689710246477899_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6010882235441704063_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6010882235441704063_7045 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5873986092320996970_7040 on 10.129.40.103:50010 size 16 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5873986092320996970_7040 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3739220010831100174_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3739220010831100174_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4892949802124987058_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4892949802124987058_7045 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_1255270580590315120_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1255270580590315120_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_9140190382960931465_7047 on 10.129.40.103:50010 size 12615168 does not belong to any file.
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_9140190382960931465_7047 to 10.129.40.103:50010
2016-09-08 20:31:40,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3395126369060701247 added as corrupt on 10.129.40.103:50010 by /10.129.40.103
2016-09-08 20:31:40,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 20:31:40,064 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 20:31:40,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 20:31:42,022 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:31:42,024 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:31:52,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:31:52,030 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:32:02,032 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:32:02,034 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:32:12,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:32:12,040 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:32:22,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:32:22,048 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:32:32,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:32:32,054 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:32:42,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:32:42,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:32:52,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:32:52,070 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:33:02,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:33:02,075 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:33:12,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:33:12,078 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:33:22,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:33:22,080 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:33:32,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:33:32,085 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:33:42,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:33:42,090 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:33:52,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:33:52,095 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:34:02,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:34:02,100 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:34:12,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:34:12,104 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:34:22,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:34:22,115 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:34:32,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:34:32,124 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:34:42,127 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:34:42,129 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:34:52,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:34:52,134 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:35:02,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:35:02,137 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:35:12,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:35:12,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:35:22,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:35:22,151 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:35:32,155 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:35:32,157 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:35:42,161 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:35:42,164 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:35:52,168 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:35:52,171 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:02,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:36:02,174 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:12,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:36:12,177 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:22,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:36:22,185 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:32,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:36:32,191 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:40,870 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call rollEditLog() from 10.129.40.100:46402: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Checkpoint not created. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Checkpoint not created. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:3901)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.rollEditLog(NameNode.java:962)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:42,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:36:42,196 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:36:52,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:36:52,202 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:37:02,206 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:37:02,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:37:12,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:37:12,216 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:37:22,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:37:22,221 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:37:32,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:37:32,224 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:37:42,226 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:37:42,228 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46278: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 901 needs additional 209 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:37:50,198 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 20:37:51,874 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:37:51,939 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:37:51,945 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 20:37:51,947 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:37:51,951 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:37:51,951 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:37:51,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 20:37:51,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 20:37:51,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 20:37:51,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 20:37:51,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 20:37:51,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 20:37:51,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 20:37:51,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 20:37:51,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 20:37:51,990 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:37:51,991 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:37:51,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 20:37:52,005 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 375
2016-09-08 20:37:52,023 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 20:37:52,023 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 loaded in 0 seconds.
2016-09-08 20:37:52,023 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2016-09-08 20:37:52,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 60 msecs
2016-09-08 20:37:52,025 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:37:52,036 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:37:52,037 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:37:52,037 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:37:52,038 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:37:52,038 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:37:52,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 20:37:52,040 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1110 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
2016-09-08 20:37:52,061 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:37:52,089 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:37:52,093 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 20:37:52,093 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 20:37:52,093 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 20:37:52,093 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:37:52,204 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 20:37:52,206 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 20:37:52,206 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 20:37:52,206 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 20:37:52,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 20:37:52,209 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 20:37:54,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.104:50010 storage DS-649323290-10.129.40.104-50010-1473344014446
2016-09-08 20:37:54,060 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.104:50010
2016-09-08 20:37:54,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-1023921585036736145_7049 on 10.129.40.104:50010 size 0 does not belong to any file.
2016-09-08 20:37:54,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1023921585036736145_7049 to 10.129.40.104:50010
2016-09-08 20:37:54,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 20:37:54,116 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 20:37:54,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 20:37:54,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 20:37:54,161 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 20:37:54,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 20:37:54,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 20:37:54,197 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8288419010529555468_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8288419010529555468_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_7689745997062661496_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7689745997062661496_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8640492215143176732_7038 on 10.129.40.103:50010 size 252064 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8640492215143176732_7038 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6442040225374702694_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6442040225374702694_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-2444506035184283803_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2444506035184283803_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4982031477067310394_7039 on 10.129.40.103:50010 size 177 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4982031477067310394_7039 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7364540058221320483_7042 on 10.129.40.103:50010 size 136 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7364540058221320483_7042 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_7862038250385078482_7047 on 10.129.40.103:50010 size 168161792 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7862038250385078482_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-878555477976763042_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-878555477976763042_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-4344984032049022173_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4344984032049022173_7045 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-8278117438479269626_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-8278117438479269626_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7757860014277293192_7043 on 10.129.40.103:50010 size 101 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7757860014277293192_7043 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-7292616938307414304_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7292616938307414304_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3666689710246477899_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3666689710246477899_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6010882235441704063_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6010882235441704063_7045 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-5873986092320996970_7040 on 10.129.40.103:50010 size 16 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-5873986092320996970_7040 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_3739220010831100174_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3739220010831100174_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_4892949802124987058_7045 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_4892949802124987058_7045 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_1255270580590315120_7047 on 10.129.40.103:50010 size 268435456 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_1255270580590315120_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_9140190382960931465_7047 on 10.129.40.103:50010 size 12615168 does not belong to any file.
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_9140190382960931465_7047 to 10.129.40.103:50010
2016-09-08 20:37:54,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3395126369060701247 added as corrupt on 10.129.40.103:50010 by /10.129.40.103
2016-09-08 20:37:54,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 20:37:54,240 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 20:37:54,256 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1110 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 20:37:54,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_6469556580943644020_6212 on 10.129.40.101:50010 size 118864384 does not belong to any file.
2016-09-08 20:37:54,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6469556580943644020_6212 to 10.129.40.101:50010
2016-09-08 20:37:56,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:37:56,147 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46446: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 28 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:38:06,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:38:06,155 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46446: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 18 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:38:14,259 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 20:38:16,162 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:38:16,166 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46446: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 8 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:38:24,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1112
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 79
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 5 datanodes
2016-09-08 20:38:24,275 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 79 blocks
2016-09-08 20:38:25,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_6469556580943644020_6212
2016-09-08 20:38:25,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-4344984032049022173_7045 blk_4892949802124987058_7045 blk_3666689710246477899_7047 blk_6442040225374702694_7047 blk_-2444506035184283803_7047 blk_4982031477067310394_7039 blk_6010882235441704063_7045 blk_-8278117438479269626_7047 blk_-7757860014277293192_7043 blk_-8640492215143176732_7038 blk_-7292616938307414304_7047 blk_-8288419010529555468_7047 blk_-7364540058221320483_7042 blk_7689745997062661496_7047 blk_7862038250385078482_7047 blk_-5873986092320996970_7040 blk_-878555477976763042_7047 blk_9140190382960931465_7047 blk_3739220010831100174_7047 blk_1255270580590315120_7047
2016-09-08 20:38:26,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:38:26,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_5604019001368321631_7037 to 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 20:38:26,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:38:26,235 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:38:26,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 20:38:26,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:38:26,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 20:38:26,296 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_7090885215942518333_7051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:38:26,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_7090885215942518333_7051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:38:26,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7090885215942518333_7051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:38:26,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7090885215942518333_7051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:38:26,369 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_-1852563516
2016-09-08 20:38:26,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 20:38:28,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_5604019001368321631_7037
2016-09-08 20:38:28,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-1023921585036736145_7049
2016-09-08 20:38:31,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_5604019001368321631_7037
2016-09-08 20:38:31,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_5604019001368321631_7037
2016-09-08 20:39:15,732 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.129.40.100
************************************************************/
2016-09-08 20:39:17,402 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/10.129.40.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.21.0
STARTUP_MSG:   classpath = /usr/local/hadoop/bin/../conf:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-common-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-common-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-mapred-examples-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-mapred-tools-0.21.0.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../lib/jsp-2.1/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../conf:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar:/usr/local/hadoop/bin/../mapred/conf:/usr/local/hadoop/bin/../mapred/hadoop-mapred-*.jar:/usr/local/hadoop/bin/../mapred/lib/*.jar:/usr/local/hadoop/bin/..:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-0.21.0-sources.jar:/usr/local/hadoop/bin/../hadoop-hdfs-ant-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0.jar:/usr/local/hadoop/bin/../hadoop-hdfs-test-0.21.0-sources.jar:/usr/local/hadoop/bin/../lib/ant-1.6.5.jar:/usr/local/hadoop/bin/../lib/asm-3.2.jar:/usr/local/hadoop/bin/../lib/aspectjrt-1.6.5.jar:/usr/local/hadoop/bin/../lib/aspectjtools-1.6.5.jar:/usr/local/hadoop/bin/../lib/avro-1.3.2.jar:/usr/local/hadoop/bin/../lib/commons-cli-1.2.jar:/usr/local/hadoop/bin/../lib/commons-codec-1.4.jar:/usr/local/hadoop/bin/../lib/commons-el-1.0.jar:/usr/local/hadoop/bin/../lib/commons-httpclient-3.1.jar:/usr/local/hadoop/bin/../lib/commons-lang-2.5.jar:/usr/local/hadoop/bin/../lib/commons-logging-1.1.1.jar:/usr/local/hadoop/bin/../lib/commons-logging-api-1.1.jar:/usr/local/hadoop/bin/../lib/commons-net-1.4.1.jar:/usr/local/hadoop/bin/../lib/core-3.1.1.jar:/usr/local/hadoop/bin/../lib/ftplet-api-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-core-1.0.0.jar:/usr/local/hadoop/bin/../lib/ftpserver-deprecated-1.0.0-M2.jar:/usr/local/hadoop/bin/../lib/hsqldb-1.8.0.10.jar:/usr/local/hadoop/bin/../lib/jackson-core-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jackson-mapper-asl-1.4.2.jar:/usr/local/hadoop/bin/../lib/jasper-compiler-5.5.12.jar:/usr/local/hadoop/bin/../lib/jasper-runtime-5.5.12.jar:/usr/local/hadoop/bin/../lib/jdiff-1.0.9.jar:/usr/local/hadoop/bin/../lib/jets3t-0.7.1.jar:/usr/local/hadoop/bin/../lib/jetty-6.1.14.jar:/usr/local/hadoop/bin/../lib/jetty-util-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/local/hadoop/bin/../lib/junit-4.8.1.jar:/usr/local/hadoop/bin/../lib/kfs-0.3.jar:/usr/local/hadoop/bin/../lib/log4j-1.2.15.jar:/usr/local/hadoop/bin/../lib/mina-core-2.0.0-M5.jar:/usr/local/hadoop/bin/../lib/mockito-all-1.8.2.jar:/usr/local/hadoop/bin/../lib/oro-2.0.8.jar:/usr/local/hadoop/bin/../lib/paranamer-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-ant-2.2.jar:/usr/local/hadoop/bin/../lib/paranamer-generator-2.2.jar:/usr/local/hadoop/bin/../lib/qdox-1.10.1.jar:/usr/local/hadoop/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/local/hadoop/bin/../lib/slf4j-api-1.5.11.jar:/usr/local/hadoop/bin/../lib/slf4j-log4j12-1.5.11.jar:/usr/local/hadoop/bin/../lib/xmlenc-0.52.jar
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.21 -r 985326; compiled by 'tomwhite' on Tue Aug 17 01:02:28 EDT 2010
************************************************************/
2016-09-08 20:39:17,466 INFO org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
2016-09-08 20:39:17,472 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
2016-09-08 20:39:17,473 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context jvm
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.<init>(JvmMetrics.java:86)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:78)
	at org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:65)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:103)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:39:17,477 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.<init>(NameNodeMetrics.java:109)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initMetrics(NameNode.java:199)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:39:17,478 INFO org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics: Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:39:17,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2016-09-08 20:39:17,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 512
2016-09-08 20:39:17,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2016-09-08 20:39:17,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2016-09-08 20:39:17,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = false
2016-09-08 20:39:17,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser
2016-09-08 20:39:17,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-09-08 20:39:17,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-09-08 20:39:17,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2016-09-08 20:39:17,516 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context dfs
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.<init>(FSNamesystemMetrics.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerMBean(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:270)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:271)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:303)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:39:17,517 INFO org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics: Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2016-09-08 20:39:17,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStatusMBean
2016-09-08 20:39:17,531 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 375
2016-09-08 20:39:17,548 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-09-08 20:39:17,548 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 loaded in 0 seconds.
2016-09-08 20:39:17,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /usr/local/hadoop_tmp/hdfs/hadoopdata/dfs/name/current/edits of size 1049092 edits # 7 loaded in 0 seconds.
2016-09-08 20:39:17,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 20:39:17,598 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 saved in 0 seconds.
2016-09-08 20:39:18,005 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 78184 saved in 0 seconds.
2016-09-08 20:39:18,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1015 msecs
2016-09-08 20:39:18,507 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-09-08 20:39:18,518 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-09-08 20:39:18,519 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.<init>(RpcMetrics.java:58)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1445)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:39:18,519 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:39:18,520 ERROR org.apache.hadoop.metrics.MetricsUtil: Unable to create metrics context rpc
java.lang.ClassNotFoundException: org.apache.hadoop.metrics.ganglia.GangliaContext31
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at org.apache.hadoop.metrics.ContextFactory.getContext(ContextFactory.java:139)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:60)
	at org.apache.hadoop.metrics.MetricsUtil.getContext(MetricsUtil.java:49)
	at org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.<init>(RpcDetailedMetrics.java:52)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1447)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:343)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:324)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:284)
	at org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:45)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:331)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:305)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:433)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1359)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1368)
2016-09-08 20:39:18,521 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=NameNode, port=8020
2016-09-08 20:39:18,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2016-09-08 20:39:18,523 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 1110 blocks to reach the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically.
2016-09-08 20:39:18,551 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-09-08 20:39:18,574 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-09-08 20:39:18,577 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2016-09-08 20:39:18,578 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-09-08 20:39:18,578 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-09-08 20:39:18,578 INFO org.mortbay.log: jetty-6.1.14
2016-09-08 20:39:18,687 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-09-08 20:39:18,688 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode Web-server up at: 0.0.0.0/0.0.0.0:50070
2016-09-08 20:39:18,688 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-09-08 20:39:18,688 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-09-08 20:39:18,689 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-09-08 20:39:18,690 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode up at: master/10.129.40.100:8020
2016-09-08 20:39:18,690 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-09-08 20:39:19,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.104:50010 storage DS-649323290-10.129.40.104-50010-1473344014446
2016-09-08 20:39:19,609 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.104:50010
2016-09-08 20:39:19,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.105:50010 storage DS-992716549-10.129.40.105-50010-1470346504944
2016-09-08 20:39:19,692 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.105:50010
2016-09-08 20:39:19,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_6446045949068725457 added as corrupt on 10.129.40.105:50010 by /10.129.40.105
2016-09-08 20:39:19,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.102:50010 storage DS-674790418-10.129.40.102-50010-1455272930001
2016-09-08 20:39:19,720 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.102:50010
2016-09-08 20:39:19,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3582789123556368590 added as corrupt on 10.129.40.102:50010 by /10.129.40.102
2016-09-08 20:39:19,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.103:50010 storage DS-711488685-127.0.1.1-50010-1469039585320
2016-09-08 20:39:19,742 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.103:50010
2016-09-08 20:39:19,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_3395126369060701247 added as corrupt on 10.129.40.103:50010 by /10.129.40.103
2016-09-08 20:39:19,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from 10.129.40.101:50010 storage DS-526678518-10.129.40.101-50010-1456853482271
2016-09-08 20:39:19,781 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.129.40.101:50010
2016-09-08 20:39:19,821 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1110 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 29 seconds.
2016-09-08 20:39:21,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:39:21,706 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46516: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 28 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:39:31,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:39:31,711 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46516: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 18 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 18 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:39:39,825 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 9 seconds.
2016-09-08 20:39:41,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:39:41,719 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call delete(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system, true) from 10.129.40.100:46516: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 8 seconds.
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system. Name node is in safe mode.
The reported blocks 1112 has reached the threshold 0.9990 of total blocks 1112. Safe mode will be turned off automatically in 8 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1804)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1780)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:39:48,148 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:256)
	at org.apache.hadoop.util.Shell.run(Shell.java:183)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:376)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:462)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:445)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:67)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:51)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:85)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:644)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:51)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4015)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkTraverse(FSNamesystem.java:3998)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:1872)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:879)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 20:39:48,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-input10-block-256	dst=null	perm=null
2016-09-08 20:39:49,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 1112
2016-09-08 20:39:49,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-09-08 20:39:49,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 79
2016-09-08 20:39:49,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-09-08 20:39:49,829 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs.
2016-09-08 20:39:49,829 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF.
2016-09-08 20:39:49,829 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 5 datanodes
2016-09-08 20:39:49,829 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 79 blocks
2016-09-08 20:39:51,724 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:39:51,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7090885215942518333_7051 to 10.129.40.104:50010 10.129.40.105:50010 10.129.40.103:50010 
2016-09-08 20:39:51,841 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=null
2016-09-08 20:39:51,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:39:51,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 20:39:51,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:39:51,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info	dst=null	perm=hduser:supergroup:rw-------
2016-09-08 20:39:51,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info. blk_-5904103860602000738_7052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:39:51,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-5904103860602000738_7052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:39:51,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5904103860602000738_7052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:39:51,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-5904103860602000738_7052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:39:51,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/jobtracker.info is closed by DFSClient_-213913761
2016-09-08 20:39:51,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 20:39:53,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 20:39:54,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_7090885215942518333_7051
2016-09-08 20:39:54,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_7090885215942518333_7051
2016-09-08 20:39:57,532 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_7090885215942518333_7051
2016-09-08 20:41:12,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/user/hduser/terasort-input10-block-256	dst=null	perm=null
2016-09-08 20:41:12,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:12,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,569 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:12,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:12,575 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:12,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:12,577 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 10 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 153 
2016-09-08 20:41:12,584 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:12,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:12,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/user/hduser/terasort-output10-block-256/_partition.lst	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:12,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-output10-block-256/_partition.lst is closed by DFSClient_1645448794
2016-09-08 20:41:12,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:41:12,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 20:41:12,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:12,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar. blk_2455145814888819235_7054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:41:13,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2455145814888819235_7054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2455145814888819235_7054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_2455145814888819235_7054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,045 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar is closed by DFSClient_1645448794
2016-09-08 20:41:13,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar. New replication is 10
2016-09-08 20:41:13,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=null
2016-09-08 20:41:13,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split. New replication is 10
2016-09-08 20:41:13,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:13,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split. blk_-6516346748472160366_7055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 20:41:13,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6516346748472160366_7055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:41:13,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-6516346748472160366_7055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:41:13,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-6516346748472160366_7055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:41:13,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6516346748472160366_7055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:41:13,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-6516346748472160366_7055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 20:41:13,151 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split is closed by DFSClient_1645448794
2016-09-08 20:41:13,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,178 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.splitmetainfo. blk_405814654912304282_7056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:41:13,193 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_405814654912304282_7056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_405814654912304282_7056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_405814654912304282_7056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,196 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.splitmetainfo is closed by DFSClient_1645448794
2016-09-08 20:41:13,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml. blk_7799979528030499211_7057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:41:13,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7799979528030499211_7057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7799979528030499211_7057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7799979528030499211_7057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:41:13,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml is closed by DFSClient_1645448794
2016-09-08 20:41:13,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=null
2016-09-08 20:41:13,334 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 20:41:13,342 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 20:41:13,351 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/job-info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/job-info. blk_-4120802014816382694_7058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:41:13,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-4120802014816382694_7058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:41:13,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-4120802014816382694_7058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:41:13,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4120802014816382694_7058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:41:13,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/job-info is closed by DFSClient_-213913761
2016-09-08 20:41:13,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:41:13,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken. blk_6239355333976600539_7059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 20:41:13,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_6239355333976600539_7059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:41:13,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6239355333976600539_7059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:41:13,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6239355333976600539_7059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 20:41:13,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken is closed by DFSClient_-213913761
2016-09-08 20:41:13,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.splitmetainfo	dst=null	perm=null
2016-09-08 20:41:16,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken	dst=null	perm=null
2016-09-08 20:41:16,314 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=null
2016-09-08 20:41:16,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=null
2016-09-08 20:41:16,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-output10-block-256/_partition.lst	dst=null	perm=null
2016-09-08 20:41:22,276 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken	dst=null	perm=null
2016-09-08 20:41:22,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken	dst=null	perm=null
2016-09-08 20:41:22,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=null
2016-09-08 20:41:22,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken	dst=null	perm=null
2016-09-08 20:41:22,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=null
2016-09-08 20:41:22,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=null
2016-09-08 20:41:22,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=null
2016-09-08 20:41:22,351 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001/jobToken	dst=null	perm=null
2016-09-08 20:41:22,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=null
2016-09-08 20:41:22,374 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=null
2016-09-08 20:41:22,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.xml	dst=null	perm=null
2016-09-08 20:41:22,417 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-output10-block-256/_partition.lst	dst=null	perm=null
2016-09-08 20:41:22,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.jar	dst=null	perm=null
2016-09-08 20:41:22,439 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-output10-block-256/_partition.lst	dst=null	perm=null
2016-09-08 20:41:22,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-output10-block-256/_partition.lst	dst=null	perm=null
2016-09-08 20:41:22,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-output10-block-256/_partition.lst	dst=null	perm=null
2016-09-08 20:41:22,903 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:22,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:22,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:22,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:23,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:23,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:23,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:23,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:23,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,248 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,353 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,358 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,464 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,518 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_2455145814888819235_7054 to datanode(s) 10.129.40.103:50010 10.129.40.101:50010
2016-09-08 20:41:24,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,761 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,771 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,788 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:24,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:24,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,911 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:24,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:25,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:25,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,066 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:41:25,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2455145814888819235_7054 size 252064
2016-09-08 20:41:25,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_2455145814888819235_7054 size 252064
2016-09-08 20:41:56,175 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:41:56,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:41:56,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:00,179 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:00,179 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:00,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:00,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,333 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,346 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,368 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,376 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:00,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:01,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:01,260 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:01,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:01,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:01,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:01,667 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:03,615 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:03,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:10,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:42:21,075 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:22,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:25,642 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:26,742 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:39,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:39,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:39,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:44,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:44,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:42:44,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00000	dst=null	perm=null
2016-09-08 20:42:50,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:50,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:42:56,735 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:42:56,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:43:02,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:43:02,806 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:43:04,054 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:43:07,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:43:07,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:43:16,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001/job.split	dst=null	perm=null
2016-09-08 20:43:16,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/terasort-input10-block-256/part-m-00001	dst=null	perm=null
2016-09-08 20:44:13,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-output10-block-256-slave4	dst=null	perm=null
2016-09-08 20:44:18,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-output5-block-256-slave4	dst=null	perm=null
2016-09-08 20:44:20,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 20:44:21,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 20:55:00,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/wordcount-input-5gb	dst=null	perm=null
2016-09-08 20:55:13,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/wordcount-output-5gb	dst=null	perm=null
2016-09-08 20:55:16,354 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 20:55:19,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 20:55:20,561 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 20:55:20,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 20:55:36,796 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 20:55:39,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/wordcount-output	dst=null	perm=null
2016-09-08 20:58:26,999 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 44 Total time for transactions(ms): 1Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 20:58:27,049 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=create	src=/user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 20:58:27,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-6312739161601776480_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:58:31,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-6312739161601776480_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:58:31,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_8507708023148082978_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:58:41,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_8507708023148082978_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:58:41,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_6366913364717218964_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:58:43,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_6366913364717218964_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:58:43,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_799990994457550359_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:58:48,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_799990994457550359_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:58:48,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_5231186345056457515_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:58:57,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5231186345056457515_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:58:57,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_4490464639119673992_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:58:59,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_4490464639119673992_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:58:59,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-1969471205421505012_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:04,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1969471205421505012_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:04,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_7863821252853506718_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:12,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7863821252853506718_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:12,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_4931401335364465462_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:15,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_4931401335364465462_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:15,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_1602324265654586981_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:19,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1602324265654586981_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:19,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-667359173356335072_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:29,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-667359173356335072_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:29,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_1981706189677022604_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:31,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_1981706189677022604_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:31,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_938992642572480289_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:36,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_938992642572480289_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:36,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_5860984060968150376_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:44,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5860984060968150376_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:44,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-1979903324447480047_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:47,211 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1979903324447480047_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:47,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-5414370170116822210_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 20:59:51,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-5414370170116822210_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 20:59:51,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_7617763853181653297_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:00,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7617763853181653297_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:00,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-4925865849773068607_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:02,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-4925865849773068607_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:02,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_2016604590807146823_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:07,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2016604590807146823_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:07,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-1258715186171983655_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:15,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1258715186171983655_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:15,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-5266595630273602547_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:18,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-5266595630273602547_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:18,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-1842601995267681626_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:22,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1842601995267681626_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:22,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-6776367067527409717_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:31,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-6776367067527409717_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:31,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_2514442261788707011_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:33,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2514442261788707011_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:33,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-7795463282512825534_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:38,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-7795463282512825534_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:38,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_8710605739097743054_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:45,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_8710605739097743054_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:45,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-2253937724759847220_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:48,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-2253937724759847220_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:48,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-4591046503687141592_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:51,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-4591046503687141592_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:51,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-3348301236228123712_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:00:57,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-3348301236228123712_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:00:57,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_4841107558863991545_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:03,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_4841107558863991545_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:03,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-615926565172230629_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:05,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-615926565172230629_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:05,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_7396341342848110198_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:09,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_7396341342848110198_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:09,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_9032266152845466716_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:13,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_9032266152845466716_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:13,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_5471680064428473702_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:15,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/wordcount-input-5gb	dst=null	perm=null
2016-09-08 21:01:17,335 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:01:18,196 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:01:18,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:01:20,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5471680064428473702_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:20,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-648766902900409938_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:23,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-648766902900409938_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:23,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_5719551376070499297_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:26,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_5719551376070499297_7060{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 268435456
2016-09-08 21:01:26,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_-8124909016951413172_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:30,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-8124909016951413172_7060{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 268435456
2016-09-08 21:01:30,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000. blk_8144459185018423130_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]}
2016-09-08 21:01:30,555 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:01:37,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.fsync: file /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000 for DFSClient_attempt_201609082039_0001_r_000000_0
2016-09-08 21:01:37,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_8144459185018423130_7060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.102:50010|RBW]]} size 0
2016-09-08 21:01:37,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_201609082039_0001_r_000000_0
2016-09-08 21:01:37,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 47 Total time for transactions(ms): 2Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 50 
2016-09-08 21:01:38,163 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=listStatus	src=/user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0	dst=null	perm=null
2016-09-08 21:01:38,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=mkdirs	src=/user/hduser/terasort-output10-block-256	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 21:01:38,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=rename	src=/user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0/part-r-00000	dst=/user/hduser/terasort-output10-block-256/part-r-00000	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:01:38,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=delete	src=/user/hduser/terasort-output10-block-256/_temporary/_attempt_201609082039_0001_r_000000_0	dst=null	perm=null
2016-09-08 21:01:40,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:01:40,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:01:44,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2455145814888819235_7054 to 10.129.40.105:50010 10.129.40.104:50010 10.129.40.102:50010 10.129.40.103:50010 10.129.40.101:50010 
2016-09-08 21:01:44,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-6516346748472160366_7055 to 10.129.40.105:50010 10.129.40.104:50010 10.129.40.102:50010 10.129.40.101:50010 10.129.40.103:50010 
2016-09-08 21:01:44,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_405814654912304282_7056 to 10.129.40.101:50010 10.129.40.105:50010 10.129.40.102:50010 
2016-09-08 21:01:44,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7799979528030499211_7057 to 10.129.40.103:50010 10.129.40.104:50010 10.129.40.102:50010 
2016-09-08 21:01:44,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0001	dst=null	perm=null
2016-09-08 21:01:45,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_-6516346748472160366_7055 blk_2455145814888819235_7054 blk_7799979528030499211_7057 blk_405814654912304282_7056
2016-09-08 21:01:45,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-6516346748472160366_7055 blk_2455145814888819235_7054 blk_7799979528030499211_7057
2016-09-08 21:01:46,432 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/jobtracker/jobsInfo/job_201609082039_0001.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:01:46,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609082039_0001.info. blk_-2625123122752329184_7061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 21:01:47,314 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-2625123122752329184_7061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 21:01:47,315 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2625123122752329184_7061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 21:01:47,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2625123122752329184_7061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]} size 0
2016-09-08 21:01:47,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /jobtracker/jobsInfo/job_201609082039_0001.info is closed by DFSClient_-213913761
2016-09-08 21:01:47,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-4120802014816382694_7058 to 10.129.40.104:50010 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 21:01:47,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6239355333976600539_7059 to 10.129.40.102:50010 10.129.40.104:50010 10.129.40.105:50010 
2016-09-08 21:01:47,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0001	dst=null	perm=null
2016-09-08 21:01:48,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_6239355333976600539_7059
2016-09-08 21:01:48,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_-6516346748472160366_7055 blk_2455145814888819235_7054 blk_-4120802014816382694_7058 blk_405814654912304282_7056 blk_6239355333976600539_7059
2016-09-08 21:01:51,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-6516346748472160366_7055 blk_2455145814888819235_7054 blk_-4120802014816382694_7058 blk_7799979528030499211_7057
2016-09-08 21:01:51,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-4120802014816382694_7058 blk_6239355333976600539_7059
2016-09-08 21:01:52,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:01:52,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:01:52,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:01:54,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-6516346748472160366_7055 blk_2455145814888819235_7054 blk_405814654912304282_7056
2016-09-08 21:02:01,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser	dst=null	perm=null
2016-09-08 21:02:12,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=listStatus	src=/user/hduser/wordcount-output-5gb	dst=null	perm=null
2016-09-08 21:02:14,333 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 21:02:14,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 21:02:14,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 21:02:26,761 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 21:02:44,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 21:02:44,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=webuser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-output-5gb/part-r-00000	dst=null	perm=null
2016-09-08 21:05:45,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6995266250029513818_6783 to 10.129.40.105:50010 10.129.40.102:50010 10.129.40.101:50010 
2016-09-08 21:05:45,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 56 Total time for transactions(ms): 3Number of transactions batched in Syncs: 1 Number of syncs: 8 SyncTimes(ms): 160 
2016-09-08 21:05:45,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/user/hduser/wordcount-output-5gb	dst=null	perm=null
2016-09-08 21:05:45,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_6995266250029513818_6783
2016-09-08 21:05:45,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_6995266250029513818_6783
2016-09-08 21:05:48,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_6995266250029513818_6783
2016-09-08 21:09:24,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 57 Total time for transactions(ms): 3Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 172 
2016-09-08 21:09:24,029 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 21:09:24,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 21:09:24,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar. blk_-3447409724559363104_7062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 21:09:24,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-3447409724559363104_7062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3447409724559363104_7062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-3447409724559363104_7062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,156 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar is closed by DFSClient_1817403841
2016-09-08 21:09:24,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar. New replication is 10
2016-09-08 21:09:24,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=null
2016-09-08 21:09:24,188 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,195 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/user/hduser/wordcount-input-5gb	dst=null	perm=null
2016-09-08 21:09:24,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:09:24,204 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:09:24,205 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00002	dst=null	perm=null
2016-09-08 21:09:24,206 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00003	dst=null	perm=null
2016-09-08 21:09:24,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Increasing replication for file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split. New replication is 10
2016-09-08 21:09:24,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setReplication	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:24,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split. blk_2084260077415001518_7063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]}
2016-09-08 21:09:24,252 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_2084260077415001518_7063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2084260077415001518_7063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2084260077415001518_7063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,259 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_2084260077415001518_7063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_2084260077415001518_7063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.105:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW]]} size 0
2016-09-08 21:09:24,261 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split is closed by DFSClient_1817403841
2016-09-08 21:09:24,272 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.splitmetainfo	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.splitmetainfo. blk_9098689343852269984_7064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 21:09:24,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_9098689343852269984_7064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_9098689343852269984_7064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_9098689343852269984_7064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,293 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.splitmetainfo is closed by DFSClient_1817403841
2016-09-08 21:09:24,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml. blk_-7036441313477950161_7065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 21:09:24,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7036441313477950161_7065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,358 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-7036441313477950161_7065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,358 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7036441313477950161_7065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,359 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml is closed by DFSClient_1817403841
2016-09-08 21:09:24,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=null
2016-09-08 21:09:24,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=mkdirs	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 21:09:24,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=setPermission	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002	dst=null	perm=hduser:supergroup:rwx------
2016-09-08 21:09:24,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/job-info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/job-info. blk_7399304579656402606_7066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]}
2016-09-08 21:09:24,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7399304579656402606_7066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_7399304579656402606_7066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,416 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7399304579656402606_7066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.104:50010|RBW]]} size 0
2016-09-08 21:09:24,417 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/job-info is closed by DFSClient_-213913761
2016-09-08 21:09:24,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:09:24,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken. blk_-1089174309804127743_7067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 21:09:24,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1089174309804127743_7067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 21:09:24,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-1089174309804127743_7067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 21:09:24,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.101:50010 is added to blk_-1089174309804127743_7067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.101:50010|RBW], ReplicaUnderConstruction[10.129.40.102:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 21:09:24,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken is closed by DFSClient_-213913761
2016-09-08 21:09:24,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.splitmetainfo	dst=null	perm=null
2016-09-08 21:09:24,736 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken	dst=null	perm=null
2016-09-08 21:09:24,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=null
2016-09-08 21:09:24,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=null
2016-09-08 21:09:25,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=mkdirs	src=/user/hduser/wordcount-output-5gb/_temporary	dst=null	perm=hduser:supergroup:rwxr-xr-x
2016-09-08 21:09:28,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken	dst=null	perm=null
2016-09-08 21:09:28,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken	dst=null	perm=null
2016-09-08 21:09:28,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=null
2016-09-08 21:09:28,259 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=null
2016-09-08 21:09:28,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=null
2016-09-08 21:09:28,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=null
2016-09-08 21:09:29,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,143 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:09:29,239 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:09:29,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:09:29,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.104	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:09:29,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken	dst=null	perm=null
2016-09-08 21:09:29,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=null
2016-09-08 21:09:29,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=null
2016-09-08 21:09:29,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,924 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,948 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:29,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:30,262 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00002	dst=null	perm=null
2016-09-08 21:09:30,262 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00002	dst=null	perm=null
2016-09-08 21:09:30,262 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00002	dst=null	perm=null
2016-09-08 21:09:30,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.101	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00002	dst=null	perm=null
2016-09-08 21:09:30,329 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002/jobToken	dst=null	perm=null
2016-09-08 21:09:30,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.xml	dst=null	perm=null
2016-09-08 21:09:30,671 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.jar	dst=null	perm=null
2016-09-08 21:09:31,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:31,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:31,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:31,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:31,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00003	dst=null	perm=null
2016-09-08 21:09:31,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00003	dst=null	perm=null
2016-09-08 21:09:31,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00003	dst=null	perm=null
2016-09-08 21:09:31,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00003	dst=null	perm=null
2016-09-08 21:09:32,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:32,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:32,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:32,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:32,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00000	dst=null	perm=null
2016-09-08 21:09:32,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:09:32,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00002	dst=null	perm=null
2016-09-08 21:09:32,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.105	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00003	dst=null	perm=null
2016-09-08 21:09:35,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:35,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:35,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:35,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split	dst=null	perm=null
2016-09-08 21:09:35,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:09:35,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:09:35,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:09:35,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.103	cmd=open	src=/user/hduser/wordcount-input-5gb/part-m-00001	dst=null	perm=null
2016-09-08 21:09:36,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to replicate blk_-3447409724559363104_7062 to datanode(s) 10.129.40.103:50010 10.129.40.102:50010
2016-09-08 21:09:38,569 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3447409724559363104_7062 size 252064
2016-09-08 21:09:38,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.102:50010 is added to blk_-3447409724559363104_7062 size 252064
2016-09-08 21:17:15,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 89 Total time for transactions(ms): 4Number of transactions batched in Syncs: 1 Number of syncs: 32 SyncTimes(ms): 456 
2016-09-08 21:17:15,671 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=delete	src=/user/hduser/wordcount-output-5gb/_temporary	dst=null	perm=null
2016-09-08 21:17:15,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-3447409724559363104_7062 to 10.129.40.105:50010 10.129.40.104:50010 10.129.40.101:50010 10.129.40.103:50010 10.129.40.102:50010 
2016-09-08 21:17:15,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_2084260077415001518_7063 to 10.129.40.105:50010 10.129.40.102:50010 10.129.40.103:50010 10.129.40.104:50010 10.129.40.101:50010 
2016-09-08 21:17:15,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_9098689343852269984_7064 to 10.129.40.103:50010 10.129.40.101:50010 10.129.40.104:50010 
2016-09-08 21:17:15,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-7036441313477950161_7065 to 10.129.40.103:50010 10.129.40.101:50010 10.129.40.104:50010 
2016-09-08 21:17:15,679 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.102	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002	dst=null	perm=null
2016-09-08 21:17:16,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-7036441313477950161_7065 blk_2084260077415001518_7063 blk_9098689343852269984_7064 blk_-3447409724559363104_7062
2016-09-08 21:17:16,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-7036441313477950161_7065 blk_2084260077415001518_7063 blk_9098689343852269984_7064 blk_-3447409724559363104_7062
2016-09-08 21:17:19,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.101:50010 to delete  blk_-7036441313477950161_7065 blk_2084260077415001518_7063 blk_9098689343852269984_7064 blk_-3447409724559363104_7062
2016-09-08 21:17:19,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_2084260077415001518_7063 blk_-3447409724559363104_7062
2016-09-08 21:17:22,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_2084260077415001518_7063 blk_-3447409724559363104_7062
2016-09-08 21:24:18,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.heartbeatCheck: lost heartbeat from 10.129.40.101:50010
2016-09-08 21:24:18,614 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.129.40.101:50010
2016-09-08 21:24:19,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7977103161958958977_6187 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:19,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7946376145675741559_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:19,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-7836937523927419363_6395 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:19,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to replicate blk_-7783429987115329298_6621 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:22,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7782772294082887928_6238 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:22,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7779376592926023201_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:23,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7977103161958958977_6187 size 67108864
2016-09-08 21:24:23,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7946376145675741559_6186 size 67108864
2016-09-08 21:24:24,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7782772294082887928_6238 size 32413
2016-09-08 21:24:25,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7779376592926023201_6186 size 67108864
2016-09-08 21:24:25,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7606683929089139453_6395 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:25,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7592615523138949943_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:28,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7505542344987141316_6441 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:28,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7496159591618832907_6395 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:29,641 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7592615523138949943_6186 size 67108864
2016-09-08 21:24:30,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7505542344987141316_6441 size 867
2016-09-08 21:24:31,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7378802120574772886_6426 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:31,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7606683929089139453_6395 size 268435456
2016-09-08 21:24:33,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7378802120574772886_6426 size 867
2016-09-08 21:24:34,063 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7220186226462313705_6623 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:34,063 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7217861245966871431_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:36,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7496159591618832907_6395 size 268435456
2016-09-08 21:24:37,063 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7075097728180246373_6032 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:37,063 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-7062453500618404191_6032 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:38,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7217861245966871431_6186 size 67108864
2016-09-08 21:24:39,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7220186226462313705_6623 size 120951808
2016-09-08 21:24:40,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-6997633878189874001_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:40,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-6992598795724169792_6953 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:40,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7062453500618404191_6032 size 30237952
2016-09-08 21:24:42,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7075097728180246373_6032 size 67108864
2016-09-08 21:24:43,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-6805898139422985155_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:43,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-6726783257435838995_6975 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:45,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6997633878189874001_6186 size 67108864
2016-09-08 21:24:49,065 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-6472055262581513341_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:24:51,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6805898139422985155_6185 size 67108864
2016-09-08 21:24:55,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-6193619035622695918_6954 to datanode(s) 10.129.40.104:50010
2016-09-08 21:24:55,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6048042576338080279_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:25:13,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6726783257435838995_6975 size 536870912
2016-09-08 21:25:14,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6992598795724169792_6953 size 1073741824
2016-09-08 21:25:16,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-5041886125514242845_6603 to datanode(s) 10.129.40.104:50010
2016-09-08 21:25:16,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-5040012651139541302_6246 to datanode(s) 10.129.40.104:50010
2016-09-08 21:25:19,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6472055262581513341_6186 size 67108864
2016-09-08 21:25:19,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-4812638991963349004_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:25:22,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-4650230693201814713_6932 to datanode(s) 10.129.40.103:50010
2016-09-08 21:25:33,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5041886125514242845_6603 size 268435456
2016-09-08 21:25:33,419 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-5040012651139541302_6246 size 1028
2016-09-08 21:25:34,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-3854331504842359070_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:25:34,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-3827632721020492089_6176 to datanode(s) 10.129.40.104:50010
2016-09-08 21:25:37,072 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-3662268239505718578_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:25:40,072 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-3489619926212567210_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:25:48,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6193619035622695918_6954 size 1073741824
2016-09-08 21:25:49,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-3028790158623645649_6751 to datanode(s) 10.129.40.104:50010
2016-09-08 21:25:50,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3827632721020492089_6176 size 67108864
2016-09-08 21:25:52,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-2985689546805393433_6954 to datanode(s) 10.129.40.103:50010
2016-09-08 21:25:53,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-4650230693201814713_6932 size 536870912
2016-09-08 21:25:53,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3662268239505718578_6185 size 67108864
2016-09-08 21:25:55,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-2846807660768621681_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:25:55,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-2845025832860308074_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:25:55,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-2674760384415208657_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:25:59,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-2674760384415208657_7047 size 268435456
2016-09-08 21:26:07,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-2154913573980251049_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:26:10,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2985689546805393433_6954 size 348129952
2016-09-08 21:26:10,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3028790158623645649_6751 size 268435456
2016-09-08 21:26:13,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1573310871218789699_6395 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:13,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-1553262788602843268_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:13,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1481450845829696827_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:14,345 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2846807660768621681_6185 size 67108864
2016-09-08 21:26:14,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2845025832860308074_6186 size 67108864
2016-09-08 21:26:16,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1342638358528927723_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:16,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1271743364420578437_6581 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:16,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1481450845829696827_6186 size 67108864
2016-09-08 21:26:19,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1128321536587334527_6976 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:19,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-1102053975483799161_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:26:19,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-1089174309804127743_7067 to datanode(s) 10.129.40.105:50010
2016-09-08 21:26:20,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1342638358528927723_6186 size 67108864
2016-09-08 21:26:20,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-1089174309804127743_7067 size 101
2016-09-08 21:26:22,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-1023750312413357328_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:24,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1573310871218789699_6395 size 268435456
2016-09-08 21:26:27,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1553262788602843268_7047 size 268435456
2016-09-08 21:26:27,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1271743364420578437_6581 size 268435456
2016-09-08 21:26:28,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-709070451333478194_6395 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:28,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-635158635183903227_6463 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:28,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-459870613114186857_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:28,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-440645940591556036_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:26:29,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-1102053975483799161_7047 size 268435456
2016-09-08 21:26:31,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1023750312413357328_6186 size 67108864
2016-09-08 21:26:34,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-327519740004269012_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:41,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-459870613114186857_7047 size 268435456
2016-09-08 21:26:49,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-709070451333478194_6395 size 268435456
2016-09-08 21:26:50,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1128321536587334527_6976 size 536870912
2016-09-08 21:26:51,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-635158635183903227_6463 size 16
2016-09-08 21:26:52,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-327519740004269012_6185 size 67108864
2016-09-08 21:26:52,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_568567926483497447_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:52,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_573955589279787991_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:55,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_774043623627564658_6623 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:55,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_834962125500556466_6773 to datanode(s) 10.129.40.104:50010
2016-09-08 21:26:55,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_920369504077894337_6976 to datanode(s) 10.129.40.102:50010
2016-09-08 21:26:56,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_568567926483497447_6185 size 67108864
2016-09-08 21:26:56,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_573955589279787991_6185 size 67108864
2016-09-08 21:26:58,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_966878484394989452_6643 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:58,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_988507713312378306_5954 to datanode(s) 10.129.40.103:50010
2016-09-08 21:26:58,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_990131373146336350_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:26:58,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_834962125500556466_6773 size 28497888
2016-09-08 21:26:59,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_774043623627564658_6623 size 120951808
2016-09-08 21:27:00,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_988507713312378306_5954 size 31380
2016-09-08 21:27:01,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1122728445505581295_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:01,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1164812860276989767_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:04,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1309684322533766710_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:04,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1438702212370444149_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:27:06,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_966878484394989452_6643 size 268435456
2016-09-08 21:27:06,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1122728445505581295_6186 size 67108864
2016-09-08 21:27:07,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1464069489553852063_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:07,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1520023544484839770_6773 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:08,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1309684322533766710_6185 size 67108864
2016-09-08 21:27:08,162 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1164812860276989767_6185 size 67108864
2016-09-08 21:27:09,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_1438702212370444149_7047 size 268435456
2016-09-08 21:27:10,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1679353812949831082_6464 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:10,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1707585693919657425_6602 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:11,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1464069489553852063_6185 size 67108864
2016-09-08 21:27:12,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1679353812949831082_6464 size 31857
2016-09-08 21:27:13,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1812978587059183657_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:13,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_1846957152619990826_6976 to datanode(s) 10.129.40.102:50010
2016-09-08 21:27:13,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1520023544484839770_6773 size 268435456
2016-09-08 21:27:16,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_2023356648774259414_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:16,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_2084009424569548296_6603 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:19,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1812978587059183657_6186 size 67108864
2016-09-08 21:27:21,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1707585693919657425_6602 size 268435456
2016-09-08 21:27:22,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_2434991129755416384_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:22,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_2478441049333117916_6184 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:27,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2023356648774259414_6186 size 67108864
2016-09-08 21:27:28,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_2884376378730379876_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:30,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2434991129755416384_6186 size 67108864
2016-09-08 21:27:32,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2084009424569548296_6603 size 268435456
2016-09-08 21:27:34,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3278750964080027991_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:34,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3294467562343461365_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:34,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3390062265384821239_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:35,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2478441049333117916_6184 size 67108864
2016-09-08 21:27:35,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2884376378730379876_6186 size 67108864
2016-09-08 21:27:37,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3416737312512338312_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:37,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3436285091712000664_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:37,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3294467562343461365_6186 size 67108864
2016-09-08 21:27:38,289 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3278750964080027991_6186 size 67108864
2016-09-08 21:27:38,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3390062265384821239_7047 size 268435456
2016-09-08 21:27:40,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3557241100251260950_6032 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:40,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3582789123556368590_6933 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:40,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3659802787662662709_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:41,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3416737312512338312_6185 size 67108864
2016-09-08 21:27:41,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3436285091712000664_6185 size 67108864
2016-09-08 21:27:43,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3786184960278206137_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:43,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3788832825427786657_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:44,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3557241100251260950_6032 size 67108864
2016-09-08 21:27:46,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_3938629731954513355_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:46,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3659802787662662709_7047 size 268435456
2016-09-08 21:27:47,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3786184960278206137_6185 size 67108864
2016-09-08 21:27:49,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4060950639630365422_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:49,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_4112255321187627228_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:27:50,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3788832825427786657_6186 size 67108864
2016-09-08 21:27:52,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4226269094948843945_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:53,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3938629731954513355_6185 size 67108864
2016-09-08 21:27:55,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4354363894532751879_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:27:56,792 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4060950639630365422_6185 size 67108864
2016-09-08 21:27:57,130 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3582789123556368590_6933 size 536870912
2016-09-08 21:27:57,131 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.invalidateBlock: blk_3582789123556368590_6933 on 10.129.40.102:50010
2016-09-08 21:27:57,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_3582789123556368590_6933 to 10.129.40.102:50010
2016-09-08 21:27:58,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4584013282473726312_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:58,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4605233459090163954_6933 to datanode(s) 10.129.40.104:50010
2016-09-08 21:27:58,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_4640397790294874104_6862 to datanode(s) 10.129.40.102:50010
2016-09-08 21:27:58,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.102:50010 to delete  blk_3582789123556368590_6933
2016-09-08 21:27:59,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_4112255321187627228_7047 size 268435456
2016-09-08 21:28:02,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4226269094948843945_6186 size 67108864
2016-09-08 21:28:02,056 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4354363894532751879_6186 size 67108864
2016-09-08 21:28:04,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4858733560779222288_6932 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:04,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_4936829901502829877_6471 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:05,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4584013282473726312_6186 size 67108864
2016-09-08 21:28:07,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_5053064429720155699_6583 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:16,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_5491945077124829769_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:28:16,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_5548417429453604243_7049 to datanode(s) 10.129.40.102:50010
2016-09-08 21:28:24,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4605233459090163954_6933 size 536870912
2016-09-08 21:28:24,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4936829901502829877_6471 size 31857
2016-09-08 21:28:25,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_5993473545310462172_6395 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:26,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4858733560779222288_6932 size 536870912
2016-09-08 21:28:27,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_5491945077124829769_7047 size 268435456
2016-09-08 21:28:28,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_6131493618031406397_6434 to datanode(s) 10.129.40.103:50010
2016-09-08 21:28:28,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_6152442587267412067_6187 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:31,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_6382231837260840579_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:28:34,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_6445579512898956756_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:34,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_6446045949068725457_6396 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:38,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6382231837260840579_7047 size 268435456
2016-09-08 21:28:41,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5053064429720155699_6583 size 268435456
2016-09-08 21:28:41,345 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_5993473545310462172_6395 size 268435456
2016-09-08 21:28:42,491 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6131493618031406397_6434 size 867
2016-09-08 21:28:43,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7023560025554360510_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:43,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7037858242854145616_6976 to datanode(s) 10.129.40.105:50010
2016-09-08 21:28:43,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7057257626135527739_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:28:43,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6152442587267412067_6187 size 67108864
2016-09-08 21:28:46,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7182528863675729136_6323 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:46,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7259927296725742419_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:46,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7057257626135527739_6185 size 67108864
2016-09-08 21:28:46,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7023560025554360510_6185 size 67108864
2016-09-08 21:28:48,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7182528863675729136_6323 size 1035
2016-09-08 21:28:49,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7399304579656402606_7066 to datanode(s) 10.129.40.102:50010
2016-09-08 21:28:49,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7426864857276055827_6602 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:49,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7454661177680876731_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:28:49,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7259927296725742419_6185 size 67108864
2016-09-08 21:28:52,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7529929598813281715_5997 to datanode(s) 10.129.40.103:50010
2016-09-08 21:28:52,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7596373101365893750_6411 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:52,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6446045949068725457_6396 size 125566428
2016-09-08 21:28:52,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.invalidateBlock: blk_6446045949068725457_6396 on 10.129.40.105:50010
2016-09-08 21:28:52,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6446045949068725457_6396 to 10.129.40.105:50010
2016-09-08 21:28:55,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7454661177680876731_6186 size 67108864
2016-09-08 21:28:55,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_6446045949068725457_6396
2016-09-08 21:28:57,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7529929598813281715_5997 size 403
2016-09-08 21:28:58,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7426864857276055827_6602 size 268435456
2016-09-08 21:28:58,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_7931813268708076060_6932 to datanode(s) 10.129.40.104:50010
2016-09-08 21:28:58,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7961540047632521112_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:29:00,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7596373101365893750_6411 size 32919
2016-09-08 21:29:01,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_8033564130516290332_6375 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:01,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_8048088812225643038_6643 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:03,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_7961540047632521112_7047 size 268435456
2016-09-08 21:29:03,714 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8033564130516290332_6375 size 32413
2016-09-08 21:29:04,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_8191431947072471751_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:07,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_8450978694738234386_6284 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:07,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8508570477610248848_7047 to datanode(s) 10.129.40.102:50010
2016-09-08 21:29:08,252 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6445579512898956756_7047 size 268435456
2016-09-08 21:29:15,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7931813268708076060_6932 size 536870912
2016-09-08 21:29:16,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_8980875291402728646_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:18,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.heartbeatCheck: lost heartbeat from 10.129.40.102:50010
2016-09-08 21:29:18,626 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.129.40.102:50010
2016-09-08 21:29:18,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8191431947072471751_6186 size 67108864
2016-09-08 21:29:19,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-635158635183903227_6463 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:19,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-459870613114186857_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:29:20,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8048088812225643038_6643 size 268435456
2016-09-08 21:29:20,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-635158635183903227_6463 size 16
2016-09-08 21:29:21,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8450978694738234386_6284 size 32413
2016-09-08 21:29:22,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_7037858242854145616_6976 size 536870912
2016-09-08 21:29:22,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-327519740004269012_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:25,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_-75278606890931903_7049 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:25,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-3572081612619764_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:25,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_76022055443862941_6642 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:26,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8980875291402728646_6186 size 67108864
2016-09-08 21:29:27,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-327519740004269012_6185 size 67108864
2016-09-08 21:29:27,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.105:50010 is added to blk_-459870613114186857_7047 size 268435456
2016-09-08 21:29:28,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_113126663445573567_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:30,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-75278606890931903_7049 size 268435456
2016-09-08 21:29:31,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_568567926483497447_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:31,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_573955589279787991_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:34,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_113126663445573567_7047 size 268435456
2016-09-08 21:29:34,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_774043623627564658_6623 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:37,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_834962125500556466_6773 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:38,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_774043623627564658_6623 size 120951808
2016-09-08 21:29:38,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3572081612619764_6186 size 67108864
2016-09-08 21:29:40,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_568567926483497447_6185 size 67108864
2016-09-08 21:29:40,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_834962125500556466_6773 size 28497888
2016-09-08 21:29:40,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_966878484394989452_6643 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:40,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_988507713312378306_5954 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:40,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1122728445505581295_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:40,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1164812860276989767_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:40,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1208860333276073979_7046 to datanode(s) 10.129.40.105:50010
2016-09-08 21:29:41,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_76022055443862941_6642 size 268435456
2016-09-08 21:29:42,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_988507713312378306_5954 size 31380
2016-09-08 21:29:43,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1309684322533766710_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:43,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1438702212370444149_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:43,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1464069489553852063_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:43,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_573955589279787991_6185 size 67108864
2016-09-08 21:29:46,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_1520023544484839770_6773 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:46,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1122728445505581295_6186 size 67108864
2016-09-08 21:29:47,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1164812860276989767_6185 size 67108864
2016-09-08 21:29:49,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to replicate blk_1679353812949831082_6464 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:49,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1707585693919657425_6602 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:51,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1520023544484839770_6773 size 268435456
2016-09-08 21:29:52,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1812978587059183657_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:29:55,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_2023356648774259414_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:55,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_2084009424569548296_6603 to datanode(s) 10.129.40.104:50010
2016-09-08 21:29:55,707 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call getBlockLocations(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split, 0, 2684354560) from 10.129.40.103:40122: error: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 21:29:55,708 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call getBlockLocations(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split, 0, 2684354560) from 10.129.40.103:40124: error: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 21:29:55,709 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call getBlockLocations(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split, 0, 2684354560) from 10.129.40.103:40120: error: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 21:29:58,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1309684322533766710_6185 size 67108864
2016-09-08 21:29:58,811 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2023356648774259414_6186 size 67108864
2016-09-08 21:29:58,882 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call getBlockLocations(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split, 0, 2684354560) from 10.129.40.105:43324: error: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 21:30:00,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_2084009424569548296_6603 size 268435456
2016-09-08 21:30:01,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_2556939611260963982_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:04,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_2884376378730379876_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:10,892 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1438702212370444149_7047 size 268435456
2016-09-08 21:30:11,656 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call getBlockLocations(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split, 0, 2684354560) from 10.129.40.104:46042: error: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 21:30:11,659 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call getBlockLocations(/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split, 0, 2684354560) from 10.129.40.104:46044: error: java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
java.io.FileNotFoundException: File does not exist: /usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/staging/hduser/.staging/job_201609082039_0002/job.split
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInternal(FSNamesystem.java:758)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockLocations(NameNode.java:589)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:342)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1350)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1346)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1344)
2016-09-08 21:30:13,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3278750964080027991_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:13,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_3294467562343461365_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:30:13,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_3390062265384821239_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:13,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1812978587059183657_6186 size 67108864
2016-09-08 21:30:13,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1707585693919657425_6602 size 268435456
2016-09-08 21:30:14,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 92 Total time for transactions(ms): 4Number of transactions batched in Syncs: 1 Number of syncs: 34 SyncTimes(ms): 473 
2016-09-08 21:30:14,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=create	src=/jobtracker/jobsInfo/job_201609082039_0002.info	dst=null	perm=hduser:supergroup:rw-r--r--
2016-09-08 21:30:14,214 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609082039_0002.info. blk_-3645734112949878524_7068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW], ReplicaUnderConstruction[10.129.40.105:50010|RBW]]}
2016-09-08 21:30:14,219 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Not able to place enough replicas, still in need of 1
2016-09-08 21:30:14,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /jobtracker/jobsInfo/job_201609082039_0002.info. blk_7862194735477958205_7068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]}
2016-09-08 21:30:14,226 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7862194735477958205_7068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 21:30:14,229 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7862194735477958205_7068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.129.40.104:50010|RBW], ReplicaUnderConstruction[10.129.40.103:50010|RBW]]} size 0
2016-09-08 21:30:14,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.completeFile: file /jobtracker/jobsInfo/job_201609082039_0002.info is closed by DFSClient_-213913761
2016-09-08 21:30:14,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7399304579656402606_7066 to 10.129.40.103:50010 10.129.40.104:50010 
2016-09-08 21:30:14,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-1089174309804127743_7067 to 10.129.40.103:50010 10.129.40.105:50010 
2016-09-08 21:30:14,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/usr/local/hadoop_tmp/hdfs/hadoopdata/mapred/system/job_201609082039_0002	dst=null	perm=null
2016-09-08 21:30:15,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3294467562343461365_6186 size 67108864
2016-09-08 21:30:16,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_3436285091712000664_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:30:16,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_3557241100251260950_6032 to datanode(s) 10.129.40.104:50010
2016-09-08 21:30:16,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3786184960278206137_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:16,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3885462861563251198_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:16,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_-1089174309804127743_7067
2016-09-08 21:30:16,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2884376378730379876_6186 size 67108864
2016-09-08 21:30:16,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3278750964080027991_6186 size 67108864
2016-09-08 21:30:18,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3786184960278206137_6185 size 67108864
2016-09-08 21:30:19,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3557241100251260950_6032 size 67108864
2016-09-08 21:30:19,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3436285091712000664_6185 size 67108864
2016-09-08 21:30:19,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3938629731954513355_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:19,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_7399304579656402606_7066 blk_-1089174309804127743_7067
2016-09-08 21:30:21,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3938629731954513355_6185 size 67108864
2016-09-08 21:30:22,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_4060950639630365422_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:22,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_4226269094948843945_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:30:22,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_7399304579656402606_7066
2016-09-08 21:30:24,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4226269094948843945_6186 size 67108864
2016-09-08 21:30:25,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_4354363894532751879_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:30:25,179 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4060950639630365422_6185 size 67108864
2016-09-08 21:30:27,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4354363894532751879_6186 size 67108864
2016-09-08 21:30:28,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_4584013282473726312_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:28,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_4605233459090163954_6933 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:31,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4584013282473726312_6186 size 67108864
2016-09-08 21:30:34,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_4858733560779222288_6932 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:34,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_4936829901502829877_6471 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:37,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_5053064429720155699_6583 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:39,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4605233459090163954_6933 size 536870912
2016-09-08 21:30:41,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4936829901502829877_6471 size 31857
2016-09-08 21:30:42,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_4858733560779222288_6932 size 536870912
2016-09-08 21:30:47,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_5053064429720155699_6583 size 268435456
2016-09-08 21:30:49,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_5993473545310462172_6395 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:49,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_6131493618031406397_6434 to datanode(s) 10.129.40.104:50010
2016-09-08 21:30:50,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_6131493618031406397_6434 size 867
2016-09-08 21:30:52,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_6152442587267412067_6187 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:53,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_5993473545310462172_6395 size 268435456
2016-09-08 21:30:54,395 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6152442587267412067_6187 size 67108864
2016-09-08 21:30:55,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_6382231837260840579_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:55,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_6445579512898956756_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:55,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_6446045949068725457_6396 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:55,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_6574230813210458185_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:30:58,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_6696779519262551660_7050 to datanode(s) 10.129.40.103:50010
2016-09-08 21:30:59,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_6696779519262551660_7050 size 1688
2016-09-08 21:31:01,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7023560025554360510_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:01,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7037858242854145616_6976 to datanode(s) 10.129.40.104:50010
2016-09-08 21:31:01,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7057257626135527739_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:31:03,861 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7023560025554360510_6185 size 67108864
2016-09-08 21:31:04,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7057257626135527739_6185 size 67108864
2016-09-08 21:31:04,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7182528863675729136_6323 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:04,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7259927296725742419_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:05,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7182528863675729136_6323 size 1035
2016-09-08 21:31:07,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7426864857276055827_6602 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:08,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7037858242854145616_6976 size 536870912
2016-09-08 21:31:10,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7454661177680876731_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:31:10,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7529929598813281715_5997 to datanode(s) 10.129.40.104:50010
2016-09-08 21:31:10,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7596373101365893750_6411 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:11,866 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7529929598813281715_5997 size 403
2016-09-08 21:31:12,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7259927296725742419_6185 size 67108864
2016-09-08 21:31:12,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7454661177680876731_6186 size 67108864
2016-09-08 21:31:14,808 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7596373101365893750_6411 size 32919
2016-09-08 21:31:15,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7426864857276055827_6602 size 268435456
2016-09-08 21:31:16,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7862194735477958205_7068 to datanode(s) 10.129.40.105:50010
2016-09-08 21:31:16,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7931813268708076060_6932 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:16,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_7961540047632521112_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:19,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8033564130516290332_6375 to datanode(s) 10.129.40.104:50010
2016-09-08 21:31:19,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_8048088812225643038_6643 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:20,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8033564130516290332_6375 size 32413
2016-09-08 21:31:22,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_8191431947072471751_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:31:26,658 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7961540047632521112_7047 size 268435456
2016-09-08 21:31:28,125 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8980875291402728646_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:31:30,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8980875291402728646_6186 size 67108864
2016-09-08 21:31:32,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_7931813268708076060_6932 size 536870912
2016-09-08 21:31:32,530 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8048088812225643038_6643 size 268435456
2016-09-08 21:31:33,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8191431947072471751_6186 size 67108864
2016-09-08 21:34:18,525 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-4812638991963349004_7047
2016-09-08 21:34:18,525 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-6048042576338080279_7047
2016-09-08 21:34:18,525 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_990131373146336350_7047
2016-09-08 21:34:18,525 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_5548417429453604243_7049
2016-09-08 21:34:18,525 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-3854331504842359070_7047
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_8508570477610248848_7047
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-440645940591556036_7047
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-3489619926212567210_7047
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-7836937523927419363_6395
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_7399304579656402606_7066
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_920369504077894337_6976
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-7783429987115329298_6621
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_4640397790294874104_6862
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-2154913573980251049_7047
2016-09-08 21:34:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_1846957152619990826_6976
2016-09-08 21:34:58,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_7495514232846220488_7047 to datanode(s) 10.129.40.104:50010 10.129.40.105:50010
2016-09-08 21:35:09,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_7495514232846220488_7047 size 268435456
2016-09-08 21:35:55,144 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-8742684997352567239_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:36:04,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7977103161958958977_6187 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:04,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-7946376145675741559_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:06,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7946376145675741559_6186 size 67108864
2016-09-08 21:36:08,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7977103161958958977_6187 size 67108864
2016-09-08 21:36:10,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7782772294082887928_6238 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:10,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-7779376592926023201_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:10,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7606683929089139453_6395 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:10,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-7592615523138949943_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:12,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7782772294082887928_6238 size 32413
2016-09-08 21:36:13,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7505542344987141316_6441 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:13,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-7496159591618832907_6395 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:13,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7779376592926023201_6186 size 67108864
2016-09-08 21:36:13,491 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7592615523138949943_6186 size 67108864
2016-09-08 21:36:15,072 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7505542344987141316_6441 size 867
2016-09-08 21:36:16,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-7378802120574772886_6426 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:17,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7496159591618832907_6395 size 268435456
2016-09-08 21:36:17,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7378802120574772886_6426 size 867
2016-09-08 21:36:19,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7220186226462313705_6623 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:19,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7217861245966871431_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:22,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-7075097728180246373_6032 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:22,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-7062453500618404191_6032 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:22,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6997633878189874001_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:23,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7606683929089139453_6395 size 268435456
2016-09-08 21:36:25,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6805898139422985155_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:26,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-7075097728180246373_6032 size 67108864
2016-09-08 21:36:26,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6997633878189874001_6186 size 67108864
2016-09-08 21:36:28,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-6726783257435838995_6975 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:29,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7220186226462313705_6623 size 120951808
2016-09-08 21:36:29,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7217861245966871431_6186 size 67108864
2016-09-08 21:36:30,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6805898139422985155_6185 size 67108864
2016-09-08 21:36:30,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-7062453500618404191_6032 size 30237952
2016-09-08 21:36:31,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6530526502300064177_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:36:34,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-6472055262581513341_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:34,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6193619035622695918_6954 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:37,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6048042576338080279_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:36:37,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-5904103860602000738_7052 to datanode(s) 10.129.40.105:50010
2016-09-08 21:36:43,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-5466012713730117132_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:36:49,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-5041886125514242845_6603 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:51,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6472055262581513341_6186 size 67108864
2016-09-08 21:36:52,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-5040012651139541302_6246 to datanode(s) 10.129.40.103:50010
2016-09-08 21:36:52,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-4812638991963349004_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:55,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-4650230693201814713_6932 to datanode(s) 10.129.40.104:50010
2016-09-08 21:36:55,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-5041886125514242845_6603 size 268435456
2016-09-08 21:36:56,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-5040012651139541302_6246 size 1028
2016-09-08 21:36:57,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6193619035622695918_6954 size 1073741824
2016-09-08 21:37:01,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-3991331141686508358_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:37:01,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-3854331504842359070_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:01,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-3827632721020492089_6176 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:04,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-3489619926212567210_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:37:04,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3827632721020492089_6176 size 67108864
2016-09-08 21:37:06,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3854331504842359070_7047 size 268435456
2016-09-08 21:37:10,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-3028790158623645649_6751 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:13,154 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-2846807660768621681_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:18,426 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-2846807660768621681_6185 size 67108864
2016-09-08 21:37:19,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-3028790158623645649_6751 size 268435456
2016-09-08 21:37:19,154 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-2154913573980251049_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:37:19,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-6726783257435838995_6975 size 536870912
2016-09-08 21:37:25,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-1573310871218789699_6395 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:25,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-1553262788602843268_7047 to datanode(s) 10.129.40.105:50010
2016-09-08 21:37:25,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4812638991963349004_7047 size 268435456
2016-09-08 21:37:28,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-1342638358528927723_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:37:28,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-1271743364420578437_6581 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:29,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1573310871218789699_6395 size 268435456
2016-09-08 21:37:31,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-1128321536587334527_6976 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:31,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-1102053975483799161_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:32,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1271743364420578437_6581 size 268435456
2016-09-08 21:37:34,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-1023750312413357328_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:37:44,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1102053975483799161_7047 size 268435456
2016-09-08 21:37:48,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1023750312413357328_6186 size 67108864
2016-09-08 21:37:50,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-1128321536587334527_6976 size 536870912
2016-09-08 21:38:06,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3991331141686508358_7047 size 268435456
2016-09-08 21:38:10,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_2434991129755416384_6186 to datanode(s) 10.129.40.103:50010
2016-09-08 21:38:12,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2434991129755416384_6186 size 67108864
2016-09-08 21:38:13,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_2478441049333117916_6184 to datanode(s) 10.129.40.103:50010
2016-09-08 21:38:15,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1342638358528927723_6186 size 67108864
2016-09-08 21:38:16,373 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4650230693201814713_6932 size 536870912
2016-09-08 21:38:16,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_2478441049333117916_6184 size 67108864
2016-09-08 21:38:19,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3166075942414836038_7047 to datanode(s) 10.129.40.103:50010
2016-09-08 21:38:23,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3166075942414836038_7047 size 268435456
2016-09-08 21:38:25,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_3416737312512338312_6185 to datanode(s) 10.129.40.103:50010
2016-09-08 21:38:25,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_3788832825427786657_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:38:27,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_3416737312512338312_6185 size 67108864
2016-09-08 21:38:29,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_3788832825427786657_6186 size 67108864
2016-09-08 21:38:34,162 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_4640397790294874104_6862 to datanode(s) 10.129.40.104:50010
2016-09-08 21:38:36,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_4640397790294874104_6862 size 32318
2016-09-08 21:38:49,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_5548417429453604243_7049 to datanode(s) 10.129.40.103:50010
2016-09-08 21:38:52,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_5548417429453604243_7049 size 168161792
2016-09-08 21:39:16,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_8450978694738234386_6284 to datanode(s) 10.129.40.103:50010
2016-09-08 21:39:16,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_8508570477610248848_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:39:17,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_8450978694738234386_6284 size 32413
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_3885462861563251198_7047
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_6382231837260840579_7047
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_7862194735477958205_7068
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_6446045949068725457_6396
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_1679353812949831082_6464
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_1208860333276073979_7046
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_2556939611260963982_7047
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_3390062265384821239_7047
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_1464069489553852063_6185
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_966878484394989452_6643
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_6445579512898956756_7047
2016-09-08 21:39:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_6574230813210458185_7047
2016-09-08 21:39:27,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_8508570477610248848_7047 size 268435456
2016-09-08 21:39:52,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 21:39:52,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_6696779519262551660_7050 to 10.129.40.104:50010 10.129.40.105:50010 10.129.40.103:50010 
2016-09-08 21:39:52,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 96 Total time for transactions(ms): 4Number of transactions batched in Syncs: 1 Number of syncs: 37 SyncTimes(ms): 671 
2016-09-08 21:39:52,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/jobtracker/jobsInfo/job_201609081943_0001.info	dst=null	perm=null
2016-09-08 21:39:52,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_6696779519262551660_7050
2016-09-08 21:39:55,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_6696779519262551660_7050
2016-09-08 21:39:58,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.105:50010 to delete  blk_6696779519262551660_7050
2016-09-08 21:44:16,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_-6992598795724169792_6953 to datanode(s) 10.129.40.103:50010
2016-09-08 21:44:18,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-6048042576338080279_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-1553262788602843268_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-6530526502300064177_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-5904103860602000738_7052
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-3489619926212567210_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_7495514232846220488_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-8742684997352567239_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-5466012713730117132_7047
2016-09-08 21:44:18,527 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: PendingReplicationMonitor timed out block blk_-2154913573980251049_7047
2016-09-08 21:44:18,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.heartbeatCheck: lost heartbeat from 10.129.40.105:50010
2016-09-08 21:44:18,654 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.129.40.105:50010
2016-09-08 21:44:21,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 21:44:22,802 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 21:44:28,289 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_-6992598795724169792_6953 size 1073741824
2016-09-08 21:47:42,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.processReport: block blk_-3645734112949878524_7068 on 10.129.40.103:50010 size 0 does not belong to any file.
2016-09-08 21:47:42,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-3645734112949878524_7068 to 10.129.40.103:50010
2016-09-08 21:47:42,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_3395126369060701247 to add as corrupt on 10.129.40.103:50010 by /10.129.40.103
2016-09-08 21:47:43,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-3645734112949878524_7068
2016-09-08 21:50:55,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-4646741607299753810_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 21:50:55,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-3662268239505718578_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 21:50:58,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-2845025832860308074_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:50:58,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-1481450845829696827_6186 to datanode(s) 10.129.40.104:50010
2016-09-08 21:51:00,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-3662268239505718578_6185 size 67108864
2016-09-08 21:51:01,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_966878484394989452_6643 to datanode(s) 10.129.40.104:50010
2016-09-08 21:51:01,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to replicate blk_1679353812949831082_6464 to datanode(s) 10.129.40.103:50010
2016-09-08 21:51:03,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.103:50010 is added to blk_1679353812949831082_6464 size 31857
2016-09-08 21:51:06,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2845025832860308074_6186 size 67108864
2016-09-08 21:51:13,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-4646741607299753810_7047 size 268435456
2016-09-08 21:51:14,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-1481450845829696827_6186 size 67108864
2016-09-08 21:51:19,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_966878484394989452_6643 size 268435456
2016-09-08 22:04:40,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-2985689546805393433_6954 to datanode(s) 10.129.40.104:50010
2016-09-08 22:04:40,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-709070451333478194_6395 to datanode(s) 10.129.40.104:50010
2016-09-08 22:04:43,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_-440645940591556036_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 22:04:43,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_920369504077894337_6976 to datanode(s) 10.129.40.104:50010
2016-09-08 22:05:07,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-709070451333478194_6395 size 268435456
2016-09-08 22:05:12,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-2985689546805393433_6954 size 348129952
2016-09-08 22:05:17,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_-440645940591556036_7047 size 268435456
2016-09-08 22:05:24,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_920369504077894337_6976 size 536870912
2016-09-08 22:18:25,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_990131373146336350_7047 to datanode(s) 10.129.40.104:50010
2016-09-08 22:18:28,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_1464069489553852063_6185 to datanode(s) 10.129.40.104:50010
2016-09-08 22:18:28,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to replicate blk_1846957152619990826_6976 to datanode(s) 10.129.40.104:50010
2016-09-08 22:18:30,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_990131373146336350_7047 size 168161792
2016-09-08 22:18:36,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1464069489553852063_6185 size 67108864
2016-09-08 22:18:43,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.129.40.104:50010 is added to blk_1846957152619990826_6976 size 536870912
2016-09-08 22:39:52,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 22:39:52,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_-2625123122752329184_7061 to 10.129.40.103:50010 10.129.40.104:50010 
2016-09-08 22:39:52,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 97 Total time for transactions(ms): 4Number of transactions batched in Syncs: 1 Number of syncs: 0 SyncTimes(ms): 0 
2016-09-08 22:39:52,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/jobtracker/jobsInfo/job_201609082039_0001.info	dst=null	perm=null
2016-09-08 22:39:52,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addToInvalidates: blk_7862194735477958205_7068 to 10.129.40.104:50010 10.129.40.103:50010 
2016-09-08 22:39:52,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=delete	src=/jobtracker/jobsInfo/job_201609082039_0002.info	dst=null	perm=null
2016-09-08 22:39:52,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.104:50010 to delete  blk_-2625123122752329184_7061 blk_7862194735477958205_7068
2016-09-08 22:39:55,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.129.40.103:50010 to delete  blk_-2625123122752329184_7061 blk_7862194735477958205_7068
2016-09-08 22:44:23,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 22:44:24,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
2016-09-08 23:39:52,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=hduser	ip=/10.129.40.100	cmd=listStatus	src=/jobtracker/jobsInfo	dst=null	perm=null
2016-09-08 23:44:24,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.129.40.100
2016-09-08 23:44:25,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 10.129.40.100
